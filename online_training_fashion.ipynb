{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x18685450b50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from CMA_obj import CMA_opt\n",
    "from PEPG_obj import PEPG_opt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from SPSA_obj import SPSA_opt\n",
    "from Finite_diff_grad import FD_opt\n",
    "from ADAM_opt import AdamOptimizer\n",
    "from PSO_obj import PSO_opt\n",
    "from scipy.interpolate import interp1d\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "from NN_utils import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online training test fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:06<00:00, 4014433.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 1611828.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4422102/4422102 [00:01<00:00, 3954408.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#load fashion MNIST DATASET\n",
    "MNIST_train = datasets.FashionMNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "MNIST_test = datasets.FashionMNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader_MNIST = torch.utils.data.DataLoader(dataset=MNIST_train, batch_size=100, shuffle=True)\n",
    "test_loader_MNIST = torch.utils.data.DataLoader(dataset=MNIST_test, batch_size=100, shuffle=False)\n",
    "\n",
    "X_train_MNIST, Y_train_MNIST = next(iter(train_loader_MNIST))\n",
    "X_test_MNIST, Y_test_MNIST = next(iter(test_loader_MNIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the network:  11274\n",
      "Using cuda device\n",
      "Tiny_convnet(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/5], Step [100/600], Loss: 0.617326021194458, Test Accuracy: 75.06%\n",
      "Epoch [1/5], Step [200/600], Loss: 0.4337739944458008, Test Accuracy: 78.76%\n",
      "Epoch [1/5], Step [300/600], Loss: 0.46650195121765137, Test Accuracy: 80.83%\n",
      "Epoch [1/5], Step [400/600], Loss: 0.6987248063087463, Test Accuracy: 81.68%\n",
      "Epoch [1/5], Step [500/600], Loss: 0.5264167785644531, Test Accuracy: 82.98%\n",
      "Epoch [1/5], Step [600/600], Loss: 0.4977506995201111, Test Accuracy: 82.78%\n",
      "Epoch [2/5], Step [100/600], Loss: 0.43587490916252136, Test Accuracy: 84.35%\n",
      "Epoch [2/5], Step [200/600], Loss: 0.5053822994232178, Test Accuracy: 84.84%\n",
      "Epoch [2/5], Step [300/600], Loss: 0.3643813729286194, Test Accuracy: 85.56%\n",
      "Epoch [2/5], Step [400/600], Loss: 0.313019722700119, Test Accuracy: 84.03%\n",
      "Epoch [2/5], Step [500/600], Loss: 0.33932361006736755, Test Accuracy: 86.43%\n",
      "Epoch [2/5], Step [600/600], Loss: 0.26979953050613403, Test Accuracy: 86.44%\n",
      "Epoch [3/5], Step [100/600], Loss: 0.4188879132270813, Test Accuracy: 86.59%\n",
      "Epoch [3/5], Step [200/600], Loss: 0.3228818476200104, Test Accuracy: 86.78%\n",
      "Epoch [3/5], Step [300/600], Loss: 0.30264952778816223, Test Accuracy: 84.46%\n",
      "Epoch [3/5], Step [400/600], Loss: 0.22665782272815704, Test Accuracy: 86.85%\n",
      "Epoch [3/5], Step [500/600], Loss: 0.3978999853134155, Test Accuracy: 86.44%\n",
      "Epoch [3/5], Step [600/600], Loss: 0.2478436529636383, Test Accuracy: 86.89%\n",
      "Epoch [4/5], Step [100/600], Loss: 0.2694854140281677, Test Accuracy: 87.61%\n",
      "Epoch [4/5], Step [200/600], Loss: 0.26485589146614075, Test Accuracy: 86.62%\n",
      "Epoch [4/5], Step [300/600], Loss: 0.304493248462677, Test Accuracy: 87.82%\n",
      "Epoch [4/5], Step [400/600], Loss: 0.31532493233680725, Test Accuracy: 88.1%\n",
      "Epoch [4/5], Step [500/600], Loss: 0.21294139325618744, Test Accuracy: 88.05%\n",
      "Epoch [4/5], Step [600/600], Loss: 0.22213402390480042, Test Accuracy: 88.5%\n",
      "Epoch [5/5], Step [100/600], Loss: 0.4052504003047943, Test Accuracy: 88.52%\n",
      "Epoch [5/5], Step [200/600], Loss: 0.41310369968414307, Test Accuracy: 87.27%\n",
      "Epoch [5/5], Step [300/600], Loss: 0.2671213746070862, Test Accuracy: 88.05%\n",
      "Epoch [5/5], Step [400/600], Loss: 0.15022872388362885, Test Accuracy: 88.19%\n",
      "Epoch [5/5], Step [500/600], Loss: 0.2175610214471817, Test Accuracy: 88.19%\n",
      "Epoch [5/5], Step [600/600], Loss: 0.31248733401298523, Test Accuracy: 88.48%\n"
     ]
    }
   ],
   "source": [
    "Mini_NN = Tiny_convnet()\n",
    "N_dim = Mini_NN.count_parameters()\n",
    "print('Number of parameters in the network: ', N_dim)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(Mini_NN.parameters(), lr=0.001)\n",
    "\n",
    "#training the full NN\n",
    "n_epochs = 5\n",
    "test_acc = train_pytorch_NN(Mini_NN, n_epochs, train_loader_MNIST, test_loader_MNIST, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Using cuda device\n",
      "Tiny_convnet(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "{i+1}Epoch [1/20], Step [50/600], Loss: 2.459984064102173, Test Accuracy: 10.36%\n",
      "{i+1}Epoch [1/20], Step [100/600], Loss: 2.7072689533233643, Test Accuracy: 18.44%\n",
      "{i+1}Epoch [1/20], Step [150/600], Loss: 2.306612253189087, Test Accuracy: 7.74%\n",
      "{i+1}Epoch [1/20], Step [200/600], Loss: 2.384544610977173, Test Accuracy: 16.96%\n",
      "{i+1}Epoch [1/20], Step [250/600], Loss: 2.4376559257507324, Test Accuracy: 13.31%\n",
      "{i+1}Epoch [1/20], Step [300/600], Loss: 2.3221144676208496, Test Accuracy: 12.27%\n",
      "{i+1}Epoch [1/20], Step [350/600], Loss: 2.345755100250244, Test Accuracy: 13.96%\n",
      "{i+1}Epoch [1/20], Step [400/600], Loss: 2.315723419189453, Test Accuracy: 15.14%\n",
      "{i+1}Epoch [1/20], Step [450/600], Loss: 2.3602182865142822, Test Accuracy: 9.23%\n",
      "{i+1}Epoch [1/20], Step [500/600], Loss: 2.260685920715332, Test Accuracy: 14.58%\n",
      "{i+1}Epoch [1/20], Step [550/600], Loss: 2.2785091400146484, Test Accuracy: 19.42%\n",
      "{i+1}Epoch [1/20], Step [600/600], Loss: 2.2434539794921875, Test Accuracy: 10.59%\n",
      "{i+1}Epoch [2/20], Step [50/600], Loss: 2.302868366241455, Test Accuracy: 13.72%\n",
      "{i+1}Epoch [2/20], Step [100/600], Loss: 2.2771756649017334, Test Accuracy: 15.04%\n",
      "{i+1}Epoch [2/20], Step [150/600], Loss: 2.280688762664795, Test Accuracy: 12.77%\n",
      "{i+1}Epoch [2/20], Step [200/600], Loss: 2.2452478408813477, Test Accuracy: 18.59%\n",
      "{i+1}Epoch [2/20], Step [250/600], Loss: 2.2574880123138428, Test Accuracy: 28.46%\n",
      "{i+1}Epoch [2/20], Step [300/600], Loss: 2.2447943687438965, Test Accuracy: 14.96%\n",
      "{i+1}Epoch [2/20], Step [350/600], Loss: 2.242906093597412, Test Accuracy: 14.99%\n",
      "{i+1}Epoch [2/20], Step [400/600], Loss: 2.2850470542907715, Test Accuracy: 17.08%\n",
      "{i+1}Epoch [2/20], Step [450/600], Loss: 2.2196383476257324, Test Accuracy: 18.74%\n",
      "{i+1}Epoch [2/20], Step [500/600], Loss: 2.2489593029022217, Test Accuracy: 12.45%\n",
      "{i+1}Epoch [2/20], Step [550/600], Loss: 2.2502710819244385, Test Accuracy: 18.6%\n",
      "{i+1}Epoch [2/20], Step [600/600], Loss: 2.2440340518951416, Test Accuracy: 24.15%\n",
      "{i+1}Epoch [3/20], Step [50/600], Loss: 2.2571980953216553, Test Accuracy: 13.99%\n",
      "{i+1}Epoch [3/20], Step [100/600], Loss: 2.1917810440063477, Test Accuracy: 14.76%\n",
      "{i+1}Epoch [3/20], Step [150/600], Loss: 2.181607723236084, Test Accuracy: 14.73%\n",
      "{i+1}Epoch [3/20], Step [200/600], Loss: 2.1297800540924072, Test Accuracy: 23.81%\n",
      "{i+1}Epoch [3/20], Step [250/600], Loss: 2.199202299118042, Test Accuracy: 19.0%\n",
      "{i+1}Epoch [3/20], Step [300/600], Loss: 2.1822760105133057, Test Accuracy: 22.25%\n",
      "{i+1}Epoch [3/20], Step [350/600], Loss: 2.0278303623199463, Test Accuracy: 30.86%\n",
      "{i+1}Epoch [3/20], Step [400/600], Loss: 2.1154327392578125, Test Accuracy: 25.48%\n",
      "{i+1}Epoch [3/20], Step [450/600], Loss: 2.128129482269287, Test Accuracy: 24.63%\n",
      "{i+1}Epoch [3/20], Step [500/600], Loss: 2.0948309898376465, Test Accuracy: 22.29%\n",
      "{i+1}Epoch [3/20], Step [550/600], Loss: 2.198998212814331, Test Accuracy: 22.08%\n",
      "{i+1}Epoch [3/20], Step [600/600], Loss: 2.1053595542907715, Test Accuracy: 22.66%\n",
      "{i+1}Epoch [4/20], Step [50/600], Loss: 2.1284894943237305, Test Accuracy: 25.91%\n",
      "{i+1}Epoch [4/20], Step [100/600], Loss: 1.9428311586380005, Test Accuracy: 35.57%\n",
      "{i+1}Epoch [4/20], Step [150/600], Loss: 2.021787643432617, Test Accuracy: 19.22%\n",
      "{i+1}Epoch [4/20], Step [200/600], Loss: 2.0506410598754883, Test Accuracy: 26.27%\n",
      "{i+1}Epoch [4/20], Step [250/600], Loss: 1.9430955648422241, Test Accuracy: 23.08%\n",
      "{i+1}Epoch [4/20], Step [300/600], Loss: 2.0822958946228027, Test Accuracy: 23.66%\n",
      "{i+1}Epoch [4/20], Step [350/600], Loss: 1.966947317123413, Test Accuracy: 27.78%\n",
      "{i+1}Epoch [4/20], Step [400/600], Loss: 1.8795796632766724, Test Accuracy: 28.46%\n",
      "{i+1}Epoch [4/20], Step [450/600], Loss: 1.7767539024353027, Test Accuracy: 46.09%\n",
      "{i+1}Epoch [4/20], Step [500/600], Loss: 1.8973779678344727, Test Accuracy: 29.43%\n",
      "{i+1}Epoch [4/20], Step [550/600], Loss: 1.817542314529419, Test Accuracy: 35.75%\n",
      "{i+1}Epoch [4/20], Step [600/600], Loss: 1.67487370967865, Test Accuracy: 34.71%\n",
      "{i+1}Epoch [5/20], Step [50/600], Loss: 1.852660059928894, Test Accuracy: 35.85%\n",
      "{i+1}Epoch [5/20], Step [100/600], Loss: 1.6518510580062866, Test Accuracy: 43.06%\n",
      "{i+1}Epoch [5/20], Step [150/600], Loss: 1.7655971050262451, Test Accuracy: 35.32%\n",
      "{i+1}Epoch [5/20], Step [200/600], Loss: 1.7632880210876465, Test Accuracy: 35.83%\n",
      "{i+1}Epoch [5/20], Step [250/600], Loss: 1.7305797338485718, Test Accuracy: 41.01%\n",
      "{i+1}Epoch [5/20], Step [300/600], Loss: 1.7899575233459473, Test Accuracy: 38.75%\n",
      "{i+1}Epoch [5/20], Step [350/600], Loss: 1.8508259057998657, Test Accuracy: 33.33%\n",
      "{i+1}Epoch [5/20], Step [400/600], Loss: 1.697676658630371, Test Accuracy: 46.57%\n",
      "{i+1}Epoch [5/20], Step [450/600], Loss: 1.6886237859725952, Test Accuracy: 36.56%\n",
      "{i+1}Epoch [5/20], Step [500/600], Loss: 1.4384384155273438, Test Accuracy: 44.53%\n",
      "{i+1}Epoch [5/20], Step [550/600], Loss: 1.662477731704712, Test Accuracy: 38.68%\n",
      "{i+1}Epoch [5/20], Step [600/600], Loss: 1.4400039911270142, Test Accuracy: 46.47%\n",
      "{i+1}Epoch [6/20], Step [50/600], Loss: 1.434411883354187, Test Accuracy: 49.26%\n",
      "{i+1}Epoch [6/20], Step [100/600], Loss: 1.4947912693023682, Test Accuracy: 48.9%\n",
      "{i+1}Epoch [6/20], Step [150/600], Loss: 1.310508131980896, Test Accuracy: 54.92%\n",
      "{i+1}Epoch [6/20], Step [200/600], Loss: 1.4716551303863525, Test Accuracy: 48.23%\n",
      "{i+1}Epoch [6/20], Step [250/600], Loss: 1.4749915599822998, Test Accuracy: 45.26%\n",
      "{i+1}Epoch [6/20], Step [300/600], Loss: 1.5674865245819092, Test Accuracy: 38.86%\n",
      "{i+1}Epoch [6/20], Step [350/600], Loss: 1.3507537841796875, Test Accuracy: 45.02%\n",
      "{i+1}Epoch [6/20], Step [400/600], Loss: 1.3482633829116821, Test Accuracy: 48.9%\n",
      "{i+1}Epoch [6/20], Step [450/600], Loss: 1.402390956878662, Test Accuracy: 44.41%\n",
      "{i+1}Epoch [6/20], Step [500/600], Loss: 1.2891422510147095, Test Accuracy: 51.26%\n",
      "{i+1}Epoch [6/20], Step [550/600], Loss: 1.2478306293487549, Test Accuracy: 53.44%\n",
      "{i+1}Epoch [6/20], Step [600/600], Loss: 1.2482914924621582, Test Accuracy: 53.27%\n",
      "{i+1}Epoch [7/20], Step [50/600], Loss: 1.348032832145691, Test Accuracy: 49.83%\n",
      "{i+1}Epoch [7/20], Step [100/600], Loss: 1.2826712131500244, Test Accuracy: 53.37%\n",
      "{i+1}Epoch [7/20], Step [150/600], Loss: 1.2121021747589111, Test Accuracy: 52.68%\n",
      "{i+1}Epoch [7/20], Step [200/600], Loss: 1.2797911167144775, Test Accuracy: 57.13%\n",
      "{i+1}Epoch [7/20], Step [250/600], Loss: 1.4767673015594482, Test Accuracy: 51.92%\n",
      "{i+1}Epoch [7/20], Step [300/600], Loss: 1.187283992767334, Test Accuracy: 53.79%\n",
      "{i+1}Epoch [7/20], Step [350/600], Loss: 1.2062227725982666, Test Accuracy: 51.29%\n",
      "{i+1}Epoch [7/20], Step [400/600], Loss: 1.1699143648147583, Test Accuracy: 52.14%\n",
      "{i+1}Epoch [7/20], Step [450/600], Loss: 1.2285734415054321, Test Accuracy: 56.5%\n",
      "{i+1}Epoch [7/20], Step [500/600], Loss: 1.3336422443389893, Test Accuracy: 55.65%\n",
      "{i+1}Epoch [7/20], Step [550/600], Loss: 1.2495808601379395, Test Accuracy: 54.73%\n",
      "{i+1}Epoch [7/20], Step [600/600], Loss: 1.12709379196167, Test Accuracy: 61.11%\n",
      "{i+1}Epoch [8/20], Step [50/600], Loss: 1.1338423490524292, Test Accuracy: 54.41%\n",
      "{i+1}Epoch [8/20], Step [100/600], Loss: 1.1784770488739014, Test Accuracy: 59.89%\n",
      "{i+1}Epoch [8/20], Step [150/600], Loss: 1.2163136005401611, Test Accuracy: 58.54%\n",
      "{i+1}Epoch [8/20], Step [200/600], Loss: 1.2265756130218506, Test Accuracy: 58.67%\n",
      "{i+1}Epoch [8/20], Step [250/600], Loss: 1.0599355697631836, Test Accuracy: 59.57%\n",
      "{i+1}Epoch [8/20], Step [300/600], Loss: 1.0353171825408936, Test Accuracy: 58.14%\n",
      "{i+1}Epoch [8/20], Step [350/600], Loss: 1.1080909967422485, Test Accuracy: 62.55%\n",
      "{i+1}Epoch [8/20], Step [400/600], Loss: 1.199575662612915, Test Accuracy: 60.51%\n",
      "{i+1}Epoch [8/20], Step [450/600], Loss: 1.0616238117218018, Test Accuracy: 59.2%\n",
      "{i+1}Epoch [8/20], Step [500/600], Loss: 1.0212318897247314, Test Accuracy: 66.72%\n",
      "{i+1}Epoch [8/20], Step [550/600], Loss: 1.126865029335022, Test Accuracy: 57.31%\n",
      "{i+1}Epoch [8/20], Step [600/600], Loss: 1.1277714967727661, Test Accuracy: 61.74%\n",
      "{i+1}Epoch [9/20], Step [50/600], Loss: 1.116368055343628, Test Accuracy: 62.04%\n",
      "{i+1}Epoch [9/20], Step [100/600], Loss: 1.0453741550445557, Test Accuracy: 61.89%\n",
      "{i+1}Epoch [9/20], Step [150/600], Loss: 0.9140550494194031, Test Accuracy: 68.1%\n",
      "{i+1}Epoch [9/20], Step [200/600], Loss: 1.150926113128662, Test Accuracy: 60.88%\n",
      "{i+1}Epoch [9/20], Step [250/600], Loss: 1.0509823560714722, Test Accuracy: 58.12%\n",
      "{i+1}Epoch [9/20], Step [300/600], Loss: 0.9140335917472839, Test Accuracy: 66.31%\n",
      "{i+1}Epoch [9/20], Step [350/600], Loss: 0.9626064896583557, Test Accuracy: 65.22%\n",
      "{i+1}Epoch [9/20], Step [400/600], Loss: 1.1164101362228394, Test Accuracy: 61.51%\n",
      "{i+1}Epoch [9/20], Step [450/600], Loss: 0.931752622127533, Test Accuracy: 60.74%\n",
      "{i+1}Epoch [9/20], Step [500/600], Loss: 0.952307939529419, Test Accuracy: 63.21%\n",
      "{i+1}Epoch [9/20], Step [550/600], Loss: 0.9218287467956543, Test Accuracy: 66.93%\n",
      "{i+1}Epoch [9/20], Step [600/600], Loss: 1.0232551097869873, Test Accuracy: 62.34%\n",
      "{i+1}Epoch [10/20], Step [50/600], Loss: 0.9672324657440186, Test Accuracy: 62.27%\n",
      "{i+1}Epoch [10/20], Step [100/600], Loss: 0.9049198031425476, Test Accuracy: 69.92%\n",
      "{i+1}Epoch [10/20], Step [150/600], Loss: 0.7835968136787415, Test Accuracy: 68.2%\n",
      "{i+1}Epoch [10/20], Step [200/600], Loss: 0.8509083390235901, Test Accuracy: 70.22%\n",
      "{i+1}Epoch [10/20], Step [250/600], Loss: 0.8697567582130432, Test Accuracy: 68.25%\n",
      "{i+1}Epoch [10/20], Step [300/600], Loss: 0.8907343149185181, Test Accuracy: 65.15%\n",
      "{i+1}Epoch [10/20], Step [350/600], Loss: 1.023982048034668, Test Accuracy: 66.62%\n",
      "{i+1}Epoch [10/20], Step [400/600], Loss: 0.8340394496917725, Test Accuracy: 66.77%\n",
      "{i+1}Epoch [10/20], Step [450/600], Loss: 0.9067612290382385, Test Accuracy: 64.48%\n",
      "{i+1}Epoch [10/20], Step [500/600], Loss: 0.8363053798675537, Test Accuracy: 65.09%\n",
      "{i+1}Epoch [10/20], Step [550/600], Loss: 0.9006196856498718, Test Accuracy: 68.6%\n",
      "{i+1}Epoch [10/20], Step [600/600], Loss: 0.950937032699585, Test Accuracy: 68.04%\n",
      "{i+1}Epoch [11/20], Step [50/600], Loss: 0.8539121150970459, Test Accuracy: 68.41%\n",
      "{i+1}Epoch [11/20], Step [100/600], Loss: 0.9458948373794556, Test Accuracy: 66.12%\n",
      "{i+1}Epoch [11/20], Step [150/600], Loss: 0.9075801968574524, Test Accuracy: 67.92%\n",
      "{i+1}Epoch [11/20], Step [200/600], Loss: 0.7879683971405029, Test Accuracy: 68.96%\n",
      "{i+1}Epoch [11/20], Step [250/600], Loss: 0.8707274794578552, Test Accuracy: 69.74%\n",
      "{i+1}Epoch [11/20], Step [300/600], Loss: 0.8244731426239014, Test Accuracy: 70.73%\n",
      "{i+1}Epoch [11/20], Step [350/600], Loss: 0.8605666160583496, Test Accuracy: 68.71%\n",
      "{i+1}Epoch [11/20], Step [400/600], Loss: 0.8996833562850952, Test Accuracy: 69.2%\n",
      "{i+1}Epoch [11/20], Step [450/600], Loss: 0.8126966953277588, Test Accuracy: 70.35%\n",
      "{i+1}Epoch [11/20], Step [500/600], Loss: 0.7969674468040466, Test Accuracy: 68.93%\n",
      "{i+1}Epoch [11/20], Step [550/600], Loss: 0.846306562423706, Test Accuracy: 69.73%\n",
      "{i+1}Epoch [11/20], Step [600/600], Loss: 0.7783852219581604, Test Accuracy: 70.91%\n",
      "{i+1}Epoch [12/20], Step [50/600], Loss: 0.8288092613220215, Test Accuracy: 68.33%\n",
      "{i+1}Epoch [12/20], Step [100/600], Loss: 0.8517513275146484, Test Accuracy: 68.68%\n",
      "{i+1}Epoch [12/20], Step [150/600], Loss: 0.7811634540557861, Test Accuracy: 65.13%\n",
      "{i+1}Epoch [12/20], Step [200/600], Loss: 0.8812707662582397, Test Accuracy: 67.63%\n",
      "{i+1}Epoch [12/20], Step [250/600], Loss: 0.8100855350494385, Test Accuracy: 71.59%\n",
      "{i+1}Epoch [12/20], Step [300/600], Loss: 0.7667116522789001, Test Accuracy: 70.66%\n",
      "{i+1}Epoch [12/20], Step [350/600], Loss: 0.7857372760772705, Test Accuracy: 70.67%\n",
      "{i+1}Epoch [12/20], Step [400/600], Loss: 0.7554743885993958, Test Accuracy: 71.05%\n",
      "{i+1}Epoch [12/20], Step [450/600], Loss: 0.720693826675415, Test Accuracy: 71.52%\n",
      "{i+1}Epoch [12/20], Step [500/600], Loss: 0.7573494911193848, Test Accuracy: 71.38%\n",
      "{i+1}Epoch [12/20], Step [550/600], Loss: 0.8420248627662659, Test Accuracy: 71.72%\n",
      "{i+1}Epoch [12/20], Step [600/600], Loss: 0.9083024859428406, Test Accuracy: 68.86%\n",
      "{i+1}Epoch [13/20], Step [50/600], Loss: 0.8699720501899719, Test Accuracy: 68.54%\n",
      "{i+1}Epoch [13/20], Step [100/600], Loss: 0.8460451364517212, Test Accuracy: 71.46%\n",
      "{i+1}Epoch [13/20], Step [150/600], Loss: 0.8640032410621643, Test Accuracy: 71.19%\n",
      "{i+1}Epoch [13/20], Step [200/600], Loss: 0.7707200050354004, Test Accuracy: 68.49%\n",
      "{i+1}Epoch [13/20], Step [250/600], Loss: 0.7764609456062317, Test Accuracy: 71.23%\n",
      "{i+1}Epoch [13/20], Step [300/600], Loss: 0.7801464200019836, Test Accuracy: 69.45%\n",
      "{i+1}Epoch [13/20], Step [350/600], Loss: 0.8644178509712219, Test Accuracy: 69.4%\n",
      "{i+1}Epoch [13/20], Step [400/600], Loss: 0.753013551235199, Test Accuracy: 70.1%\n",
      "{i+1}Epoch [13/20], Step [450/600], Loss: 0.808241069316864, Test Accuracy: 71.22%\n",
      "{i+1}Epoch [13/20], Step [500/600], Loss: 0.8329744935035706, Test Accuracy: 71.53%\n",
      "{i+1}Epoch [13/20], Step [550/600], Loss: 0.8718356490135193, Test Accuracy: 69.97%\n",
      "{i+1}Epoch [13/20], Step [600/600], Loss: 0.7645068168640137, Test Accuracy: 71.13%\n",
      "{i+1}Epoch [14/20], Step [50/600], Loss: 0.7269219756126404, Test Accuracy: 71.93%\n",
      "{i+1}Epoch [14/20], Step [100/600], Loss: 0.7407888770103455, Test Accuracy: 72.1%\n",
      "{i+1}Epoch [14/20], Step [150/600], Loss: 0.9154548645019531, Test Accuracy: 67.92%\n",
      "{i+1}Epoch [14/20], Step [200/600], Loss: 0.7757530212402344, Test Accuracy: 71.62%\n",
      "{i+1}Epoch [14/20], Step [250/600], Loss: 0.7202422618865967, Test Accuracy: 72.33%\n",
      "{i+1}Epoch [14/20], Step [300/600], Loss: 0.7211989760398865, Test Accuracy: 70.53%\n",
      "{i+1}Epoch [14/20], Step [350/600], Loss: 0.7580364346504211, Test Accuracy: 70.98%\n",
      "{i+1}Epoch [14/20], Step [400/600], Loss: 0.7223328948020935, Test Accuracy: 71.74%\n",
      "{i+1}Epoch [14/20], Step [450/600], Loss: 0.7217074632644653, Test Accuracy: 73.14%\n",
      "{i+1}Epoch [14/20], Step [500/600], Loss: 0.6893206834793091, Test Accuracy: 72.98%\n",
      "{i+1}Epoch [14/20], Step [550/600], Loss: 0.770373523235321, Test Accuracy: 73.19%\n",
      "{i+1}Epoch [14/20], Step [600/600], Loss: 0.7342993021011353, Test Accuracy: 72.75%\n",
      "{i+1}Epoch [15/20], Step [50/600], Loss: 0.6919807195663452, Test Accuracy: 71.91%\n",
      "{i+1}Epoch [15/20], Step [100/600], Loss: 0.8018656969070435, Test Accuracy: 70.69%\n",
      "{i+1}Epoch [15/20], Step [150/600], Loss: 0.6631962656974792, Test Accuracy: 72.48%\n",
      "{i+1}Epoch [15/20], Step [200/600], Loss: 0.8191143870353699, Test Accuracy: 70.35%\n",
      "{i+1}Epoch [15/20], Step [250/600], Loss: 0.6500646471977234, Test Accuracy: 72.88%\n",
      "{i+1}Epoch [15/20], Step [300/600], Loss: 0.6985073685646057, Test Accuracy: 73.64%\n",
      "{i+1}Epoch [15/20], Step [350/600], Loss: 0.7181727886199951, Test Accuracy: 71.02%\n",
      "{i+1}Epoch [15/20], Step [400/600], Loss: 0.6857608556747437, Test Accuracy: 72.78%\n",
      "{i+1}Epoch [15/20], Step [450/600], Loss: 0.689121425151825, Test Accuracy: 70.8%\n",
      "{i+1}Epoch [15/20], Step [500/600], Loss: 0.7541549205780029, Test Accuracy: 71.45%\n",
      "{i+1}Epoch [15/20], Step [550/600], Loss: 0.7439415454864502, Test Accuracy: 69.15%\n",
      "{i+1}Epoch [15/20], Step [600/600], Loss: 0.687974214553833, Test Accuracy: 71.91%\n",
      "{i+1}Epoch [16/20], Step [50/600], Loss: 0.7338920831680298, Test Accuracy: 72.81%\n",
      "{i+1}Epoch [16/20], Step [100/600], Loss: 0.7132750749588013, Test Accuracy: 73.15%\n",
      "{i+1}Epoch [16/20], Step [150/600], Loss: 0.7638537883758545, Test Accuracy: 70.48%\n",
      "{i+1}Epoch [16/20], Step [200/600], Loss: 0.8553485870361328, Test Accuracy: 71.69%\n",
      "{i+1}Epoch [16/20], Step [250/600], Loss: 0.712311863899231, Test Accuracy: 71.64%\n",
      "{i+1}Epoch [16/20], Step [300/600], Loss: 0.7008416652679443, Test Accuracy: 72.95%\n",
      "{i+1}Epoch [16/20], Step [350/600], Loss: 0.7614638805389404, Test Accuracy: 72.0%\n",
      "{i+1}Epoch [16/20], Step [400/600], Loss: 0.6617960333824158, Test Accuracy: 74.19%\n",
      "{i+1}Epoch [16/20], Step [450/600], Loss: 0.698203444480896, Test Accuracy: 73.41%\n",
      "{i+1}Epoch [16/20], Step [500/600], Loss: 0.8145046234130859, Test Accuracy: 72.24%\n",
      "{i+1}Epoch [16/20], Step [550/600], Loss: 0.7458646893501282, Test Accuracy: 73.27%\n",
      "{i+1}Epoch [16/20], Step [600/600], Loss: 0.6332520842552185, Test Accuracy: 73.59%\n",
      "{i+1}Epoch [17/20], Step [50/600], Loss: 0.6802019476890564, Test Accuracy: 71.71%\n",
      "{i+1}Epoch [17/20], Step [100/600], Loss: 0.7197227478027344, Test Accuracy: 73.11%\n",
      "{i+1}Epoch [17/20], Step [150/600], Loss: 0.6905614733695984, Test Accuracy: 74.22%\n",
      "{i+1}Epoch [17/20], Step [200/600], Loss: 0.7210848331451416, Test Accuracy: 73.69%\n",
      "{i+1}Epoch [17/20], Step [250/600], Loss: 0.6804611086845398, Test Accuracy: 75.25%\n",
      "{i+1}Epoch [17/20], Step [300/600], Loss: 0.7276160717010498, Test Accuracy: 73.63%\n",
      "{i+1}Epoch [17/20], Step [350/600], Loss: 0.6030380725860596, Test Accuracy: 73.97%\n",
      "{i+1}Epoch [17/20], Step [400/600], Loss: 0.700888991355896, Test Accuracy: 73.61%\n",
      "{i+1}Epoch [17/20], Step [450/600], Loss: 0.6564957499504089, Test Accuracy: 73.91%\n",
      "{i+1}Epoch [17/20], Step [500/600], Loss: 0.6748031377792358, Test Accuracy: 73.41%\n",
      "{i+1}Epoch [17/20], Step [550/600], Loss: 0.6483017206192017, Test Accuracy: 74.22%\n",
      "{i+1}Epoch [17/20], Step [600/600], Loss: 0.6934658288955688, Test Accuracy: 73.36%\n",
      "{i+1}Epoch [18/20], Step [50/600], Loss: 0.6700611114501953, Test Accuracy: 73.94%\n",
      "{i+1}Epoch [18/20], Step [100/600], Loss: 0.6838841438293457, Test Accuracy: 72.98%\n",
      "{i+1}Epoch [18/20], Step [150/600], Loss: 0.6029338240623474, Test Accuracy: 72.71%\n",
      "{i+1}Epoch [18/20], Step [200/600], Loss: 0.6869174838066101, Test Accuracy: 72.59%\n",
      "{i+1}Epoch [18/20], Step [250/600], Loss: 0.651343584060669, Test Accuracy: 73.97%\n",
      "{i+1}Epoch [18/20], Step [300/600], Loss: 0.6989279389381409, Test Accuracy: 74.68%\n",
      "{i+1}Epoch [18/20], Step [350/600], Loss: 0.653056800365448, Test Accuracy: 73.93%\n",
      "{i+1}Epoch [18/20], Step [400/600], Loss: 0.6833831667900085, Test Accuracy: 73.83%\n",
      "{i+1}Epoch [18/20], Step [450/600], Loss: 0.7609607577323914, Test Accuracy: 73.19%\n",
      "{i+1}Epoch [18/20], Step [500/600], Loss: 0.6345626711845398, Test Accuracy: 73.49%\n",
      "{i+1}Epoch [18/20], Step [550/600], Loss: 0.6831579804420471, Test Accuracy: 72.45%\n",
      "{i+1}Epoch [18/20], Step [600/600], Loss: 0.6102504134178162, Test Accuracy: 72.07%\n",
      "{i+1}Epoch [19/20], Step [50/600], Loss: 0.7109543681144714, Test Accuracy: 73.27%\n",
      "{i+1}Epoch [19/20], Step [100/600], Loss: 0.6384488344192505, Test Accuracy: 74.13%\n",
      "{i+1}Epoch [19/20], Step [150/600], Loss: 0.6398880481719971, Test Accuracy: 73.33%\n",
      "{i+1}Epoch [19/20], Step [200/600], Loss: 0.6753999590873718, Test Accuracy: 73.4%\n",
      "{i+1}Epoch [19/20], Step [250/600], Loss: 0.6939408779144287, Test Accuracy: 71.35%\n",
      "{i+1}Epoch [19/20], Step [300/600], Loss: 0.6163573265075684, Test Accuracy: 74.36%\n",
      "{i+1}Epoch [19/20], Step [350/600], Loss: 0.6185025572776794, Test Accuracy: 72.14%\n",
      "{i+1}Epoch [19/20], Step [400/600], Loss: 0.6263566613197327, Test Accuracy: 75.16%\n",
      "{i+1}Epoch [19/20], Step [450/600], Loss: 0.6670120358467102, Test Accuracy: 73.18%\n",
      "{i+1}Epoch [19/20], Step [500/600], Loss: 0.7060754895210266, Test Accuracy: 72.85%\n",
      "{i+1}Epoch [19/20], Step [550/600], Loss: 0.7013764977455139, Test Accuracy: 73.34%\n",
      "{i+1}Epoch [19/20], Step [600/600], Loss: 0.6585298180580139, Test Accuracy: 75.51%\n",
      "{i+1}Epoch [20/20], Step [50/600], Loss: 0.6476917266845703, Test Accuracy: 74.65%\n",
      "{i+1}Epoch [20/20], Step [100/600], Loss: 0.638076901435852, Test Accuracy: 74.58%\n",
      "{i+1}Epoch [20/20], Step [150/600], Loss: 0.6585370898246765, Test Accuracy: 75.86%\n",
      "{i+1}Epoch [20/20], Step [200/600], Loss: 0.6504170298576355, Test Accuracy: 74.01%\n",
      "{i+1}Epoch [20/20], Step [250/600], Loss: 0.6168437600135803, Test Accuracy: 74.71%\n",
      "{i+1}Epoch [20/20], Step [300/600], Loss: 0.5949601531028748, Test Accuracy: 74.62%\n",
      "{i+1}Epoch [20/20], Step [350/600], Loss: 0.6804020404815674, Test Accuracy: 74.01%\n",
      "{i+1}Epoch [20/20], Step [400/600], Loss: 0.6626535654067993, Test Accuracy: 74.92%\n",
      "{i+1}Epoch [20/20], Step [450/600], Loss: 0.6291837096214294, Test Accuracy: 72.77%\n",
      "{i+1}Epoch [20/20], Step [500/600], Loss: 0.6249381899833679, Test Accuracy: 73.92%\n",
      "{i+1}Epoch [20/20], Step [550/600], Loss: 0.6217018365859985, Test Accuracy: 74.83%\n",
      "{i+1}Epoch [20/20], Step [600/600], Loss: 0.6634863018989563, Test Accuracy: 72.53%\n",
      "10\n",
      "Using cuda device\n",
      "Tiny_convnet(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "{i+1}Epoch [1/20], Step [50/600], Loss: 2.4126288890838623, Test Accuracy: 7.96%\n",
      "{i+1}Epoch [1/20], Step [100/600], Loss: 2.3354709148406982, Test Accuracy: 14.52%\n",
      "{i+1}Epoch [1/20], Step [150/600], Loss: 2.316004991531372, Test Accuracy: 15.16%\n",
      "{i+1}Epoch [1/20], Step [200/600], Loss: 2.2877814769744873, Test Accuracy: 5.83%\n",
      "{i+1}Epoch [1/20], Step [250/600], Loss: 2.269693374633789, Test Accuracy: 15.94%\n",
      "{i+1}Epoch [1/20], Step [300/600], Loss: 2.284681797027588, Test Accuracy: 10.65%\n",
      "{i+1}Epoch [1/20], Step [350/600], Loss: 2.2268102169036865, Test Accuracy: 13.81%\n",
      "{i+1}Epoch [1/20], Step [400/600], Loss: 2.276209592819214, Test Accuracy: 11.46%\n",
      "{i+1}Epoch [1/20], Step [450/600], Loss: 2.307549476623535, Test Accuracy: 13.21%\n",
      "{i+1}Epoch [1/20], Step [500/600], Loss: 2.2923085689544678, Test Accuracy: 8.09%\n",
      "{i+1}Epoch [1/20], Step [550/600], Loss: 2.246645450592041, Test Accuracy: 25.56%\n",
      "{i+1}Epoch [1/20], Step [600/600], Loss: 2.2575907707214355, Test Accuracy: 13.1%\n",
      "{i+1}Epoch [2/20], Step [50/600], Loss: 2.2724835872650146, Test Accuracy: 11.84%\n",
      "{i+1}Epoch [2/20], Step [100/600], Loss: 2.2807517051696777, Test Accuracy: 12.09%\n",
      "{i+1}Epoch [2/20], Step [150/600], Loss: 2.2024240493774414, Test Accuracy: 30.57%\n",
      "{i+1}Epoch [2/20], Step [200/600], Loss: 2.1689608097076416, Test Accuracy: 22.08%\n",
      "{i+1}Epoch [2/20], Step [250/600], Loss: 2.256922483444214, Test Accuracy: 8.88%\n",
      "{i+1}Epoch [2/20], Step [300/600], Loss: 2.2002062797546387, Test Accuracy: 24.56%\n",
      "{i+1}Epoch [2/20], Step [350/600], Loss: 2.1294105052948, Test Accuracy: 28.22%\n",
      "{i+1}Epoch [2/20], Step [400/600], Loss: 2.2402801513671875, Test Accuracy: 20.05%\n",
      "{i+1}Epoch [2/20], Step [450/600], Loss: 2.129605293273926, Test Accuracy: 26.98%\n",
      "{i+1}Epoch [2/20], Step [500/600], Loss: 2.1108264923095703, Test Accuracy: 27.32%\n",
      "{i+1}Epoch [2/20], Step [550/600], Loss: 2.071320056915283, Test Accuracy: 31.3%\n",
      "{i+1}Epoch [2/20], Step [600/600], Loss: 2.1018450260162354, Test Accuracy: 22.79%\n",
      "{i+1}Epoch [3/20], Step [50/600], Loss: 1.961130976676941, Test Accuracy: 35.69%\n",
      "{i+1}Epoch [3/20], Step [100/600], Loss: 1.940017819404602, Test Accuracy: 34.18%\n",
      "{i+1}Epoch [3/20], Step [150/600], Loss: 1.8822603225708008, Test Accuracy: 40.42%\n",
      "{i+1}Epoch [3/20], Step [200/600], Loss: 1.8465564250946045, Test Accuracy: 33.77%\n",
      "{i+1}Epoch [3/20], Step [250/600], Loss: 1.8748834133148193, Test Accuracy: 30.42%\n",
      "{i+1}Epoch [3/20], Step [300/600], Loss: 1.6162619590759277, Test Accuracy: 46.1%\n",
      "{i+1}Epoch [3/20], Step [350/600], Loss: 1.783657193183899, Test Accuracy: 32.51%\n",
      "{i+1}Epoch [3/20], Step [400/600], Loss: 1.764195203781128, Test Accuracy: 31.0%\n",
      "{i+1}Epoch [3/20], Step [450/600], Loss: 1.6340521574020386, Test Accuracy: 43.77%\n",
      "{i+1}Epoch [3/20], Step [500/600], Loss: 1.7950025796890259, Test Accuracy: 35.67%\n",
      "{i+1}Epoch [3/20], Step [550/600], Loss: 1.570740818977356, Test Accuracy: 47.72%\n",
      "{i+1}Epoch [3/20], Step [600/600], Loss: 1.5115296840667725, Test Accuracy: 47.31%\n",
      "{i+1}Epoch [4/20], Step [50/600], Loss: 1.557031512260437, Test Accuracy: 39.44%\n",
      "{i+1}Epoch [4/20], Step [100/600], Loss: 1.5497764348983765, Test Accuracy: 45.9%\n",
      "{i+1}Epoch [4/20], Step [150/600], Loss: 1.4808387756347656, Test Accuracy: 50.06%\n",
      "{i+1}Epoch [4/20], Step [200/600], Loss: 1.2400697469711304, Test Accuracy: 57.0%\n",
      "{i+1}Epoch [4/20], Step [250/600], Loss: 1.3010450601577759, Test Accuracy: 52.49%\n",
      "{i+1}Epoch [4/20], Step [300/600], Loss: 1.5396989583969116, Test Accuracy: 46.21%\n",
      "{i+1}Epoch [4/20], Step [350/600], Loss: 1.2777698040008545, Test Accuracy: 56.08%\n",
      "{i+1}Epoch [4/20], Step [400/600], Loss: 1.210319995880127, Test Accuracy: 53.52%\n",
      "{i+1}Epoch [4/20], Step [450/600], Loss: 1.1258965730667114, Test Accuracy: 52.67%\n",
      "{i+1}Epoch [4/20], Step [500/600], Loss: 1.3514405488967896, Test Accuracy: 47.45%\n",
      "{i+1}Epoch [4/20], Step [550/600], Loss: 1.181019902229309, Test Accuracy: 53.07%\n",
      "{i+1}Epoch [4/20], Step [600/600], Loss: 1.1503231525421143, Test Accuracy: 52.68%\n",
      "{i+1}Epoch [5/20], Step [50/600], Loss: 1.2273070812225342, Test Accuracy: 56.19%\n",
      "{i+1}Epoch [5/20], Step [100/600], Loss: 1.2963323593139648, Test Accuracy: 55.31%\n",
      "{i+1}Epoch [5/20], Step [150/600], Loss: 1.1416668891906738, Test Accuracy: 56.85%\n",
      "{i+1}Epoch [5/20], Step [200/600], Loss: 1.1985284090042114, Test Accuracy: 59.17%\n",
      "{i+1}Epoch [5/20], Step [250/600], Loss: 1.1845442056655884, Test Accuracy: 55.0%\n",
      "{i+1}Epoch [5/20], Step [300/600], Loss: 1.0195788145065308, Test Accuracy: 60.54%\n",
      "{i+1}Epoch [5/20], Step [350/600], Loss: 1.0963119268417358, Test Accuracy: 63.58%\n",
      "{i+1}Epoch [5/20], Step [400/600], Loss: 1.0596745014190674, Test Accuracy: 58.48%\n",
      "{i+1}Epoch [5/20], Step [450/600], Loss: 0.9744516015052795, Test Accuracy: 61.96%\n",
      "{i+1}Epoch [5/20], Step [500/600], Loss: 0.982465386390686, Test Accuracy: 60.08%\n",
      "{i+1}Epoch [5/20], Step [550/600], Loss: 0.9190611243247986, Test Accuracy: 65.61%\n",
      "{i+1}Epoch [5/20], Step [600/600], Loss: 0.9557148814201355, Test Accuracy: 61.54%\n",
      "{i+1}Epoch [6/20], Step [50/600], Loss: 1.005184292793274, Test Accuracy: 63.2%\n",
      "{i+1}Epoch [6/20], Step [100/600], Loss: 1.0560535192489624, Test Accuracy: 59.66%\n",
      "{i+1}Epoch [6/20], Step [150/600], Loss: 0.9527655243873596, Test Accuracy: 67.12%\n",
      "{i+1}Epoch [6/20], Step [200/600], Loss: 1.0307163000106812, Test Accuracy: 65.59%\n",
      "{i+1}Epoch [6/20], Step [250/600], Loss: 1.0521725416183472, Test Accuracy: 61.09%\n",
      "{i+1}Epoch [6/20], Step [300/600], Loss: 0.9533100128173828, Test Accuracy: 68.23%\n",
      "{i+1}Epoch [6/20], Step [350/600], Loss: 1.010682463645935, Test Accuracy: 62.55%\n",
      "{i+1}Epoch [6/20], Step [400/600], Loss: 0.9558796882629395, Test Accuracy: 63.65%\n",
      "{i+1}Epoch [6/20], Step [450/600], Loss: 0.881522536277771, Test Accuracy: 66.33%\n",
      "{i+1}Epoch [6/20], Step [500/600], Loss: 0.9352853894233704, Test Accuracy: 63.52%\n",
      "{i+1}Epoch [6/20], Step [550/600], Loss: 0.8733346462249756, Test Accuracy: 69.13%\n",
      "{i+1}Epoch [6/20], Step [600/600], Loss: 0.8574846386909485, Test Accuracy: 66.95%\n",
      "{i+1}Epoch [7/20], Step [50/600], Loss: 0.8614997267723083, Test Accuracy: 69.09%\n",
      "{i+1}Epoch [7/20], Step [100/600], Loss: 1.0426825284957886, Test Accuracy: 67.85%\n",
      "{i+1}Epoch [7/20], Step [150/600], Loss: 0.9252868890762329, Test Accuracy: 70.1%\n",
      "{i+1}Epoch [7/20], Step [200/600], Loss: 0.8619489073753357, Test Accuracy: 69.0%\n",
      "{i+1}Epoch [7/20], Step [250/600], Loss: 0.9218197464942932, Test Accuracy: 66.98%\n",
      "{i+1}Epoch [7/20], Step [300/600], Loss: 0.8133847117424011, Test Accuracy: 70.01%\n",
      "{i+1}Epoch [7/20], Step [350/600], Loss: 0.9441313743591309, Test Accuracy: 68.49%\n",
      "{i+1}Epoch [7/20], Step [400/600], Loss: 0.9303500652313232, Test Accuracy: 63.17%\n",
      "{i+1}Epoch [7/20], Step [450/600], Loss: 1.0878371000289917, Test Accuracy: 65.47%\n",
      "{i+1}Epoch [7/20], Step [500/600], Loss: 0.8254607319831848, Test Accuracy: 73.04%\n",
      "{i+1}Epoch [7/20], Step [550/600], Loss: 0.8670299649238586, Test Accuracy: 69.86%\n",
      "{i+1}Epoch [7/20], Step [600/600], Loss: 0.8369353413581848, Test Accuracy: 67.51%\n",
      "{i+1}Epoch [8/20], Step [50/600], Loss: 0.9631192088127136, Test Accuracy: 69.42%\n",
      "{i+1}Epoch [8/20], Step [100/600], Loss: 0.9087245464324951, Test Accuracy: 70.05%\n",
      "{i+1}Epoch [8/20], Step [150/600], Loss: 0.812156081199646, Test Accuracy: 69.3%\n",
      "{i+1}Epoch [8/20], Step [200/600], Loss: 0.8272576928138733, Test Accuracy: 70.58%\n",
      "{i+1}Epoch [8/20], Step [250/600], Loss: 0.7224428057670593, Test Accuracy: 72.24%\n",
      "{i+1}Epoch [8/20], Step [300/600], Loss: 0.8072443604469299, Test Accuracy: 72.54%\n",
      "{i+1}Epoch [8/20], Step [350/600], Loss: 0.8374106884002686, Test Accuracy: 70.15%\n",
      "{i+1}Epoch [8/20], Step [400/600], Loss: 0.8151801228523254, Test Accuracy: 72.97%\n",
      "{i+1}Epoch [8/20], Step [450/600], Loss: 0.8899609446525574, Test Accuracy: 70.92%\n",
      "{i+1}Epoch [8/20], Step [500/600], Loss: 0.8082526922225952, Test Accuracy: 72.67%\n",
      "{i+1}Epoch [8/20], Step [550/600], Loss: 0.7403872609138489, Test Accuracy: 72.82%\n",
      "{i+1}Epoch [8/20], Step [600/600], Loss: 0.7972575426101685, Test Accuracy: 70.04%\n",
      "{i+1}Epoch [9/20], Step [50/600], Loss: 0.757477343082428, Test Accuracy: 70.41%\n",
      "{i+1}Epoch [9/20], Step [100/600], Loss: 0.7972513437271118, Test Accuracy: 70.76%\n",
      "{i+1}Epoch [9/20], Step [150/600], Loss: 0.8379034399986267, Test Accuracy: 70.04%\n",
      "{i+1}Epoch [9/20], Step [200/600], Loss: 0.7951128482818604, Test Accuracy: 71.24%\n",
      "{i+1}Epoch [9/20], Step [250/600], Loss: 0.8052021265029907, Test Accuracy: 72.53%\n",
      "{i+1}Epoch [9/20], Step [300/600], Loss: 0.7369054555892944, Test Accuracy: 72.25%\n",
      "{i+1}Epoch [9/20], Step [350/600], Loss: 0.7415676712989807, Test Accuracy: 71.49%\n",
      "{i+1}Epoch [9/20], Step [400/600], Loss: 0.8528629541397095, Test Accuracy: 71.99%\n",
      "{i+1}Epoch [9/20], Step [450/600], Loss: 0.7908936142921448, Test Accuracy: 71.92%\n",
      "{i+1}Epoch [9/20], Step [500/600], Loss: 0.7956626415252686, Test Accuracy: 71.6%\n",
      "{i+1}Epoch [9/20], Step [550/600], Loss: 0.7700459361076355, Test Accuracy: 72.25%\n",
      "{i+1}Epoch [9/20], Step [600/600], Loss: 0.8134437799453735, Test Accuracy: 71.39%\n",
      "{i+1}Epoch [10/20], Step [50/600], Loss: 0.7230886220932007, Test Accuracy: 71.1%\n",
      "{i+1}Epoch [10/20], Step [100/600], Loss: 0.6644966006278992, Test Accuracy: 73.78%\n",
      "{i+1}Epoch [10/20], Step [150/600], Loss: 0.8064197301864624, Test Accuracy: 72.91%\n",
      "{i+1}Epoch [10/20], Step [200/600], Loss: 0.741889476776123, Test Accuracy: 73.91%\n",
      "{i+1}Epoch [10/20], Step [250/600], Loss: 0.7033845782279968, Test Accuracy: 73.59%\n",
      "{i+1}Epoch [10/20], Step [300/600], Loss: 0.7410190105438232, Test Accuracy: 72.93%\n",
      "{i+1}Epoch [10/20], Step [350/600], Loss: 0.8368797898292542, Test Accuracy: 70.19%\n",
      "{i+1}Epoch [10/20], Step [400/600], Loss: 0.6849632859230042, Test Accuracy: 72.22%\n",
      "{i+1}Epoch [10/20], Step [450/600], Loss: 0.6890190243721008, Test Accuracy: 74.09%\n",
      "{i+1}Epoch [10/20], Step [500/600], Loss: 0.8303950428962708, Test Accuracy: 71.49%\n",
      "{i+1}Epoch [10/20], Step [550/600], Loss: 0.7629631161689758, Test Accuracy: 71.65%\n",
      "{i+1}Epoch [10/20], Step [600/600], Loss: 0.7852333188056946, Test Accuracy: 72.45%\n",
      "{i+1}Epoch [11/20], Step [50/600], Loss: 0.8006559014320374, Test Accuracy: 69.7%\n",
      "{i+1}Epoch [11/20], Step [100/600], Loss: 0.7540609836578369, Test Accuracy: 73.75%\n",
      "{i+1}Epoch [11/20], Step [150/600], Loss: 0.868278980255127, Test Accuracy: 70.64%\n",
      "{i+1}Epoch [11/20], Step [200/600], Loss: 0.7473567724227905, Test Accuracy: 73.63%\n",
      "{i+1}Epoch [11/20], Step [250/600], Loss: 0.8234778046607971, Test Accuracy: 71.84%\n",
      "{i+1}Epoch [11/20], Step [300/600], Loss: 0.7397946119308472, Test Accuracy: 74.02%\n",
      "{i+1}Epoch [11/20], Step [350/600], Loss: 0.7522392272949219, Test Accuracy: 75.54%\n",
      "{i+1}Epoch [11/20], Step [400/600], Loss: 0.7651944756507874, Test Accuracy: 73.76%\n",
      "{i+1}Epoch [11/20], Step [450/600], Loss: 0.7731055617332458, Test Accuracy: 72.5%\n",
      "{i+1}Epoch [11/20], Step [500/600], Loss: 0.7223258018493652, Test Accuracy: 73.48%\n",
      "{i+1}Epoch [11/20], Step [550/600], Loss: 0.7548670768737793, Test Accuracy: 74.28%\n",
      "{i+1}Epoch [11/20], Step [600/600], Loss: 0.7039059996604919, Test Accuracy: 73.66%\n",
      "{i+1}Epoch [12/20], Step [50/600], Loss: 0.7966981530189514, Test Accuracy: 72.31%\n",
      "{i+1}Epoch [12/20], Step [100/600], Loss: 0.7637705206871033, Test Accuracy: 73.41%\n",
      "{i+1}Epoch [12/20], Step [150/600], Loss: 0.6644768714904785, Test Accuracy: 74.94%\n",
      "{i+1}Epoch [12/20], Step [200/600], Loss: 0.7471282482147217, Test Accuracy: 75.41%\n",
      "{i+1}Epoch [12/20], Step [250/600], Loss: 0.7106167078018188, Test Accuracy: 75.29%\n",
      "{i+1}Epoch [12/20], Step [300/600], Loss: 0.8000661730766296, Test Accuracy: 74.28%\n",
      "{i+1}Epoch [12/20], Step [350/600], Loss: 0.7117498517036438, Test Accuracy: 75.71%\n",
      "{i+1}Epoch [12/20], Step [400/600], Loss: 0.7315614223480225, Test Accuracy: 74.25%\n",
      "{i+1}Epoch [12/20], Step [450/600], Loss: 0.6624428033828735, Test Accuracy: 75.49%\n",
      "{i+1}Epoch [12/20], Step [500/600], Loss: 0.7131958603858948, Test Accuracy: 73.13%\n",
      "{i+1}Epoch [12/20], Step [550/600], Loss: 0.7252060770988464, Test Accuracy: 75.43%\n",
      "{i+1}Epoch [12/20], Step [600/600], Loss: 0.7499806880950928, Test Accuracy: 74.89%\n",
      "{i+1}Epoch [13/20], Step [50/600], Loss: 0.6753133535385132, Test Accuracy: 75.92%\n",
      "{i+1}Epoch [13/20], Step [100/600], Loss: 0.6850834488868713, Test Accuracy: 75.18%\n",
      "{i+1}Epoch [13/20], Step [150/600], Loss: 0.7009975910186768, Test Accuracy: 73.93%\n",
      "{i+1}Epoch [13/20], Step [200/600], Loss: 0.6772987842559814, Test Accuracy: 73.83%\n",
      "{i+1}Epoch [13/20], Step [250/600], Loss: 0.6824885010719299, Test Accuracy: 73.58%\n",
      "{i+1}Epoch [13/20], Step [300/600], Loss: 0.7030684947967529, Test Accuracy: 74.99%\n",
      "{i+1}Epoch [13/20], Step [350/600], Loss: 0.7114410400390625, Test Accuracy: 75.29%\n",
      "{i+1}Epoch [13/20], Step [400/600], Loss: 0.7273723483085632, Test Accuracy: 75.43%\n",
      "{i+1}Epoch [13/20], Step [450/600], Loss: 0.6463207006454468, Test Accuracy: 74.83%\n",
      "{i+1}Epoch [13/20], Step [500/600], Loss: 0.6519064903259277, Test Accuracy: 76.82%\n",
      "{i+1}Epoch [13/20], Step [550/600], Loss: 0.6905013918876648, Test Accuracy: 76.45%\n",
      "{i+1}Epoch [13/20], Step [600/600], Loss: 0.6792249083518982, Test Accuracy: 75.31%\n",
      "{i+1}Epoch [14/20], Step [50/600], Loss: 0.6512581706047058, Test Accuracy: 75.16%\n",
      "{i+1}Epoch [14/20], Step [100/600], Loss: 0.6372116804122925, Test Accuracy: 75.6%\n",
      "{i+1}Epoch [14/20], Step [150/600], Loss: 0.7274085283279419, Test Accuracy: 75.12%\n",
      "{i+1}Epoch [14/20], Step [200/600], Loss: 0.7279806733131409, Test Accuracy: 75.02%\n",
      "{i+1}Epoch [14/20], Step [250/600], Loss: 0.6566479206085205, Test Accuracy: 75.1%\n",
      "{i+1}Epoch [14/20], Step [300/600], Loss: 0.6534788012504578, Test Accuracy: 76.49%\n",
      "{i+1}Epoch [14/20], Step [350/600], Loss: 0.66668301820755, Test Accuracy: 76.73%\n",
      "{i+1}Epoch [14/20], Step [400/600], Loss: 0.6482090950012207, Test Accuracy: 73.87%\n",
      "{i+1}Epoch [14/20], Step [450/600], Loss: 0.6690902709960938, Test Accuracy: 73.56%\n",
      "{i+1}Epoch [14/20], Step [500/600], Loss: 0.665260374546051, Test Accuracy: 76.58%\n",
      "{i+1}Epoch [14/20], Step [550/600], Loss: 0.6554146409034729, Test Accuracy: 74.96%\n",
      "{i+1}Epoch [14/20], Step [600/600], Loss: 0.6434464454650879, Test Accuracy: 77.15%\n",
      "{i+1}Epoch [15/20], Step [50/600], Loss: 0.6671780347824097, Test Accuracy: 74.96%\n",
      "{i+1}Epoch [15/20], Step [100/600], Loss: 0.615842878818512, Test Accuracy: 75.44%\n",
      "{i+1}Epoch [15/20], Step [150/600], Loss: 0.6306849122047424, Test Accuracy: 76.04%\n",
      "{i+1}Epoch [15/20], Step [200/600], Loss: 0.6952129602432251, Test Accuracy: 76.32%\n",
      "{i+1}Epoch [15/20], Step [250/600], Loss: 0.7043744921684265, Test Accuracy: 76.47%\n",
      "{i+1}Epoch [15/20], Step [300/600], Loss: 0.6952860355377197, Test Accuracy: 76.71%\n",
      "{i+1}Epoch [15/20], Step [350/600], Loss: 0.6330433487892151, Test Accuracy: 76.05%\n",
      "{i+1}Epoch [15/20], Step [400/600], Loss: 0.674299955368042, Test Accuracy: 76.33%\n",
      "{i+1}Epoch [15/20], Step [450/600], Loss: 0.6568963527679443, Test Accuracy: 77.03%\n",
      "{i+1}Epoch [15/20], Step [500/600], Loss: 0.6857580542564392, Test Accuracy: 76.64%\n",
      "{i+1}Epoch [15/20], Step [550/600], Loss: 0.6412602066993713, Test Accuracy: 76.69%\n",
      "{i+1}Epoch [15/20], Step [600/600], Loss: 0.7391090989112854, Test Accuracy: 74.02%\n",
      "{i+1}Epoch [16/20], Step [50/600], Loss: 0.646862268447876, Test Accuracy: 76.07%\n",
      "{i+1}Epoch [16/20], Step [100/600], Loss: 0.684828519821167, Test Accuracy: 76.86%\n",
      "{i+1}Epoch [16/20], Step [150/600], Loss: 0.6889585852622986, Test Accuracy: 76.87%\n",
      "{i+1}Epoch [16/20], Step [200/600], Loss: 0.6475231647491455, Test Accuracy: 76.88%\n",
      "{i+1}Epoch [16/20], Step [250/600], Loss: 0.6875888109207153, Test Accuracy: 77.28%\n",
      "{i+1}Epoch [16/20], Step [300/600], Loss: 0.5948625802993774, Test Accuracy: 75.53%\n",
      "{i+1}Epoch [16/20], Step [350/600], Loss: 0.6315337419509888, Test Accuracy: 76.99%\n",
      "{i+1}Epoch [16/20], Step [400/600], Loss: 0.6774219274520874, Test Accuracy: 76.28%\n",
      "{i+1}Epoch [16/20], Step [450/600], Loss: 0.6824945211410522, Test Accuracy: 76.61%\n",
      "{i+1}Epoch [16/20], Step [500/600], Loss: 0.5623412728309631, Test Accuracy: 75.57%\n",
      "{i+1}Epoch [16/20], Step [550/600], Loss: 0.6626465320587158, Test Accuracy: 77.6%\n",
      "{i+1}Epoch [16/20], Step [600/600], Loss: 0.6963317394256592, Test Accuracy: 77.65%\n",
      "{i+1}Epoch [17/20], Step [50/600], Loss: 0.6946568489074707, Test Accuracy: 77.33%\n",
      "{i+1}Epoch [17/20], Step [100/600], Loss: 0.6521593332290649, Test Accuracy: 77.61%\n",
      "{i+1}Epoch [17/20], Step [150/600], Loss: 0.6458757519721985, Test Accuracy: 75.76%\n",
      "{i+1}Epoch [17/20], Step [200/600], Loss: 0.6866815686225891, Test Accuracy: 76.82%\n",
      "{i+1}Epoch [17/20], Step [250/600], Loss: 0.6931127905845642, Test Accuracy: 76.91%\n",
      "{i+1}Epoch [17/20], Step [300/600], Loss: 0.6857621669769287, Test Accuracy: 77.2%\n",
      "{i+1}Epoch [17/20], Step [350/600], Loss: 0.6359343528747559, Test Accuracy: 77.99%\n",
      "{i+1}Epoch [17/20], Step [400/600], Loss: 0.6653898358345032, Test Accuracy: 77.21%\n",
      "{i+1}Epoch [17/20], Step [450/600], Loss: 0.7410340905189514, Test Accuracy: 76.86%\n",
      "{i+1}Epoch [17/20], Step [500/600], Loss: 0.5995731949806213, Test Accuracy: 75.86%\n",
      "{i+1}Epoch [17/20], Step [550/600], Loss: 0.6202980279922485, Test Accuracy: 77.78%\n",
      "{i+1}Epoch [17/20], Step [600/600], Loss: 0.5756241679191589, Test Accuracy: 77.33%\n",
      "{i+1}Epoch [18/20], Step [50/600], Loss: 0.6480917930603027, Test Accuracy: 76.36%\n",
      "{i+1}Epoch [18/20], Step [100/600], Loss: 0.6536604166030884, Test Accuracy: 77.79%\n",
      "{i+1}Epoch [18/20], Step [150/600], Loss: 0.5874933004379272, Test Accuracy: 78.34%\n",
      "{i+1}Epoch [18/20], Step [200/600], Loss: 0.6211475133895874, Test Accuracy: 77.34%\n",
      "{i+1}Epoch [18/20], Step [250/600], Loss: 0.6401304006576538, Test Accuracy: 77.44%\n",
      "{i+1}Epoch [18/20], Step [300/600], Loss: 0.5866810083389282, Test Accuracy: 78.1%\n",
      "{i+1}Epoch [18/20], Step [350/600], Loss: 0.6109203696250916, Test Accuracy: 77.3%\n",
      "{i+1}Epoch [18/20], Step [400/600], Loss: 0.6342772841453552, Test Accuracy: 76.74%\n",
      "{i+1}Epoch [18/20], Step [450/600], Loss: 0.6438593864440918, Test Accuracy: 78.42%\n",
      "{i+1}Epoch [18/20], Step [500/600], Loss: 0.6497228145599365, Test Accuracy: 77.24%\n",
      "{i+1}Epoch [18/20], Step [550/600], Loss: 0.6712300777435303, Test Accuracy: 77.05%\n",
      "{i+1}Epoch [18/20], Step [600/600], Loss: 0.6777917742729187, Test Accuracy: 78.14%\n",
      "{i+1}Epoch [19/20], Step [50/600], Loss: 0.5906224250793457, Test Accuracy: 78.16%\n",
      "{i+1}Epoch [19/20], Step [100/600], Loss: 0.648531436920166, Test Accuracy: 77.88%\n",
      "{i+1}Epoch [19/20], Step [150/600], Loss: 0.6677702069282532, Test Accuracy: 78.16%\n",
      "{i+1}Epoch [19/20], Step [200/600], Loss: 0.6516786813735962, Test Accuracy: 77.97%\n",
      "{i+1}Epoch [19/20], Step [250/600], Loss: 0.6989710927009583, Test Accuracy: 77.17%\n",
      "{i+1}Epoch [19/20], Step [300/600], Loss: 0.6171979308128357, Test Accuracy: 77.93%\n",
      "{i+1}Epoch [19/20], Step [350/600], Loss: 0.6077282428741455, Test Accuracy: 78.43%\n",
      "{i+1}Epoch [19/20], Step [400/600], Loss: 0.6503224968910217, Test Accuracy: 75.38%\n",
      "{i+1}Epoch [19/20], Step [450/600], Loss: 0.6314346194267273, Test Accuracy: 78.08%\n",
      "{i+1}Epoch [19/20], Step [500/600], Loss: 0.6552764177322388, Test Accuracy: 77.17%\n",
      "{i+1}Epoch [19/20], Step [550/600], Loss: 0.6408101916313171, Test Accuracy: 78.5%\n",
      "{i+1}Epoch [19/20], Step [600/600], Loss: 0.6508870720863342, Test Accuracy: 78.24%\n",
      "{i+1}Epoch [20/20], Step [50/600], Loss: 0.6086194515228271, Test Accuracy: 78.84%\n",
      "{i+1}Epoch [20/20], Step [100/600], Loss: 0.6085385680198669, Test Accuracy: 78.36%\n",
      "{i+1}Epoch [20/20], Step [150/600], Loss: 0.6433166265487671, Test Accuracy: 78.11%\n",
      "{i+1}Epoch [20/20], Step [200/600], Loss: 0.5859501957893372, Test Accuracy: 78.63%\n",
      "{i+1}Epoch [20/20], Step [250/600], Loss: 0.6153578758239746, Test Accuracy: 78.54%\n",
      "{i+1}Epoch [20/20], Step [300/600], Loss: 0.6374136209487915, Test Accuracy: 77.88%\n",
      "{i+1}Epoch [20/20], Step [350/600], Loss: 0.5907391905784607, Test Accuracy: 78.43%\n",
      "{i+1}Epoch [20/20], Step [400/600], Loss: 0.6037267446517944, Test Accuracy: 78.24%\n",
      "{i+1}Epoch [20/20], Step [450/600], Loss: 0.6286129951477051, Test Accuracy: 78.1%\n",
      "{i+1}Epoch [20/20], Step [500/600], Loss: 0.6274436116218567, Test Accuracy: 77.21%\n",
      "{i+1}Epoch [20/20], Step [550/600], Loss: 0.6481292247772217, Test Accuracy: 78.1%\n",
      "{i+1}Epoch [20/20], Step [600/600], Loss: 0.6338186860084534, Test Accuracy: 78.52%\n",
      "20\n",
      "Using cuda device\n",
      "Tiny_convnet(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "{i+1}Epoch [1/20], Step [50/600], Loss: 2.502418279647827, Test Accuracy: 12.07%\n",
      "{i+1}Epoch [1/20], Step [100/600], Loss: 2.2816948890686035, Test Accuracy: 9.17%\n",
      "{i+1}Epoch [1/20], Step [150/600], Loss: 2.400020122528076, Test Accuracy: 14.48%\n",
      "{i+1}Epoch [1/20], Step [200/600], Loss: 2.3278610706329346, Test Accuracy: 9.67%\n",
      "{i+1}Epoch [1/20], Step [250/600], Loss: 2.3398163318634033, Test Accuracy: 11.85%\n",
      "{i+1}Epoch [1/20], Step [300/600], Loss: 2.200855016708374, Test Accuracy: 14.64%\n",
      "{i+1}Epoch [1/20], Step [350/600], Loss: 2.2937164306640625, Test Accuracy: 13.62%\n",
      "{i+1}Epoch [1/20], Step [400/600], Loss: 2.208353042602539, Test Accuracy: 18.14%\n",
      "{i+1}Epoch [1/20], Step [450/600], Loss: 2.2330141067504883, Test Accuracy: 19.58%\n",
      "{i+1}Epoch [1/20], Step [500/600], Loss: 2.2193331718444824, Test Accuracy: 22.51%\n",
      "{i+1}Epoch [1/20], Step [550/600], Loss: 2.128730535507202, Test Accuracy: 23.33%\n",
      "{i+1}Epoch [1/20], Step [600/600], Loss: 2.202942371368408, Test Accuracy: 20.62%\n",
      "{i+1}Epoch [2/20], Step [50/600], Loss: 2.065812349319458, Test Accuracy: 22.56%\n",
      "{i+1}Epoch [2/20], Step [100/600], Loss: 2.0766489505767822, Test Accuracy: 26.72%\n",
      "{i+1}Epoch [2/20], Step [150/600], Loss: 2.074481725692749, Test Accuracy: 31.83%\n",
      "{i+1}Epoch [2/20], Step [200/600], Loss: 1.9540382623672485, Test Accuracy: 26.09%\n",
      "{i+1}Epoch [2/20], Step [250/600], Loss: 2.0301926136016846, Test Accuracy: 32.44%\n",
      "{i+1}Epoch [2/20], Step [300/600], Loss: 1.8114919662475586, Test Accuracy: 35.03%\n",
      "{i+1}Epoch [2/20], Step [350/600], Loss: 1.7901500463485718, Test Accuracy: 34.81%\n",
      "{i+1}Epoch [2/20], Step [400/600], Loss: 1.7460260391235352, Test Accuracy: 44.14%\n",
      "{i+1}Epoch [2/20], Step [450/600], Loss: 1.6497960090637207, Test Accuracy: 43.53%\n",
      "{i+1}Epoch [2/20], Step [500/600], Loss: 1.5088882446289062, Test Accuracy: 39.31%\n",
      "{i+1}Epoch [2/20], Step [550/600], Loss: 1.5484626293182373, Test Accuracy: 46.09%\n",
      "{i+1}Epoch [2/20], Step [600/600], Loss: 1.5852558612823486, Test Accuracy: 37.72%\n",
      "{i+1}Epoch [3/20], Step [50/600], Loss: 1.3997176885604858, Test Accuracy: 48.95%\n",
      "{i+1}Epoch [3/20], Step [100/600], Loss: 1.3786731958389282, Test Accuracy: 48.88%\n",
      "{i+1}Epoch [3/20], Step [150/600], Loss: 1.5231648683547974, Test Accuracy: 43.14%\n",
      "{i+1}Epoch [3/20], Step [200/600], Loss: 1.5388717651367188, Test Accuracy: 43.23%\n",
      "{i+1}Epoch [3/20], Step [250/600], Loss: 1.3604800701141357, Test Accuracy: 47.33%\n",
      "{i+1}Epoch [3/20], Step [300/600], Loss: 1.3154503107070923, Test Accuracy: 49.29%\n",
      "{i+1}Epoch [3/20], Step [350/600], Loss: 1.1318186521530151, Test Accuracy: 54.52%\n",
      "{i+1}Epoch [3/20], Step [400/600], Loss: 1.1468722820281982, Test Accuracy: 56.62%\n",
      "{i+1}Epoch [3/20], Step [450/600], Loss: 1.262128233909607, Test Accuracy: 51.22%\n",
      "{i+1}Epoch [3/20], Step [500/600], Loss: 1.3184292316436768, Test Accuracy: 55.12%\n",
      "{i+1}Epoch [3/20], Step [550/600], Loss: 1.25071120262146, Test Accuracy: 52.23%\n",
      "{i+1}Epoch [3/20], Step [600/600], Loss: 1.0910295248031616, Test Accuracy: 59.83%\n",
      "{i+1}Epoch [4/20], Step [50/600], Loss: 1.131557822227478, Test Accuracy: 53.15%\n",
      "{i+1}Epoch [4/20], Step [100/600], Loss: 1.2193626165390015, Test Accuracy: 56.5%\n",
      "{i+1}Epoch [4/20], Step [150/600], Loss: 1.112756371498108, Test Accuracy: 60.95%\n",
      "{i+1}Epoch [4/20], Step [200/600], Loss: 1.0565731525421143, Test Accuracy: 62.46%\n",
      "{i+1}Epoch [4/20], Step [250/600], Loss: 1.1887829303741455, Test Accuracy: 56.4%\n",
      "{i+1}Epoch [4/20], Step [300/600], Loss: 1.0531936883926392, Test Accuracy: 60.06%\n",
      "{i+1}Epoch [4/20], Step [350/600], Loss: 1.0019298791885376, Test Accuracy: 59.4%\n",
      "{i+1}Epoch [4/20], Step [400/600], Loss: 1.1008880138397217, Test Accuracy: 55.06%\n",
      "{i+1}Epoch [4/20], Step [450/600], Loss: 0.9461383819580078, Test Accuracy: 61.49%\n",
      "{i+1}Epoch [4/20], Step [500/600], Loss: 1.0906388759613037, Test Accuracy: 58.6%\n",
      "{i+1}Epoch [4/20], Step [550/600], Loss: 0.9512017965316772, Test Accuracy: 62.72%\n",
      "{i+1}Epoch [4/20], Step [600/600], Loss: 1.0339970588684082, Test Accuracy: 64.72%\n",
      "{i+1}Epoch [5/20], Step [50/600], Loss: 0.9525351524353027, Test Accuracy: 65.3%\n",
      "{i+1}Epoch [5/20], Step [100/600], Loss: 0.8675953149795532, Test Accuracy: 66.03%\n",
      "{i+1}Epoch [5/20], Step [150/600], Loss: 0.9299014210700989, Test Accuracy: 62.42%\n",
      "{i+1}Epoch [5/20], Step [200/600], Loss: 0.944403886795044, Test Accuracy: 66.69%\n",
      "{i+1}Epoch [5/20], Step [250/600], Loss: 0.9106208682060242, Test Accuracy: 67.87%\n",
      "{i+1}Epoch [5/20], Step [300/600], Loss: 0.9551124572753906, Test Accuracy: 60.21%\n",
      "{i+1}Epoch [5/20], Step [350/600], Loss: 0.8013314008712769, Test Accuracy: 69.54%\n",
      "{i+1}Epoch [5/20], Step [400/600], Loss: 0.9586688876152039, Test Accuracy: 64.98%\n",
      "{i+1}Epoch [5/20], Step [450/600], Loss: 0.924193263053894, Test Accuracy: 64.41%\n",
      "{i+1}Epoch [5/20], Step [500/600], Loss: 0.9426578283309937, Test Accuracy: 63.7%\n",
      "{i+1}Epoch [5/20], Step [550/600], Loss: 0.9042835831642151, Test Accuracy: 64.75%\n",
      "{i+1}Epoch [5/20], Step [600/600], Loss: 0.8617709875106812, Test Accuracy: 66.68%\n",
      "{i+1}Epoch [6/20], Step [50/600], Loss: 0.9567921161651611, Test Accuracy: 63.95%\n",
      "{i+1}Epoch [6/20], Step [100/600], Loss: 0.8431867361068726, Test Accuracy: 68.07%\n",
      "{i+1}Epoch [6/20], Step [150/600], Loss: 0.8964933156967163, Test Accuracy: 67.57%\n",
      "{i+1}Epoch [6/20], Step [200/600], Loss: 0.930055558681488, Test Accuracy: 65.31%\n",
      "{i+1}Epoch [6/20], Step [250/600], Loss: 0.8455579876899719, Test Accuracy: 68.98%\n",
      "{i+1}Epoch [6/20], Step [300/600], Loss: 0.8648555874824524, Test Accuracy: 69.47%\n",
      "{i+1}Epoch [6/20], Step [350/600], Loss: 0.7432137131690979, Test Accuracy: 73.43%\n",
      "{i+1}Epoch [6/20], Step [400/600], Loss: 0.7763651013374329, Test Accuracy: 68.51%\n",
      "{i+1}Epoch [6/20], Step [450/600], Loss: 0.7610434889793396, Test Accuracy: 71.82%\n",
      "{i+1}Epoch [6/20], Step [500/600], Loss: 0.7920870184898376, Test Accuracy: 70.86%\n",
      "{i+1}Epoch [6/20], Step [550/600], Loss: 0.8903864026069641, Test Accuracy: 71.5%\n",
      "{i+1}Epoch [6/20], Step [600/600], Loss: 0.7645268440246582, Test Accuracy: 72.5%\n",
      "{i+1}Epoch [7/20], Step [50/600], Loss: 0.8023556470870972, Test Accuracy: 67.72%\n",
      "{i+1}Epoch [7/20], Step [100/600], Loss: 0.8162152767181396, Test Accuracy: 68.62%\n",
      "{i+1}Epoch [7/20], Step [150/600], Loss: 0.8202871084213257, Test Accuracy: 71.65%\n",
      "{i+1}Epoch [7/20], Step [200/600], Loss: 0.8199041485786438, Test Accuracy: 70.5%\n",
      "{i+1}Epoch [7/20], Step [250/600], Loss: 0.8793761730194092, Test Accuracy: 69.09%\n",
      "{i+1}Epoch [7/20], Step [300/600], Loss: 0.8187762498855591, Test Accuracy: 71.91%\n",
      "{i+1}Epoch [7/20], Step [350/600], Loss: 0.7700488567352295, Test Accuracy: 71.98%\n",
      "{i+1}Epoch [7/20], Step [400/600], Loss: 0.7399395108222961, Test Accuracy: 71.08%\n",
      "{i+1}Epoch [7/20], Step [450/600], Loss: 0.8262993097305298, Test Accuracy: 70.58%\n",
      "{i+1}Epoch [7/20], Step [500/600], Loss: 0.782488226890564, Test Accuracy: 72.57%\n",
      "{i+1}Epoch [7/20], Step [550/600], Loss: 0.7978471517562866, Test Accuracy: 70.46%\n",
      "{i+1}Epoch [7/20], Step [600/600], Loss: 0.7245104312896729, Test Accuracy: 73.84%\n",
      "{i+1}Epoch [8/20], Step [50/600], Loss: 0.7704638838768005, Test Accuracy: 72.31%\n",
      "{i+1}Epoch [8/20], Step [100/600], Loss: 0.7848613858222961, Test Accuracy: 73.61%\n",
      "{i+1}Epoch [8/20], Step [150/600], Loss: 0.748309850692749, Test Accuracy: 72.69%\n",
      "{i+1}Epoch [8/20], Step [200/600], Loss: 0.708355188369751, Test Accuracy: 73.16%\n",
      "{i+1}Epoch [8/20], Step [250/600], Loss: 0.7188712358474731, Test Accuracy: 73.24%\n",
      "{i+1}Epoch [8/20], Step [300/600], Loss: 0.7290745377540588, Test Accuracy: 73.22%\n",
      "{i+1}Epoch [8/20], Step [350/600], Loss: 0.7224022150039673, Test Accuracy: 70.88%\n",
      "{i+1}Epoch [8/20], Step [400/600], Loss: 0.7054429650306702, Test Accuracy: 73.65%\n",
      "{i+1}Epoch [8/20], Step [450/600], Loss: 0.7926572561264038, Test Accuracy: 72.32%\n",
      "{i+1}Epoch [8/20], Step [500/600], Loss: 0.692781388759613, Test Accuracy: 72.3%\n",
      "{i+1}Epoch [8/20], Step [550/600], Loss: 0.7091230750083923, Test Accuracy: 72.64%\n",
      "{i+1}Epoch [8/20], Step [600/600], Loss: 0.6930353045463562, Test Accuracy: 74.65%\n",
      "{i+1}Epoch [9/20], Step [50/600], Loss: 0.6685366630554199, Test Accuracy: 75.04%\n",
      "{i+1}Epoch [9/20], Step [100/600], Loss: 0.7711699604988098, Test Accuracy: 75.16%\n",
      "{i+1}Epoch [9/20], Step [150/600], Loss: 0.6824100613594055, Test Accuracy: 74.09%\n",
      "{i+1}Epoch [9/20], Step [200/600], Loss: 0.718578577041626, Test Accuracy: 74.64%\n",
      "{i+1}Epoch [9/20], Step [250/600], Loss: 0.7477660179138184, Test Accuracy: 74.26%\n",
      "{i+1}Epoch [9/20], Step [300/600], Loss: 0.7181533575057983, Test Accuracy: 74.01%\n",
      "{i+1}Epoch [9/20], Step [350/600], Loss: 0.7113285064697266, Test Accuracy: 72.06%\n",
      "{i+1}Epoch [9/20], Step [400/600], Loss: 0.6271682977676392, Test Accuracy: 74.05%\n",
      "{i+1}Epoch [9/20], Step [450/600], Loss: 0.651686429977417, Test Accuracy: 76.33%\n",
      "{i+1}Epoch [9/20], Step [500/600], Loss: 0.611873984336853, Test Accuracy: 76.15%\n",
      "{i+1}Epoch [9/20], Step [550/600], Loss: 0.7657011151313782, Test Accuracy: 74.5%\n",
      "{i+1}Epoch [9/20], Step [600/600], Loss: 0.7021027207374573, Test Accuracy: 76.21%\n",
      "{i+1}Epoch [10/20], Step [50/600], Loss: 0.6673827171325684, Test Accuracy: 76.08%\n",
      "{i+1}Epoch [10/20], Step [100/600], Loss: 0.5966256856918335, Test Accuracy: 75.82%\n",
      "{i+1}Epoch [10/20], Step [150/600], Loss: 0.6709088683128357, Test Accuracy: 76.44%\n",
      "{i+1}Epoch [10/20], Step [200/600], Loss: 0.6256600022315979, Test Accuracy: 75.26%\n",
      "{i+1}Epoch [10/20], Step [250/600], Loss: 0.6437249779701233, Test Accuracy: 75.33%\n",
      "{i+1}Epoch [10/20], Step [300/600], Loss: 0.6307241916656494, Test Accuracy: 74.55%\n",
      "{i+1}Epoch [10/20], Step [350/600], Loss: 0.6442117094993591, Test Accuracy: 74.17%\n",
      "{i+1}Epoch [10/20], Step [400/600], Loss: 0.611082136631012, Test Accuracy: 76.68%\n",
      "{i+1}Epoch [10/20], Step [450/600], Loss: 0.7204969525337219, Test Accuracy: 75.44%\n",
      "{i+1}Epoch [10/20], Step [500/600], Loss: 0.6442110538482666, Test Accuracy: 75.89%\n",
      "{i+1}Epoch [10/20], Step [550/600], Loss: 0.7151472568511963, Test Accuracy: 75.76%\n",
      "{i+1}Epoch [10/20], Step [600/600], Loss: 0.7265387177467346, Test Accuracy: 75.07%\n",
      "{i+1}Epoch [11/20], Step [50/600], Loss: 0.6334821581840515, Test Accuracy: 77.3%\n",
      "{i+1}Epoch [11/20], Step [100/600], Loss: 0.5943114757537842, Test Accuracy: 76.5%\n",
      "{i+1}Epoch [11/20], Step [150/600], Loss: 0.6432853937149048, Test Accuracy: 75.33%\n",
      "{i+1}Epoch [11/20], Step [200/600], Loss: 0.6531750559806824, Test Accuracy: 76.56%\n",
      "{i+1}Epoch [11/20], Step [250/600], Loss: 0.6086962223052979, Test Accuracy: 76.94%\n",
      "{i+1}Epoch [11/20], Step [300/600], Loss: 0.664029598236084, Test Accuracy: 76.72%\n",
      "{i+1}Epoch [11/20], Step [350/600], Loss: 0.6585713028907776, Test Accuracy: 76.11%\n",
      "{i+1}Epoch [11/20], Step [400/600], Loss: 0.6392131447792053, Test Accuracy: 74.16%\n",
      "{i+1}Epoch [11/20], Step [450/600], Loss: 0.580449640750885, Test Accuracy: 75.32%\n",
      "{i+1}Epoch [11/20], Step [500/600], Loss: 0.5799812078475952, Test Accuracy: 76.09%\n",
      "{i+1}Epoch [11/20], Step [550/600], Loss: 0.6248241066932678, Test Accuracy: 77.18%\n",
      "{i+1}Epoch [11/20], Step [600/600], Loss: 0.574448823928833, Test Accuracy: 78.07%\n",
      "{i+1}Epoch [12/20], Step [50/600], Loss: 0.646318256855011, Test Accuracy: 76.19%\n",
      "{i+1}Epoch [12/20], Step [100/600], Loss: 0.6389721632003784, Test Accuracy: 77.23%\n",
      "{i+1}Epoch [12/20], Step [150/600], Loss: 0.6540548801422119, Test Accuracy: 76.75%\n",
      "{i+1}Epoch [12/20], Step [200/600], Loss: 0.6042513847351074, Test Accuracy: 75.7%\n",
      "{i+1}Epoch [12/20], Step [250/600], Loss: 0.6927204728126526, Test Accuracy: 75.92%\n",
      "{i+1}Epoch [12/20], Step [300/600], Loss: 0.5749056339263916, Test Accuracy: 76.2%\n",
      "{i+1}Epoch [12/20], Step [350/600], Loss: 0.584438145160675, Test Accuracy: 75.31%\n",
      "{i+1}Epoch [12/20], Step [400/600], Loss: 0.5512328743934631, Test Accuracy: 77.51%\n",
      "{i+1}Epoch [12/20], Step [450/600], Loss: 0.5673750042915344, Test Accuracy: 77.44%\n",
      "{i+1}Epoch [12/20], Step [500/600], Loss: 0.6350430846214294, Test Accuracy: 77.11%\n",
      "{i+1}Epoch [12/20], Step [550/600], Loss: 0.5844983458518982, Test Accuracy: 76.77%\n",
      "{i+1}Epoch [12/20], Step [600/600], Loss: 0.6261535882949829, Test Accuracy: 77.82%\n",
      "{i+1}Epoch [13/20], Step [50/600], Loss: 0.5910763144493103, Test Accuracy: 78.01%\n",
      "{i+1}Epoch [13/20], Step [100/600], Loss: 0.6704803705215454, Test Accuracy: 75.21%\n",
      "{i+1}Epoch [13/20], Step [150/600], Loss: 0.6186347007751465, Test Accuracy: 77.43%\n",
      "{i+1}Epoch [13/20], Step [200/600], Loss: 0.625091552734375, Test Accuracy: 77.92%\n",
      "{i+1}Epoch [13/20], Step [250/600], Loss: 0.6325535774230957, Test Accuracy: 78.03%\n",
      "{i+1}Epoch [13/20], Step [300/600], Loss: 0.599588930606842, Test Accuracy: 79.26%\n",
      "{i+1}Epoch [13/20], Step [350/600], Loss: 0.6208310127258301, Test Accuracy: 76.25%\n",
      "{i+1}Epoch [13/20], Step [400/600], Loss: 0.6197717785835266, Test Accuracy: 77.27%\n",
      "{i+1}Epoch [13/20], Step [450/600], Loss: 0.5849940776824951, Test Accuracy: 77.5%\n",
      "{i+1}Epoch [13/20], Step [500/600], Loss: 0.6176755428314209, Test Accuracy: 77.58%\n",
      "{i+1}Epoch [13/20], Step [550/600], Loss: 0.5656888484954834, Test Accuracy: 78.48%\n",
      "{i+1}Epoch [13/20], Step [600/600], Loss: 0.5820209383964539, Test Accuracy: 77.88%\n",
      "{i+1}Epoch [14/20], Step [50/600], Loss: 0.5736762881278992, Test Accuracy: 78.05%\n",
      "{i+1}Epoch [14/20], Step [100/600], Loss: 0.5964218378067017, Test Accuracy: 78.92%\n",
      "{i+1}Epoch [14/20], Step [150/600], Loss: 0.599879801273346, Test Accuracy: 78.11%\n",
      "{i+1}Epoch [14/20], Step [200/600], Loss: 0.5918287038803101, Test Accuracy: 78.83%\n",
      "{i+1}Epoch [14/20], Step [250/600], Loss: 0.5715327858924866, Test Accuracy: 78.67%\n",
      "{i+1}Epoch [14/20], Step [300/600], Loss: 0.5652599334716797, Test Accuracy: 78.47%\n",
      "{i+1}Epoch [14/20], Step [350/600], Loss: 0.5926182866096497, Test Accuracy: 78.82%\n",
      "{i+1}Epoch [14/20], Step [400/600], Loss: 0.5897006392478943, Test Accuracy: 78.7%\n",
      "{i+1}Epoch [14/20], Step [450/600], Loss: 0.5542896389961243, Test Accuracy: 76.68%\n",
      "{i+1}Epoch [14/20], Step [500/600], Loss: 0.619327187538147, Test Accuracy: 78.6%\n",
      "{i+1}Epoch [14/20], Step [550/600], Loss: 0.5623872876167297, Test Accuracy: 78.76%\n",
      "{i+1}Epoch [14/20], Step [600/600], Loss: 0.599241316318512, Test Accuracy: 78.72%\n",
      "{i+1}Epoch [15/20], Step [50/600], Loss: 0.5694370865821838, Test Accuracy: 78.19%\n",
      "{i+1}Epoch [15/20], Step [100/600], Loss: 0.6023866534233093, Test Accuracy: 77.63%\n",
      "{i+1}Epoch [15/20], Step [150/600], Loss: 0.6155892014503479, Test Accuracy: 78.12%\n",
      "{i+1}Epoch [15/20], Step [200/600], Loss: 0.5666343569755554, Test Accuracy: 78.42%\n",
      "{i+1}Epoch [15/20], Step [250/600], Loss: 0.5911683440208435, Test Accuracy: 79.01%\n",
      "{i+1}Epoch [15/20], Step [300/600], Loss: 0.5643872022628784, Test Accuracy: 78.32%\n",
      "{i+1}Epoch [15/20], Step [350/600], Loss: 0.5865182876586914, Test Accuracy: 79.25%\n",
      "{i+1}Epoch [15/20], Step [400/600], Loss: 0.526533842086792, Test Accuracy: 79.67%\n",
      "{i+1}Epoch [15/20], Step [450/600], Loss: 0.5805563926696777, Test Accuracy: 79.46%\n",
      "{i+1}Epoch [15/20], Step [500/600], Loss: 0.5768852233886719, Test Accuracy: 78.2%\n",
      "{i+1}Epoch [15/20], Step [550/600], Loss: 0.5479146838188171, Test Accuracy: 77.49%\n",
      "{i+1}Epoch [15/20], Step [600/600], Loss: 0.5897777676582336, Test Accuracy: 78.99%\n",
      "{i+1}Epoch [16/20], Step [50/600], Loss: 0.5685858726501465, Test Accuracy: 78.14%\n",
      "{i+1}Epoch [16/20], Step [100/600], Loss: 0.5403605103492737, Test Accuracy: 79.83%\n",
      "{i+1}Epoch [16/20], Step [150/600], Loss: 0.5868931412696838, Test Accuracy: 78.62%\n",
      "{i+1}Epoch [16/20], Step [200/600], Loss: 0.570692241191864, Test Accuracy: 80.14%\n",
      "{i+1}Epoch [16/20], Step [250/600], Loss: 0.5500530004501343, Test Accuracy: 79.26%\n",
      "{i+1}Epoch [16/20], Step [300/600], Loss: 0.5507738590240479, Test Accuracy: 79.16%\n",
      "{i+1}Epoch [16/20], Step [350/600], Loss: 0.5289877653121948, Test Accuracy: 78.91%\n",
      "{i+1}Epoch [16/20], Step [400/600], Loss: 0.5177837014198303, Test Accuracy: 78.95%\n",
      "{i+1}Epoch [16/20], Step [450/600], Loss: 0.5207314491271973, Test Accuracy: 80.14%\n",
      "{i+1}Epoch [16/20], Step [500/600], Loss: 0.568703830242157, Test Accuracy: 79.0%\n",
      "{i+1}Epoch [16/20], Step [550/600], Loss: 0.5732138156890869, Test Accuracy: 79.55%\n",
      "{i+1}Epoch [16/20], Step [600/600], Loss: 0.6063263416290283, Test Accuracy: 79.75%\n",
      "{i+1}Epoch [17/20], Step [50/600], Loss: 0.5105888247489929, Test Accuracy: 79.55%\n",
      "{i+1}Epoch [17/20], Step [100/600], Loss: 0.5287147760391235, Test Accuracy: 78.89%\n",
      "{i+1}Epoch [17/20], Step [150/600], Loss: 0.5770953893661499, Test Accuracy: 80.17%\n",
      "{i+1}Epoch [17/20], Step [200/600], Loss: 0.5390163660049438, Test Accuracy: 79.78%\n",
      "{i+1}Epoch [17/20], Step [250/600], Loss: 0.510647177696228, Test Accuracy: 78.67%\n",
      "{i+1}Epoch [17/20], Step [300/600], Loss: 0.5094387531280518, Test Accuracy: 79.7%\n",
      "{i+1}Epoch [17/20], Step [350/600], Loss: 0.5011730194091797, Test Accuracy: 79.65%\n",
      "{i+1}Epoch [17/20], Step [400/600], Loss: 0.6284275650978088, Test Accuracy: 78.69%\n",
      "{i+1}Epoch [17/20], Step [450/600], Loss: 0.5360063314437866, Test Accuracy: 80.13%\n",
      "{i+1}Epoch [17/20], Step [500/600], Loss: 0.49899280071258545, Test Accuracy: 79.89%\n",
      "{i+1}Epoch [17/20], Step [550/600], Loss: 0.5045872330665588, Test Accuracy: 79.43%\n",
      "{i+1}Epoch [17/20], Step [600/600], Loss: 0.5452249050140381, Test Accuracy: 79.32%\n",
      "{i+1}Epoch [18/20], Step [50/600], Loss: 0.5477997064590454, Test Accuracy: 79.89%\n",
      "{i+1}Epoch [18/20], Step [100/600], Loss: 0.5312657356262207, Test Accuracy: 80.49%\n",
      "{i+1}Epoch [18/20], Step [150/600], Loss: 0.5362439155578613, Test Accuracy: 80.19%\n",
      "{i+1}Epoch [18/20], Step [200/600], Loss: 0.593437135219574, Test Accuracy: 80.54%\n",
      "{i+1}Epoch [18/20], Step [250/600], Loss: 0.5579192638397217, Test Accuracy: 80.57%\n",
      "{i+1}Epoch [18/20], Step [300/600], Loss: 0.5268054604530334, Test Accuracy: 80.68%\n",
      "{i+1}Epoch [18/20], Step [350/600], Loss: 0.5460211038589478, Test Accuracy: 80.42%\n",
      "{i+1}Epoch [18/20], Step [400/600], Loss: 0.5668231844902039, Test Accuracy: 79.6%\n",
      "{i+1}Epoch [18/20], Step [450/600], Loss: 0.514866054058075, Test Accuracy: 80.5%\n",
      "{i+1}Epoch [18/20], Step [500/600], Loss: 0.5329007506370544, Test Accuracy: 79.73%\n",
      "{i+1}Epoch [18/20], Step [550/600], Loss: 0.5626621246337891, Test Accuracy: 80.0%\n",
      "{i+1}Epoch [18/20], Step [600/600], Loss: 0.5224516987800598, Test Accuracy: 80.44%\n",
      "{i+1}Epoch [19/20], Step [50/600], Loss: 0.5050615072250366, Test Accuracy: 80.67%\n",
      "{i+1}Epoch [19/20], Step [100/600], Loss: 0.5188944339752197, Test Accuracy: 80.72%\n",
      "{i+1}Epoch [19/20], Step [150/600], Loss: 0.549039363861084, Test Accuracy: 80.18%\n",
      "{i+1}Epoch [19/20], Step [200/600], Loss: 0.5075100064277649, Test Accuracy: 80.23%\n",
      "{i+1}Epoch [19/20], Step [250/600], Loss: 0.5297240614891052, Test Accuracy: 80.37%\n",
      "{i+1}Epoch [19/20], Step [300/600], Loss: 0.4987333416938782, Test Accuracy: 79.6%\n",
      "{i+1}Epoch [19/20], Step [350/600], Loss: 0.5478183627128601, Test Accuracy: 80.7%\n",
      "{i+1}Epoch [19/20], Step [400/600], Loss: 0.5383355617523193, Test Accuracy: 78.37%\n",
      "{i+1}Epoch [19/20], Step [450/600], Loss: 0.49042826890945435, Test Accuracy: 79.99%\n",
      "{i+1}Epoch [19/20], Step [500/600], Loss: 0.514028012752533, Test Accuracy: 80.72%\n",
      "{i+1}Epoch [19/20], Step [550/600], Loss: 0.5665128827095032, Test Accuracy: 80.21%\n",
      "{i+1}Epoch [19/20], Step [600/600], Loss: 0.5522186756134033, Test Accuracy: 80.54%\n",
      "{i+1}Epoch [20/20], Step [50/600], Loss: 0.555616557598114, Test Accuracy: 80.7%\n",
      "{i+1}Epoch [20/20], Step [100/600], Loss: 0.5438129901885986, Test Accuracy: 80.44%\n",
      "{i+1}Epoch [20/20], Step [150/600], Loss: 0.5549623370170593, Test Accuracy: 80.31%\n",
      "{i+1}Epoch [20/20], Step [200/600], Loss: 0.4902169406414032, Test Accuracy: 80.54%\n",
      "{i+1}Epoch [20/20], Step [250/600], Loss: 0.5213994383811951, Test Accuracy: 80.68%\n",
      "{i+1}Epoch [20/20], Step [300/600], Loss: 0.5265734195709229, Test Accuracy: 80.24%\n",
      "{i+1}Epoch [20/20], Step [350/600], Loss: 0.5053316354751587, Test Accuracy: 80.55%\n",
      "{i+1}Epoch [20/20], Step [400/600], Loss: 0.49486204981803894, Test Accuracy: 80.84%\n",
      "{i+1}Epoch [20/20], Step [450/600], Loss: 0.5504466891288757, Test Accuracy: 80.7%\n",
      "{i+1}Epoch [20/20], Step [500/600], Loss: 0.5449681878089905, Test Accuracy: 80.07%\n",
      "{i+1}Epoch [20/20], Step [550/600], Loss: 0.5093672871589661, Test Accuracy: 79.92%\n",
      "{i+1}Epoch [20/20], Step [600/600], Loss: 0.5299504995346069, Test Accuracy: 80.93%\n",
      "50\n",
      "Using cuda device\n",
      "Tiny_convnet(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "{i+1}Epoch [1/20], Step [50/600], Loss: 2.266645908355713, Test Accuracy: 16.82%\n",
      "{i+1}Epoch [1/20], Step [100/600], Loss: 2.2592618465423584, Test Accuracy: 24.89%\n",
      "{i+1}Epoch [1/20], Step [150/600], Loss: 2.2354736328125, Test Accuracy: 24.47%\n",
      "{i+1}Epoch [1/20], Step [200/600], Loss: 2.2693796157836914, Test Accuracy: 20.2%\n",
      "{i+1}Epoch [1/20], Step [250/600], Loss: 2.071317195892334, Test Accuracy: 23.57%\n",
      "{i+1}Epoch [1/20], Step [300/600], Loss: 2.0827488899230957, Test Accuracy: 25.23%\n",
      "{i+1}Epoch [1/20], Step [350/600], Loss: 1.7364871501922607, Test Accuracy: 41.36%\n",
      "{i+1}Epoch [1/20], Step [400/600], Loss: 1.9481379985809326, Test Accuracy: 31.88%\n",
      "{i+1}Epoch [1/20], Step [450/600], Loss: 1.5311651229858398, Test Accuracy: 40.23%\n",
      "{i+1}Epoch [1/20], Step [500/600], Loss: 1.5265707969665527, Test Accuracy: 47.96%\n",
      "{i+1}Epoch [1/20], Step [550/600], Loss: 1.476815938949585, Test Accuracy: 46.62%\n",
      "{i+1}Epoch [1/20], Step [600/600], Loss: 1.4096978902816772, Test Accuracy: 45.75%\n",
      "{i+1}Epoch [2/20], Step [50/600], Loss: 1.2213398218154907, Test Accuracy: 51.33%\n",
      "{i+1}Epoch [2/20], Step [100/600], Loss: 1.1968696117401123, Test Accuracy: 56.32%\n",
      "{i+1}Epoch [2/20], Step [150/600], Loss: 1.1244810819625854, Test Accuracy: 57.76%\n",
      "{i+1}Epoch [2/20], Step [200/600], Loss: 1.101402997970581, Test Accuracy: 62.15%\n",
      "{i+1}Epoch [2/20], Step [250/600], Loss: 1.0255699157714844, Test Accuracy: 65.38%\n",
      "{i+1}Epoch [2/20], Step [300/600], Loss: 1.1419470310211182, Test Accuracy: 59.64%\n",
      "{i+1}Epoch [2/20], Step [350/600], Loss: 1.0039846897125244, Test Accuracy: 63.74%\n",
      "{i+1}Epoch [2/20], Step [400/600], Loss: 0.9798558950424194, Test Accuracy: 67.41%\n",
      "{i+1}Epoch [2/20], Step [450/600], Loss: 1.0061140060424805, Test Accuracy: 65.89%\n",
      "{i+1}Epoch [2/20], Step [500/600], Loss: 0.9203212261199951, Test Accuracy: 62.54%\n",
      "{i+1}Epoch [2/20], Step [550/600], Loss: 0.9366154670715332, Test Accuracy: 63.79%\n",
      "{i+1}Epoch [2/20], Step [600/600], Loss: 0.8673539161682129, Test Accuracy: 68.07%\n",
      "{i+1}Epoch [3/20], Step [50/600], Loss: 0.878532350063324, Test Accuracy: 71.32%\n",
      "{i+1}Epoch [3/20], Step [100/600], Loss: 0.9125892519950867, Test Accuracy: 65.96%\n",
      "{i+1}Epoch [3/20], Step [150/600], Loss: 1.0447535514831543, Test Accuracy: 66.09%\n",
      "{i+1}Epoch [3/20], Step [200/600], Loss: 0.8900129199028015, Test Accuracy: 67.27%\n",
      "{i+1}Epoch [3/20], Step [250/600], Loss: 0.814677894115448, Test Accuracy: 70.94%\n",
      "{i+1}Epoch [3/20], Step [300/600], Loss: 0.754487156867981, Test Accuracy: 69.81%\n",
      "{i+1}Epoch [3/20], Step [350/600], Loss: 0.8038284778594971, Test Accuracy: 71.5%\n",
      "{i+1}Epoch [3/20], Step [400/600], Loss: 0.7712776064872742, Test Accuracy: 71.11%\n",
      "{i+1}Epoch [3/20], Step [450/600], Loss: 0.7575563788414001, Test Accuracy: 70.02%\n",
      "{i+1}Epoch [3/20], Step [500/600], Loss: 0.7574251294136047, Test Accuracy: 70.2%\n",
      "{i+1}Epoch [3/20], Step [550/600], Loss: 0.6557018756866455, Test Accuracy: 72.34%\n",
      "{i+1}Epoch [3/20], Step [600/600], Loss: 0.7508655786514282, Test Accuracy: 72.67%\n",
      "{i+1}Epoch [4/20], Step [50/600], Loss: 0.7314854264259338, Test Accuracy: 72.51%\n",
      "{i+1}Epoch [4/20], Step [100/600], Loss: 0.7518138885498047, Test Accuracy: 72.02%\n",
      "{i+1}Epoch [4/20], Step [150/600], Loss: 0.8380140066146851, Test Accuracy: 72.71%\n",
      "{i+1}Epoch [4/20], Step [200/600], Loss: 0.7790846228599548, Test Accuracy: 72.74%\n",
      "{i+1}Epoch [4/20], Step [250/600], Loss: 0.8210522532463074, Test Accuracy: 74.22%\n",
      "{i+1}Epoch [4/20], Step [300/600], Loss: 0.7660465240478516, Test Accuracy: 74.32%\n",
      "{i+1}Epoch [4/20], Step [350/600], Loss: 0.8820738196372986, Test Accuracy: 73.43%\n",
      "{i+1}Epoch [4/20], Step [400/600], Loss: 0.7503632307052612, Test Accuracy: 73.17%\n",
      "{i+1}Epoch [4/20], Step [450/600], Loss: 0.7589588761329651, Test Accuracy: 73.55%\n",
      "{i+1}Epoch [4/20], Step [500/600], Loss: 0.7477928400039673, Test Accuracy: 72.48%\n",
      "{i+1}Epoch [4/20], Step [550/600], Loss: 0.7694593667984009, Test Accuracy: 73.49%\n",
      "{i+1}Epoch [4/20], Step [600/600], Loss: 0.691291093826294, Test Accuracy: 75.46%\n",
      "{i+1}Epoch [5/20], Step [50/600], Loss: 0.7175624966621399, Test Accuracy: 75.94%\n",
      "{i+1}Epoch [5/20], Step [100/600], Loss: 0.6262857913970947, Test Accuracy: 75.45%\n",
      "{i+1}Epoch [5/20], Step [150/600], Loss: 0.6832531690597534, Test Accuracy: 72.53%\n",
      "{i+1}Epoch [5/20], Step [200/600], Loss: 0.6727859973907471, Test Accuracy: 75.54%\n",
      "{i+1}Epoch [5/20], Step [250/600], Loss: 0.6729493737220764, Test Accuracy: 76.17%\n",
      "{i+1}Epoch [5/20], Step [300/600], Loss: 0.621374785900116, Test Accuracy: 75.24%\n",
      "{i+1}Epoch [5/20], Step [350/600], Loss: 0.701784074306488, Test Accuracy: 74.21%\n",
      "{i+1}Epoch [5/20], Step [400/600], Loss: 0.6564689874649048, Test Accuracy: 77.49%\n",
      "{i+1}Epoch [5/20], Step [450/600], Loss: 0.6320396661758423, Test Accuracy: 76.41%\n",
      "{i+1}Epoch [5/20], Step [500/600], Loss: 0.6889104247093201, Test Accuracy: 75.4%\n",
      "{i+1}Epoch [5/20], Step [550/600], Loss: 0.6906091570854187, Test Accuracy: 76.06%\n",
      "{i+1}Epoch [5/20], Step [600/600], Loss: 0.682301938533783, Test Accuracy: 77.45%\n",
      "{i+1}Epoch [6/20], Step [50/600], Loss: 0.7227779626846313, Test Accuracy: 76.81%\n",
      "{i+1}Epoch [6/20], Step [100/600], Loss: 0.702780544757843, Test Accuracy: 76.48%\n",
      "{i+1}Epoch [6/20], Step [150/600], Loss: 0.6049394607543945, Test Accuracy: 78.17%\n",
      "{i+1}Epoch [6/20], Step [200/600], Loss: 0.6426870822906494, Test Accuracy: 75.77%\n",
      "{i+1}Epoch [6/20], Step [250/600], Loss: 0.6002474427223206, Test Accuracy: 76.31%\n",
      "{i+1}Epoch [6/20], Step [300/600], Loss: 0.6590616106987, Test Accuracy: 77.15%\n",
      "{i+1}Epoch [6/20], Step [350/600], Loss: 0.5916396975517273, Test Accuracy: 77.87%\n",
      "{i+1}Epoch [6/20], Step [400/600], Loss: 0.6497443318367004, Test Accuracy: 78.21%\n",
      "{i+1}Epoch [6/20], Step [450/600], Loss: 0.6813225746154785, Test Accuracy: 77.27%\n",
      "{i+1}Epoch [6/20], Step [500/600], Loss: 0.6092668771743774, Test Accuracy: 78.54%\n",
      "{i+1}Epoch [6/20], Step [550/600], Loss: 0.6436185240745544, Test Accuracy: 77.53%\n",
      "{i+1}Epoch [6/20], Step [600/600], Loss: 0.6692899465560913, Test Accuracy: 77.74%\n",
      "{i+1}Epoch [7/20], Step [50/600], Loss: 0.6353262066841125, Test Accuracy: 78.36%\n",
      "{i+1}Epoch [7/20], Step [100/600], Loss: 0.5979582071304321, Test Accuracy: 78.21%\n",
      "{i+1}Epoch [7/20], Step [150/600], Loss: 0.611391544342041, Test Accuracy: 77.28%\n",
      "{i+1}Epoch [7/20], Step [200/600], Loss: 0.755623996257782, Test Accuracy: 78.36%\n",
      "{i+1}Epoch [7/20], Step [250/600], Loss: 0.6997285485267639, Test Accuracy: 77.59%\n",
      "{i+1}Epoch [7/20], Step [300/600], Loss: 0.6243485808372498, Test Accuracy: 78.73%\n",
      "{i+1}Epoch [7/20], Step [350/600], Loss: 0.6261477470397949, Test Accuracy: 76.59%\n",
      "{i+1}Epoch [7/20], Step [400/600], Loss: 0.6991201043128967, Test Accuracy: 78.05%\n",
      "{i+1}Epoch [7/20], Step [450/600], Loss: 0.6436794996261597, Test Accuracy: 75.33%\n",
      "{i+1}Epoch [7/20], Step [500/600], Loss: 0.6830678582191467, Test Accuracy: 77.45%\n",
      "{i+1}Epoch [7/20], Step [550/600], Loss: 0.6368123888969421, Test Accuracy: 79.51%\n",
      "{i+1}Epoch [7/20], Step [600/600], Loss: 0.5875483155250549, Test Accuracy: 79.34%\n",
      "{i+1}Epoch [8/20], Step [50/600], Loss: 0.5786104202270508, Test Accuracy: 77.98%\n",
      "{i+1}Epoch [8/20], Step [100/600], Loss: 0.6277340054512024, Test Accuracy: 78.85%\n",
      "{i+1}Epoch [8/20], Step [150/600], Loss: 0.6568435430526733, Test Accuracy: 79.51%\n",
      "{i+1}Epoch [8/20], Step [200/600], Loss: 0.6133849620819092, Test Accuracy: 79.73%\n",
      "{i+1}Epoch [8/20], Step [250/600], Loss: 0.5972548127174377, Test Accuracy: 79.4%\n",
      "{i+1}Epoch [8/20], Step [300/600], Loss: 0.6403371691703796, Test Accuracy: 79.46%\n",
      "{i+1}Epoch [8/20], Step [350/600], Loss: 0.601682186126709, Test Accuracy: 72.74%\n",
      "{i+1}Epoch [8/20], Step [400/600], Loss: 0.6220076084136963, Test Accuracy: 80.71%\n",
      "{i+1}Epoch [8/20], Step [450/600], Loss: 0.6192854046821594, Test Accuracy: 80.37%\n",
      "{i+1}Epoch [8/20], Step [500/600], Loss: 0.6646751165390015, Test Accuracy: 80.29%\n",
      "{i+1}Epoch [8/20], Step [550/600], Loss: 0.6700613498687744, Test Accuracy: 78.99%\n",
      "{i+1}Epoch [8/20], Step [600/600], Loss: 0.5936952233314514, Test Accuracy: 79.38%\n",
      "{i+1}Epoch [9/20], Step [50/600], Loss: 0.7095359563827515, Test Accuracy: 79.28%\n",
      "{i+1}Epoch [9/20], Step [100/600], Loss: 0.5922821164131165, Test Accuracy: 79.79%\n",
      "{i+1}Epoch [9/20], Step [150/600], Loss: 0.6491938829421997, Test Accuracy: 79.15%\n",
      "{i+1}Epoch [9/20], Step [200/600], Loss: 0.6089284420013428, Test Accuracy: 80.51%\n",
      "{i+1}Epoch [9/20], Step [250/600], Loss: 0.5833578705787659, Test Accuracy: 79.69%\n",
      "{i+1}Epoch [9/20], Step [300/600], Loss: 0.5670819282531738, Test Accuracy: 80.56%\n",
      "{i+1}Epoch [9/20], Step [350/600], Loss: 0.5630221366882324, Test Accuracy: 80.02%\n",
      "{i+1}Epoch [9/20], Step [400/600], Loss: 0.5549870133399963, Test Accuracy: 80.69%\n",
      "{i+1}Epoch [9/20], Step [450/600], Loss: 0.5426538586616516, Test Accuracy: 80.27%\n",
      "{i+1}Epoch [9/20], Step [500/600], Loss: 0.6303908824920654, Test Accuracy: 78.86%\n",
      "{i+1}Epoch [9/20], Step [550/600], Loss: 0.5402576327323914, Test Accuracy: 78.99%\n",
      "{i+1}Epoch [9/20], Step [600/600], Loss: 0.5595413446426392, Test Accuracy: 79.99%\n",
      "{i+1}Epoch [10/20], Step [50/600], Loss: 0.5753664970397949, Test Accuracy: 81.31%\n",
      "{i+1}Epoch [10/20], Step [100/600], Loss: 0.6003717184066772, Test Accuracy: 79.0%\n",
      "{i+1}Epoch [10/20], Step [150/600], Loss: 0.5446480512619019, Test Accuracy: 81.38%\n",
      "{i+1}Epoch [10/20], Step [200/600], Loss: 0.5356171131134033, Test Accuracy: 81.12%\n",
      "{i+1}Epoch [10/20], Step [250/600], Loss: 0.5383825898170471, Test Accuracy: 79.74%\n",
      "{i+1}Epoch [10/20], Step [300/600], Loss: 0.5514976382255554, Test Accuracy: 81.59%\n",
      "{i+1}Epoch [10/20], Step [350/600], Loss: 0.6182456016540527, Test Accuracy: 81.34%\n",
      "{i+1}Epoch [10/20], Step [400/600], Loss: 0.5671606659889221, Test Accuracy: 81.53%\n",
      "{i+1}Epoch [10/20], Step [450/600], Loss: 0.609556257724762, Test Accuracy: 80.69%\n",
      "{i+1}Epoch [10/20], Step [500/600], Loss: 0.6613979339599609, Test Accuracy: 79.52%\n",
      "{i+1}Epoch [10/20], Step [550/600], Loss: 0.6749991774559021, Test Accuracy: 80.95%\n",
      "{i+1}Epoch [10/20], Step [600/600], Loss: 0.5357024669647217, Test Accuracy: 81.43%\n",
      "{i+1}Epoch [11/20], Step [50/600], Loss: 0.5875659584999084, Test Accuracy: 81.35%\n",
      "{i+1}Epoch [11/20], Step [100/600], Loss: 0.5335870981216431, Test Accuracy: 81.03%\n",
      "{i+1}Epoch [11/20], Step [150/600], Loss: 0.6000311374664307, Test Accuracy: 81.04%\n",
      "{i+1}Epoch [11/20], Step [200/600], Loss: 0.5791386365890503, Test Accuracy: 81.34%\n",
      "{i+1}Epoch [11/20], Step [250/600], Loss: 0.5438132286071777, Test Accuracy: 81.54%\n",
      "{i+1}Epoch [11/20], Step [300/600], Loss: 0.5893913507461548, Test Accuracy: 80.78%\n",
      "{i+1}Epoch [11/20], Step [350/600], Loss: 0.6065776348114014, Test Accuracy: 81.81%\n",
      "{i+1}Epoch [11/20], Step [400/600], Loss: 0.5184967517852783, Test Accuracy: 81.28%\n",
      "{i+1}Epoch [11/20], Step [450/600], Loss: 0.565580427646637, Test Accuracy: 81.07%\n",
      "{i+1}Epoch [11/20], Step [500/600], Loss: 0.5215898752212524, Test Accuracy: 81.61%\n",
      "{i+1}Epoch [11/20], Step [550/600], Loss: 0.5617539882659912, Test Accuracy: 81.85%\n",
      "{i+1}Epoch [11/20], Step [600/600], Loss: 0.557222306728363, Test Accuracy: 80.57%\n",
      "{i+1}Epoch [12/20], Step [50/600], Loss: 0.5148923397064209, Test Accuracy: 80.78%\n",
      "{i+1}Epoch [12/20], Step [100/600], Loss: 0.5330605506896973, Test Accuracy: 81.67%\n",
      "{i+1}Epoch [12/20], Step [150/600], Loss: 0.5391743183135986, Test Accuracy: 81.29%\n",
      "{i+1}Epoch [12/20], Step [200/600], Loss: 0.5155538320541382, Test Accuracy: 82.02%\n",
      "{i+1}Epoch [12/20], Step [250/600], Loss: 0.5746148228645325, Test Accuracy: 82.79%\n",
      "{i+1}Epoch [12/20], Step [300/600], Loss: 0.5119163990020752, Test Accuracy: 81.07%\n",
      "{i+1}Epoch [12/20], Step [350/600], Loss: 0.5594912171363831, Test Accuracy: 81.71%\n",
      "{i+1}Epoch [12/20], Step [400/600], Loss: 0.5390232801437378, Test Accuracy: 82.43%\n",
      "{i+1}Epoch [12/20], Step [450/600], Loss: 0.5860629677772522, Test Accuracy: 81.78%\n",
      "{i+1}Epoch [12/20], Step [500/600], Loss: 0.5419213175773621, Test Accuracy: 82.53%\n",
      "{i+1}Epoch [12/20], Step [550/600], Loss: 0.538999080657959, Test Accuracy: 82.13%\n",
      "{i+1}Epoch [12/20], Step [600/600], Loss: 0.5584510564804077, Test Accuracy: 81.28%\n",
      "{i+1}Epoch [13/20], Step [50/600], Loss: 0.5949684381484985, Test Accuracy: 82.26%\n",
      "{i+1}Epoch [13/20], Step [100/600], Loss: 0.5242879390716553, Test Accuracy: 81.44%\n",
      "{i+1}Epoch [13/20], Step [150/600], Loss: 0.5851135849952698, Test Accuracy: 82.13%\n",
      "{i+1}Epoch [13/20], Step [200/600], Loss: 0.5335252285003662, Test Accuracy: 80.94%\n",
      "{i+1}Epoch [13/20], Step [250/600], Loss: 0.5689955949783325, Test Accuracy: 82.61%\n",
      "{i+1}Epoch [13/20], Step [300/600], Loss: 0.5945239067077637, Test Accuracy: 82.46%\n",
      "{i+1}Epoch [13/20], Step [350/600], Loss: 0.5355141162872314, Test Accuracy: 82.54%\n",
      "{i+1}Epoch [13/20], Step [400/600], Loss: 0.5599254369735718, Test Accuracy: 80.99%\n",
      "{i+1}Epoch [13/20], Step [450/600], Loss: 0.5079082250595093, Test Accuracy: 79.85%\n",
      "{i+1}Epoch [13/20], Step [500/600], Loss: 0.5917788743972778, Test Accuracy: 82.51%\n",
      "{i+1}Epoch [13/20], Step [550/600], Loss: 0.534156084060669, Test Accuracy: 82.7%\n",
      "{i+1}Epoch [13/20], Step [600/600], Loss: 0.5310853123664856, Test Accuracy: 81.72%\n",
      "{i+1}Epoch [14/20], Step [50/600], Loss: 0.5568608641624451, Test Accuracy: 82.62%\n",
      "{i+1}Epoch [14/20], Step [100/600], Loss: 0.5620594620704651, Test Accuracy: 82.52%\n",
      "{i+1}Epoch [14/20], Step [150/600], Loss: 0.5575084090232849, Test Accuracy: 82.63%\n",
      "{i+1}Epoch [14/20], Step [200/600], Loss: 0.5359118580818176, Test Accuracy: 82.05%\n",
      "{i+1}Epoch [14/20], Step [250/600], Loss: 0.5445781946182251, Test Accuracy: 83.1%\n",
      "{i+1}Epoch [14/20], Step [300/600], Loss: 0.6113329529762268, Test Accuracy: 82.7%\n",
      "{i+1}Epoch [14/20], Step [350/600], Loss: 0.475129634141922, Test Accuracy: 80.54%\n",
      "{i+1}Epoch [14/20], Step [400/600], Loss: 0.5661835670471191, Test Accuracy: 81.68%\n",
      "{i+1}Epoch [14/20], Step [450/600], Loss: 0.5045230984687805, Test Accuracy: 81.26%\n",
      "{i+1}Epoch [14/20], Step [500/600], Loss: 0.5290682315826416, Test Accuracy: 82.21%\n",
      "{i+1}Epoch [14/20], Step [550/600], Loss: 0.5281022191047668, Test Accuracy: 83.14%\n",
      "{i+1}Epoch [14/20], Step [600/600], Loss: 0.6052864789962769, Test Accuracy: 81.61%\n",
      "{i+1}Epoch [15/20], Step [50/600], Loss: 0.5139095783233643, Test Accuracy: 82.28%\n",
      "{i+1}Epoch [15/20], Step [100/600], Loss: 0.5574249029159546, Test Accuracy: 83.06%\n",
      "{i+1}Epoch [15/20], Step [150/600], Loss: 0.5410367846488953, Test Accuracy: 83.04%\n",
      "{i+1}Epoch [15/20], Step [200/600], Loss: 0.5624668002128601, Test Accuracy: 82.63%\n",
      "{i+1}Epoch [15/20], Step [250/600], Loss: 0.5362287759780884, Test Accuracy: 82.37%\n",
      "{i+1}Epoch [15/20], Step [300/600], Loss: 0.5561107397079468, Test Accuracy: 83.53%\n",
      "{i+1}Epoch [15/20], Step [350/600], Loss: 0.5526544451713562, Test Accuracy: 82.8%\n",
      "{i+1}Epoch [15/20], Step [400/600], Loss: 0.6094589829444885, Test Accuracy: 83.02%\n",
      "{i+1}Epoch [15/20], Step [450/600], Loss: 0.5949380397796631, Test Accuracy: 82.85%\n",
      "{i+1}Epoch [15/20], Step [500/600], Loss: 0.5675860047340393, Test Accuracy: 83.52%\n",
      "{i+1}Epoch [15/20], Step [550/600], Loss: 0.5651804208755493, Test Accuracy: 82.89%\n",
      "{i+1}Epoch [15/20], Step [600/600], Loss: 0.5303660035133362, Test Accuracy: 83.39%\n",
      "{i+1}Epoch [16/20], Step [50/600], Loss: 0.5561947226524353, Test Accuracy: 83.01%\n",
      "{i+1}Epoch [16/20], Step [100/600], Loss: 0.5600501894950867, Test Accuracy: 82.59%\n",
      "{i+1}Epoch [16/20], Step [150/600], Loss: 0.5559958815574646, Test Accuracy: 82.86%\n",
      "{i+1}Epoch [16/20], Step [200/600], Loss: 0.5495320558547974, Test Accuracy: 83.23%\n",
      "{i+1}Epoch [16/20], Step [250/600], Loss: 0.49653977155685425, Test Accuracy: 83.06%\n",
      "{i+1}Epoch [16/20], Step [300/600], Loss: 0.5381165146827698, Test Accuracy: 83.28%\n",
      "{i+1}Epoch [16/20], Step [350/600], Loss: 0.5078613758087158, Test Accuracy: 83.12%\n",
      "{i+1}Epoch [16/20], Step [400/600], Loss: 0.4913746118545532, Test Accuracy: 83.1%\n",
      "{i+1}Epoch [16/20], Step [450/600], Loss: 0.5144011378288269, Test Accuracy: 83.83%\n",
      "{i+1}Epoch [16/20], Step [500/600], Loss: 0.54392409324646, Test Accuracy: 83.18%\n",
      "{i+1}Epoch [16/20], Step [550/600], Loss: 0.5132845044136047, Test Accuracy: 83.62%\n",
      "{i+1}Epoch [16/20], Step [600/600], Loss: 0.5411128401756287, Test Accuracy: 83.77%\n",
      "{i+1}Epoch [17/20], Step [50/600], Loss: 0.5050145983695984, Test Accuracy: 83.39%\n",
      "{i+1}Epoch [17/20], Step [100/600], Loss: 0.592003345489502, Test Accuracy: 83.55%\n",
      "{i+1}Epoch [17/20], Step [150/600], Loss: 0.5626978278160095, Test Accuracy: 83.32%\n",
      "{i+1}Epoch [17/20], Step [200/600], Loss: 0.5494510531425476, Test Accuracy: 83.71%\n",
      "{i+1}Epoch [17/20], Step [250/600], Loss: 0.5532686710357666, Test Accuracy: 83.34%\n",
      "{i+1}Epoch [17/20], Step [300/600], Loss: 0.5108282566070557, Test Accuracy: 83.2%\n",
      "{i+1}Epoch [17/20], Step [350/600], Loss: 0.5609167814254761, Test Accuracy: 82.93%\n",
      "{i+1}Epoch [17/20], Step [400/600], Loss: 0.5244514346122742, Test Accuracy: 83.4%\n",
      "{i+1}Epoch [17/20], Step [450/600], Loss: 0.5735656023025513, Test Accuracy: 83.13%\n",
      "{i+1}Epoch [17/20], Step [500/600], Loss: 0.5489834547042847, Test Accuracy: 83.19%\n",
      "{i+1}Epoch [17/20], Step [550/600], Loss: 0.5355156660079956, Test Accuracy: 82.77%\n",
      "{i+1}Epoch [17/20], Step [600/600], Loss: 0.619105339050293, Test Accuracy: 83.52%\n",
      "{i+1}Epoch [18/20], Step [50/600], Loss: 0.5272113680839539, Test Accuracy: 83.64%\n",
      "{i+1}Epoch [18/20], Step [100/600], Loss: 0.4965897798538208, Test Accuracy: 83.85%\n",
      "{i+1}Epoch [18/20], Step [150/600], Loss: 0.5492316484451294, Test Accuracy: 83.21%\n",
      "{i+1}Epoch [18/20], Step [200/600], Loss: 0.48905089497566223, Test Accuracy: 82.99%\n",
      "{i+1}Epoch [18/20], Step [250/600], Loss: 0.482791930437088, Test Accuracy: 83.13%\n",
      "{i+1}Epoch [18/20], Step [300/600], Loss: 0.5219340324401855, Test Accuracy: 83.91%\n",
      "{i+1}Epoch [18/20], Step [350/600], Loss: 0.5045895576477051, Test Accuracy: 83.99%\n",
      "{i+1}Epoch [18/20], Step [400/600], Loss: 0.5109530687332153, Test Accuracy: 82.91%\n",
      "{i+1}Epoch [18/20], Step [450/600], Loss: 0.5899386405944824, Test Accuracy: 83.64%\n",
      "{i+1}Epoch [18/20], Step [500/600], Loss: 0.5264580845832825, Test Accuracy: 83.07%\n",
      "{i+1}Epoch [18/20], Step [550/600], Loss: 0.5209886431694031, Test Accuracy: 83.1%\n",
      "{i+1}Epoch [18/20], Step [600/600], Loss: 0.5733883380889893, Test Accuracy: 83.59%\n",
      "{i+1}Epoch [19/20], Step [50/600], Loss: 0.5003263354301453, Test Accuracy: 83.62%\n",
      "{i+1}Epoch [19/20], Step [100/600], Loss: 0.5452938675880432, Test Accuracy: 83.91%\n",
      "{i+1}Epoch [19/20], Step [150/600], Loss: 0.5002039670944214, Test Accuracy: 83.22%\n",
      "{i+1}Epoch [19/20], Step [200/600], Loss: 0.5372102856636047, Test Accuracy: 83.9%\n",
      "{i+1}Epoch [19/20], Step [250/600], Loss: 0.5317804217338562, Test Accuracy: 83.94%\n",
      "{i+1}Epoch [19/20], Step [300/600], Loss: 0.5081161260604858, Test Accuracy: 83.5%\n",
      "{i+1}Epoch [19/20], Step [350/600], Loss: 0.5323249101638794, Test Accuracy: 83.89%\n",
      "{i+1}Epoch [19/20], Step [400/600], Loss: 0.5494224429130554, Test Accuracy: 83.2%\n",
      "{i+1}Epoch [19/20], Step [450/600], Loss: 0.5726589560508728, Test Accuracy: 83.94%\n",
      "{i+1}Epoch [19/20], Step [500/600], Loss: 0.5597962737083435, Test Accuracy: 83.68%\n",
      "{i+1}Epoch [19/20], Step [550/600], Loss: 0.5275705456733704, Test Accuracy: 83.52%\n",
      "{i+1}Epoch [19/20], Step [600/600], Loss: 0.5031632781028748, Test Accuracy: 83.42%\n",
      "{i+1}Epoch [20/20], Step [50/600], Loss: 0.5075947046279907, Test Accuracy: 83.82%\n",
      "{i+1}Epoch [20/20], Step [100/600], Loss: 0.5212608575820923, Test Accuracy: 84.44%\n",
      "{i+1}Epoch [20/20], Step [150/600], Loss: 0.5534623861312866, Test Accuracy: 84.29%\n",
      "{i+1}Epoch [20/20], Step [200/600], Loss: 0.5023207068443298, Test Accuracy: 83.99%\n",
      "{i+1}Epoch [20/20], Step [250/600], Loss: 0.5086920857429504, Test Accuracy: 84.16%\n",
      "{i+1}Epoch [20/20], Step [300/600], Loss: 0.5191981792449951, Test Accuracy: 84.47%\n",
      "{i+1}Epoch [20/20], Step [350/600], Loss: 0.5430966019630432, Test Accuracy: 84.58%\n",
      "{i+1}Epoch [20/20], Step [400/600], Loss: 0.5306503176689148, Test Accuracy: 84.32%\n",
      "{i+1}Epoch [20/20], Step [450/600], Loss: 0.5119208693504333, Test Accuracy: 84.32%\n",
      "{i+1}Epoch [20/20], Step [500/600], Loss: 0.5245157480239868, Test Accuracy: 84.16%\n",
      "{i+1}Epoch [20/20], Step [550/600], Loss: 0.5200989246368408, Test Accuracy: 84.2%\n",
      "{i+1}Epoch [20/20], Step [600/600], Loss: 0.4970995783805847, Test Accuracy: 83.83%\n",
      "100\n",
      "Using cuda device\n",
      "Tiny_convnet(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "{i+1}Epoch [1/20], Step [50/600], Loss: 2.322357416152954, Test Accuracy: 20.98%\n",
      "{i+1}Epoch [1/20], Step [100/600], Loss: 2.1650147438049316, Test Accuracy: 14.86%\n",
      "{i+1}Epoch [1/20], Step [150/600], Loss: 1.9206128120422363, Test Accuracy: 32.53%\n",
      "{i+1}Epoch [1/20], Step [200/600], Loss: 1.4963878393173218, Test Accuracy: 48.24%\n",
      "{i+1}Epoch [1/20], Step [250/600], Loss: 1.3128186464309692, Test Accuracy: 52.22%\n",
      "{i+1}Epoch [1/20], Step [300/600], Loss: 1.278173804283142, Test Accuracy: 55.4%\n",
      "{i+1}Epoch [1/20], Step [350/600], Loss: 1.0324645042419434, Test Accuracy: 65.87%\n",
      "{i+1}Epoch [1/20], Step [400/600], Loss: 1.0954432487487793, Test Accuracy: 62.67%\n",
      "{i+1}Epoch [1/20], Step [450/600], Loss: 1.0196478366851807, Test Accuracy: 65.97%\n",
      "{i+1}Epoch [1/20], Step [500/600], Loss: 1.0349212884902954, Test Accuracy: 61.18%\n",
      "{i+1}Epoch [1/20], Step [550/600], Loss: 0.8699746131896973, Test Accuracy: 68.03%\n",
      "{i+1}Epoch [1/20], Step [600/600], Loss: 0.8748798370361328, Test Accuracy: 69.96%\n",
      "{i+1}Epoch [2/20], Step [50/600], Loss: 0.8784232139587402, Test Accuracy: 69.74%\n",
      "{i+1}Epoch [2/20], Step [100/600], Loss: 0.822974681854248, Test Accuracy: 70.51%\n",
      "{i+1}Epoch [2/20], Step [150/600], Loss: 0.784938633441925, Test Accuracy: 72.45%\n",
      "{i+1}Epoch [2/20], Step [200/600], Loss: 0.8415393233299255, Test Accuracy: 68.8%\n",
      "{i+1}Epoch [2/20], Step [250/600], Loss: 0.8066831827163696, Test Accuracy: 71.15%\n",
      "{i+1}Epoch [2/20], Step [300/600], Loss: 0.774006724357605, Test Accuracy: 69.9%\n",
      "{i+1}Epoch [2/20], Step [350/600], Loss: 0.7479269504547119, Test Accuracy: 72.6%\n",
      "{i+1}Epoch [2/20], Step [400/600], Loss: 0.7697228789329529, Test Accuracy: 75.54%\n",
      "{i+1}Epoch [2/20], Step [450/600], Loss: 0.789376437664032, Test Accuracy: 74.06%\n",
      "{i+1}Epoch [2/20], Step [500/600], Loss: 0.7792871594429016, Test Accuracy: 73.22%\n",
      "{i+1}Epoch [2/20], Step [550/600], Loss: 0.7946354150772095, Test Accuracy: 70.01%\n",
      "{i+1}Epoch [2/20], Step [600/600], Loss: 0.773363471031189, Test Accuracy: 75.62%\n",
      "{i+1}Epoch [3/20], Step [50/600], Loss: 0.8413878083229065, Test Accuracy: 73.75%\n",
      "{i+1}Epoch [3/20], Step [100/600], Loss: 0.7353036403656006, Test Accuracy: 76.33%\n",
      "{i+1}Epoch [3/20], Step [150/600], Loss: 0.7669808864593506, Test Accuracy: 74.99%\n",
      "{i+1}Epoch [3/20], Step [200/600], Loss: 0.7600242495536804, Test Accuracy: 76.02%\n",
      "{i+1}Epoch [3/20], Step [250/600], Loss: 0.7678170800209045, Test Accuracy: 75.79%\n",
      "{i+1}Epoch [3/20], Step [300/600], Loss: 0.7609029412269592, Test Accuracy: 76.58%\n",
      "{i+1}Epoch [3/20], Step [350/600], Loss: 0.7657623887062073, Test Accuracy: 75.99%\n",
      "{i+1}Epoch [3/20], Step [400/600], Loss: 0.7890216708183289, Test Accuracy: 75.9%\n",
      "{i+1}Epoch [3/20], Step [450/600], Loss: 0.7548435926437378, Test Accuracy: 75.31%\n",
      "{i+1}Epoch [3/20], Step [500/600], Loss: 0.6401199102401733, Test Accuracy: 76.09%\n",
      "{i+1}Epoch [3/20], Step [550/600], Loss: 0.797532320022583, Test Accuracy: 76.9%\n",
      "{i+1}Epoch [3/20], Step [600/600], Loss: 0.7301352620124817, Test Accuracy: 77.35%\n",
      "{i+1}Epoch [4/20], Step [50/600], Loss: 0.7937302589416504, Test Accuracy: 77.31%\n",
      "{i+1}Epoch [4/20], Step [100/600], Loss: 0.715603768825531, Test Accuracy: 77.59%\n",
      "{i+1}Epoch [4/20], Step [150/600], Loss: 0.7062090039253235, Test Accuracy: 78.09%\n",
      "{i+1}Epoch [4/20], Step [200/600], Loss: 0.6951904892921448, Test Accuracy: 78.68%\n",
      "{i+1}Epoch [4/20], Step [250/600], Loss: 0.6895471811294556, Test Accuracy: 77.26%\n",
      "{i+1}Epoch [4/20], Step [300/600], Loss: 0.7123766541481018, Test Accuracy: 77.73%\n",
      "{i+1}Epoch [4/20], Step [350/600], Loss: 0.659107506275177, Test Accuracy: 77.3%\n",
      "{i+1}Epoch [4/20], Step [400/600], Loss: 0.6445055603981018, Test Accuracy: 77.69%\n",
      "{i+1}Epoch [4/20], Step [450/600], Loss: 0.6441531181335449, Test Accuracy: 78.15%\n",
      "{i+1}Epoch [4/20], Step [500/600], Loss: 0.6861768364906311, Test Accuracy: 78.55%\n",
      "{i+1}Epoch [4/20], Step [550/600], Loss: 0.709794282913208, Test Accuracy: 78.69%\n",
      "{i+1}Epoch [4/20], Step [600/600], Loss: 0.6738747954368591, Test Accuracy: 79.12%\n",
      "{i+1}Epoch [5/20], Step [50/600], Loss: 0.6061307191848755, Test Accuracy: 76.57%\n",
      "{i+1}Epoch [5/20], Step [100/600], Loss: 0.6007470488548279, Test Accuracy: 77.06%\n",
      "{i+1}Epoch [5/20], Step [150/600], Loss: 0.6493096947669983, Test Accuracy: 78.07%\n",
      "{i+1}Epoch [5/20], Step [200/600], Loss: 0.6131181120872498, Test Accuracy: 78.28%\n",
      "{i+1}Epoch [5/20], Step [250/600], Loss: 0.6482306122779846, Test Accuracy: 78.6%\n",
      "{i+1}Epoch [5/20], Step [300/600], Loss: 0.6403343677520752, Test Accuracy: 79.68%\n",
      "{i+1}Epoch [5/20], Step [350/600], Loss: 0.6867438554763794, Test Accuracy: 79.11%\n",
      "{i+1}Epoch [5/20], Step [400/600], Loss: 0.5799596309661865, Test Accuracy: 79.71%\n",
      "{i+1}Epoch [5/20], Step [450/600], Loss: 0.5902752876281738, Test Accuracy: 79.41%\n",
      "{i+1}Epoch [5/20], Step [500/600], Loss: 0.7151396870613098, Test Accuracy: 80.13%\n",
      "{i+1}Epoch [5/20], Step [550/600], Loss: 0.6275638341903687, Test Accuracy: 80.14%\n",
      "{i+1}Epoch [5/20], Step [600/600], Loss: 0.6458685994148254, Test Accuracy: 79.88%\n",
      "{i+1}Epoch [6/20], Step [50/600], Loss: 0.640338659286499, Test Accuracy: 79.77%\n",
      "{i+1}Epoch [6/20], Step [100/600], Loss: 0.5552969574928284, Test Accuracy: 79.62%\n",
      "{i+1}Epoch [6/20], Step [150/600], Loss: 0.616120457649231, Test Accuracy: 78.53%\n",
      "{i+1}Epoch [6/20], Step [200/600], Loss: 0.6264645457267761, Test Accuracy: 80.32%\n",
      "{i+1}Epoch [6/20], Step [250/600], Loss: 0.6502529978752136, Test Accuracy: 80.51%\n",
      "{i+1}Epoch [6/20], Step [300/600], Loss: 0.6195700764656067, Test Accuracy: 80.65%\n",
      "{i+1}Epoch [6/20], Step [350/600], Loss: 0.6963564157485962, Test Accuracy: 79.48%\n",
      "{i+1}Epoch [6/20], Step [400/600], Loss: 0.5950213074684143, Test Accuracy: 80.12%\n",
      "{i+1}Epoch [6/20], Step [450/600], Loss: 0.6752274036407471, Test Accuracy: 80.45%\n",
      "{i+1}Epoch [6/20], Step [500/600], Loss: 0.6309993267059326, Test Accuracy: 79.89%\n",
      "{i+1}Epoch [6/20], Step [550/600], Loss: 0.6624273061752319, Test Accuracy: 80.97%\n",
      "{i+1}Epoch [6/20], Step [600/600], Loss: 0.661846935749054, Test Accuracy: 79.46%\n",
      "{i+1}Epoch [7/20], Step [50/600], Loss: 0.5701072216033936, Test Accuracy: 80.65%\n",
      "{i+1}Epoch [7/20], Step [100/600], Loss: 0.5947388410568237, Test Accuracy: 79.77%\n",
      "{i+1}Epoch [7/20], Step [150/600], Loss: 0.5901613831520081, Test Accuracy: 80.44%\n",
      "{i+1}Epoch [7/20], Step [200/600], Loss: 0.550238847732544, Test Accuracy: 80.44%\n",
      "{i+1}Epoch [7/20], Step [250/600], Loss: 0.6028210520744324, Test Accuracy: 80.58%\n",
      "{i+1}Epoch [7/20], Step [300/600], Loss: 0.592232882976532, Test Accuracy: 80.25%\n",
      "{i+1}Epoch [7/20], Step [350/600], Loss: 0.6357896327972412, Test Accuracy: 80.42%\n",
      "{i+1}Epoch [7/20], Step [400/600], Loss: 0.5903395414352417, Test Accuracy: 79.82%\n",
      "{i+1}Epoch [7/20], Step [450/600], Loss: 0.5502916574478149, Test Accuracy: 79.62%\n",
      "{i+1}Epoch [7/20], Step [500/600], Loss: 0.5888062119483948, Test Accuracy: 81.54%\n",
      "{i+1}Epoch [7/20], Step [550/600], Loss: 0.6456397175788879, Test Accuracy: 80.65%\n",
      "{i+1}Epoch [7/20], Step [600/600], Loss: 0.6138573288917542, Test Accuracy: 81.76%\n",
      "{i+1}Epoch [8/20], Step [50/600], Loss: 0.5848990082740784, Test Accuracy: 81.53%\n",
      "{i+1}Epoch [8/20], Step [100/600], Loss: 0.6004601120948792, Test Accuracy: 80.91%\n",
      "{i+1}Epoch [8/20], Step [150/600], Loss: 0.6011837124824524, Test Accuracy: 80.36%\n",
      "{i+1}Epoch [8/20], Step [200/600], Loss: 0.631088137626648, Test Accuracy: 80.66%\n",
      "{i+1}Epoch [8/20], Step [250/600], Loss: 0.5792571902275085, Test Accuracy: 81.12%\n",
      "{i+1}Epoch [8/20], Step [300/600], Loss: 0.5902376770973206, Test Accuracy: 80.27%\n",
      "{i+1}Epoch [8/20], Step [350/600], Loss: 0.5946658849716187, Test Accuracy: 81.74%\n",
      "{i+1}Epoch [8/20], Step [400/600], Loss: 0.5887744426727295, Test Accuracy: 81.82%\n",
      "{i+1}Epoch [8/20], Step [450/600], Loss: 0.6034337878227234, Test Accuracy: 81.95%\n",
      "{i+1}Epoch [8/20], Step [500/600], Loss: 0.6005299091339111, Test Accuracy: 81.91%\n",
      "{i+1}Epoch [8/20], Step [550/600], Loss: 0.5822247266769409, Test Accuracy: 80.71%\n",
      "{i+1}Epoch [8/20], Step [600/600], Loss: 0.5950176119804382, Test Accuracy: 81.9%\n",
      "{i+1}Epoch [9/20], Step [50/600], Loss: 0.5928244590759277, Test Accuracy: 82.13%\n",
      "{i+1}Epoch [9/20], Step [100/600], Loss: 0.6055995225906372, Test Accuracy: 81.58%\n",
      "{i+1}Epoch [9/20], Step [150/600], Loss: 0.6074530482292175, Test Accuracy: 82.21%\n",
      "{i+1}Epoch [9/20], Step [200/600], Loss: 0.6309117078781128, Test Accuracy: 81.66%\n",
      "{i+1}Epoch [9/20], Step [250/600], Loss: 0.6035476922988892, Test Accuracy: 81.46%\n",
      "{i+1}Epoch [9/20], Step [300/600], Loss: 0.5795334577560425, Test Accuracy: 81.98%\n",
      "{i+1}Epoch [9/20], Step [350/600], Loss: 0.5926820039749146, Test Accuracy: 82.31%\n",
      "{i+1}Epoch [9/20], Step [400/600], Loss: 0.595795750617981, Test Accuracy: 81.67%\n",
      "{i+1}Epoch [9/20], Step [450/600], Loss: 0.5751611590385437, Test Accuracy: 81.05%\n",
      "{i+1}Epoch [9/20], Step [500/600], Loss: 0.6076056361198425, Test Accuracy: 81.4%\n",
      "{i+1}Epoch [9/20], Step [550/600], Loss: 0.5673300623893738, Test Accuracy: 82.02%\n",
      "{i+1}Epoch [9/20], Step [600/600], Loss: 0.6311191916465759, Test Accuracy: 81.93%\n",
      "{i+1}Epoch [10/20], Step [50/600], Loss: 0.6327438950538635, Test Accuracy: 82.31%\n",
      "{i+1}Epoch [10/20], Step [100/600], Loss: 0.614328145980835, Test Accuracy: 81.18%\n",
      "{i+1}Epoch [10/20], Step [150/600], Loss: 0.5932101607322693, Test Accuracy: 82.17%\n",
      "{i+1}Epoch [10/20], Step [200/600], Loss: 0.5910229682922363, Test Accuracy: 81.18%\n",
      "{i+1}Epoch [10/20], Step [250/600], Loss: 0.5436468720436096, Test Accuracy: 81.23%\n",
      "{i+1}Epoch [10/20], Step [300/600], Loss: 0.6275981664657593, Test Accuracy: 81.81%\n",
      "{i+1}Epoch [10/20], Step [350/600], Loss: 0.546755850315094, Test Accuracy: 82.22%\n",
      "{i+1}Epoch [10/20], Step [400/600], Loss: 0.6157164573669434, Test Accuracy: 81.92%\n",
      "{i+1}Epoch [10/20], Step [450/600], Loss: 0.5730719566345215, Test Accuracy: 82.31%\n",
      "{i+1}Epoch [10/20], Step [500/600], Loss: 0.5891278982162476, Test Accuracy: 82.05%\n",
      "{i+1}Epoch [10/20], Step [550/600], Loss: 0.635876476764679, Test Accuracy: 81.87%\n",
      "{i+1}Epoch [10/20], Step [600/600], Loss: 0.6233597993850708, Test Accuracy: 81.76%\n",
      "{i+1}Epoch [11/20], Step [50/600], Loss: 0.5655133724212646, Test Accuracy: 82.44%\n",
      "{i+1}Epoch [11/20], Step [100/600], Loss: 0.6054147481918335, Test Accuracy: 81.6%\n",
      "{i+1}Epoch [11/20], Step [150/600], Loss: 0.5170239210128784, Test Accuracy: 82.69%\n",
      "{i+1}Epoch [11/20], Step [200/600], Loss: 0.6224912405014038, Test Accuracy: 82.54%\n",
      "{i+1}Epoch [11/20], Step [250/600], Loss: 0.5527229905128479, Test Accuracy: 82.27%\n",
      "{i+1}Epoch [11/20], Step [300/600], Loss: 0.5965349078178406, Test Accuracy: 82.0%\n",
      "{i+1}Epoch [11/20], Step [350/600], Loss: 0.5325167179107666, Test Accuracy: 82.19%\n",
      "{i+1}Epoch [11/20], Step [400/600], Loss: 0.6096729636192322, Test Accuracy: 82.44%\n",
      "{i+1}Epoch [11/20], Step [450/600], Loss: 0.5577512979507446, Test Accuracy: 82.13%\n",
      "{i+1}Epoch [11/20], Step [500/600], Loss: 0.5538591146469116, Test Accuracy: 82.13%\n",
      "{i+1}Epoch [11/20], Step [550/600], Loss: 0.6020805835723877, Test Accuracy: 82.71%\n",
      "{i+1}Epoch [11/20], Step [600/600], Loss: 0.5888559222221375, Test Accuracy: 82.66%\n",
      "{i+1}Epoch [12/20], Step [50/600], Loss: 0.579603374004364, Test Accuracy: 82.65%\n",
      "{i+1}Epoch [12/20], Step [100/600], Loss: 0.5600383281707764, Test Accuracy: 82.55%\n",
      "{i+1}Epoch [12/20], Step [150/600], Loss: 0.6255528926849365, Test Accuracy: 82.58%\n",
      "{i+1}Epoch [12/20], Step [200/600], Loss: 0.5588116645812988, Test Accuracy: 81.56%\n",
      "{i+1}Epoch [12/20], Step [250/600], Loss: 0.5846164226531982, Test Accuracy: 83.11%\n",
      "{i+1}Epoch [12/20], Step [300/600], Loss: 0.5721375942230225, Test Accuracy: 82.73%\n",
      "{i+1}Epoch [12/20], Step [350/600], Loss: 0.5883117914199829, Test Accuracy: 82.81%\n",
      "{i+1}Epoch [12/20], Step [400/600], Loss: 0.5580518841743469, Test Accuracy: 82.67%\n",
      "{i+1}Epoch [12/20], Step [450/600], Loss: 0.5805593729019165, Test Accuracy: 82.79%\n",
      "{i+1}Epoch [12/20], Step [500/600], Loss: 0.518073558807373, Test Accuracy: 82.9%\n",
      "{i+1}Epoch [12/20], Step [550/600], Loss: 0.6037007570266724, Test Accuracy: 82.91%\n",
      "{i+1}Epoch [12/20], Step [600/600], Loss: 0.5075939297676086, Test Accuracy: 82.24%\n",
      "{i+1}Epoch [13/20], Step [50/600], Loss: 0.5865005850791931, Test Accuracy: 83.21%\n",
      "{i+1}Epoch [13/20], Step [100/600], Loss: 0.5044441819190979, Test Accuracy: 82.69%\n",
      "{i+1}Epoch [13/20], Step [150/600], Loss: 0.5236326456069946, Test Accuracy: 82.53%\n",
      "{i+1}Epoch [13/20], Step [200/600], Loss: 0.5027886033058167, Test Accuracy: 82.86%\n",
      "{i+1}Epoch [13/20], Step [250/600], Loss: 0.541614294052124, Test Accuracy: 83.4%\n",
      "{i+1}Epoch [13/20], Step [300/600], Loss: 0.5696238875389099, Test Accuracy: 83.07%\n",
      "{i+1}Epoch [13/20], Step [350/600], Loss: 0.5516170263290405, Test Accuracy: 82.89%\n",
      "{i+1}Epoch [13/20], Step [400/600], Loss: 0.5678413510322571, Test Accuracy: 83.44%\n",
      "{i+1}Epoch [13/20], Step [450/600], Loss: 0.5251701474189758, Test Accuracy: 83.59%\n",
      "{i+1}Epoch [13/20], Step [500/600], Loss: 0.538290798664093, Test Accuracy: 83.16%\n",
      "{i+1}Epoch [13/20], Step [550/600], Loss: 0.5886088013648987, Test Accuracy: 83.28%\n",
      "{i+1}Epoch [13/20], Step [600/600], Loss: 0.5619421601295471, Test Accuracy: 83.48%\n",
      "{i+1}Epoch [14/20], Step [50/600], Loss: 0.5544118285179138, Test Accuracy: 83.62%\n",
      "{i+1}Epoch [14/20], Step [100/600], Loss: 0.5272451043128967, Test Accuracy: 83.37%\n",
      "{i+1}Epoch [14/20], Step [150/600], Loss: 0.5627619028091431, Test Accuracy: 83.24%\n",
      "{i+1}Epoch [14/20], Step [200/600], Loss: 0.5772106647491455, Test Accuracy: 83.52%\n",
      "{i+1}Epoch [14/20], Step [250/600], Loss: 0.538012683391571, Test Accuracy: 83.7%\n",
      "{i+1}Epoch [14/20], Step [300/600], Loss: 0.5324190855026245, Test Accuracy: 83.15%\n",
      "{i+1}Epoch [14/20], Step [350/600], Loss: 0.4954959452152252, Test Accuracy: 83.12%\n",
      "{i+1}Epoch [14/20], Step [400/600], Loss: 0.5567314028739929, Test Accuracy: 83.4%\n",
      "{i+1}Epoch [14/20], Step [450/600], Loss: 0.5213362574577332, Test Accuracy: 83.18%\n",
      "{i+1}Epoch [14/20], Step [500/600], Loss: 0.5996188521385193, Test Accuracy: 83.28%\n",
      "{i+1}Epoch [14/20], Step [550/600], Loss: 0.5598908066749573, Test Accuracy: 82.95%\n",
      "{i+1}Epoch [14/20], Step [600/600], Loss: 0.5624508261680603, Test Accuracy: 83.02%\n",
      "{i+1}Epoch [15/20], Step [50/600], Loss: 0.5511188507080078, Test Accuracy: 83.45%\n",
      "{i+1}Epoch [15/20], Step [100/600], Loss: 0.5559157729148865, Test Accuracy: 83.35%\n",
      "{i+1}Epoch [15/20], Step [150/600], Loss: 0.578133761882782, Test Accuracy: 83.49%\n",
      "{i+1}Epoch [15/20], Step [200/600], Loss: 0.5427005290985107, Test Accuracy: 83.41%\n",
      "{i+1}Epoch [15/20], Step [250/600], Loss: 0.5553430914878845, Test Accuracy: 83.98%\n",
      "{i+1}Epoch [15/20], Step [300/600], Loss: 0.5394712686538696, Test Accuracy: 83.09%\n",
      "{i+1}Epoch [15/20], Step [350/600], Loss: 0.5533386468887329, Test Accuracy: 83.93%\n",
      "{i+1}Epoch [15/20], Step [400/600], Loss: 0.5358017086982727, Test Accuracy: 84.11%\n",
      "{i+1}Epoch [15/20], Step [450/600], Loss: 0.5457637906074524, Test Accuracy: 83.87%\n",
      "{i+1}Epoch [15/20], Step [500/600], Loss: 0.5660789012908936, Test Accuracy: 83.76%\n",
      "{i+1}Epoch [15/20], Step [550/600], Loss: 0.5310349464416504, Test Accuracy: 83.84%\n",
      "{i+1}Epoch [15/20], Step [600/600], Loss: 0.5732274055480957, Test Accuracy: 83.73%\n",
      "{i+1}Epoch [16/20], Step [50/600], Loss: 0.5150988101959229, Test Accuracy: 83.73%\n",
      "{i+1}Epoch [16/20], Step [100/600], Loss: 0.533881425857544, Test Accuracy: 84.31%\n",
      "{i+1}Epoch [16/20], Step [150/600], Loss: 0.5823211669921875, Test Accuracy: 83.38%\n",
      "{i+1}Epoch [16/20], Step [200/600], Loss: 0.5945545434951782, Test Accuracy: 83.66%\n",
      "{i+1}Epoch [16/20], Step [250/600], Loss: 0.5371842384338379, Test Accuracy: 83.72%\n",
      "{i+1}Epoch [16/20], Step [300/600], Loss: 0.5426217317581177, Test Accuracy: 83.94%\n",
      "{i+1}Epoch [16/20], Step [350/600], Loss: 0.5338446497917175, Test Accuracy: 83.89%\n",
      "{i+1}Epoch [16/20], Step [400/600], Loss: 0.5177828073501587, Test Accuracy: 83.58%\n",
      "{i+1}Epoch [16/20], Step [450/600], Loss: 0.5212513208389282, Test Accuracy: 83.71%\n",
      "{i+1}Epoch [16/20], Step [500/600], Loss: 0.5277199149131775, Test Accuracy: 83.76%\n",
      "{i+1}Epoch [16/20], Step [550/600], Loss: 0.533627450466156, Test Accuracy: 84.07%\n",
      "{i+1}Epoch [16/20], Step [600/600], Loss: 0.5040366649627686, Test Accuracy: 84.1%\n",
      "{i+1}Epoch [17/20], Step [50/600], Loss: 0.4982941150665283, Test Accuracy: 84.37%\n",
      "{i+1}Epoch [17/20], Step [100/600], Loss: 0.5091530084609985, Test Accuracy: 83.67%\n",
      "{i+1}Epoch [17/20], Step [150/600], Loss: 0.46691107749938965, Test Accuracy: 83.97%\n",
      "{i+1}Epoch [17/20], Step [200/600], Loss: 0.5072624683380127, Test Accuracy: 84.35%\n",
      "{i+1}Epoch [17/20], Step [250/600], Loss: 0.5061625242233276, Test Accuracy: 83.51%\n",
      "{i+1}Epoch [17/20], Step [300/600], Loss: 0.5135461688041687, Test Accuracy: 83.8%\n",
      "{i+1}Epoch [17/20], Step [350/600], Loss: 0.4994220733642578, Test Accuracy: 83.99%\n",
      "{i+1}Epoch [17/20], Step [400/600], Loss: 0.5023605823516846, Test Accuracy: 83.76%\n",
      "{i+1}Epoch [17/20], Step [450/600], Loss: 0.4963570535182953, Test Accuracy: 84.11%\n",
      "{i+1}Epoch [17/20], Step [500/600], Loss: 0.5550578236579895, Test Accuracy: 84.19%\n",
      "{i+1}Epoch [17/20], Step [550/600], Loss: 0.5189771056175232, Test Accuracy: 84.1%\n",
      "{i+1}Epoch [17/20], Step [600/600], Loss: 0.48998817801475525, Test Accuracy: 83.61%\n",
      "{i+1}Epoch [18/20], Step [50/600], Loss: 0.5338230133056641, Test Accuracy: 82.93%\n",
      "{i+1}Epoch [18/20], Step [100/600], Loss: 0.508905291557312, Test Accuracy: 84.03%\n",
      "{i+1}Epoch [18/20], Step [150/600], Loss: 0.4930179715156555, Test Accuracy: 83.91%\n",
      "{i+1}Epoch [18/20], Step [200/600], Loss: 0.501886785030365, Test Accuracy: 84.2%\n",
      "{i+1}Epoch [18/20], Step [250/600], Loss: 0.4931272268295288, Test Accuracy: 84.14%\n",
      "{i+1}Epoch [18/20], Step [300/600], Loss: 0.5230007171630859, Test Accuracy: 84.03%\n",
      "{i+1}Epoch [18/20], Step [350/600], Loss: 0.4984970986843109, Test Accuracy: 84.48%\n",
      "{i+1}Epoch [18/20], Step [400/600], Loss: 0.5005596280097961, Test Accuracy: 83.78%\n",
      "{i+1}Epoch [18/20], Step [450/600], Loss: 0.5366240739822388, Test Accuracy: 84.43%\n",
      "{i+1}Epoch [18/20], Step [500/600], Loss: 0.5317062139511108, Test Accuracy: 84.16%\n",
      "{i+1}Epoch [18/20], Step [550/600], Loss: 0.521586537361145, Test Accuracy: 84.53%\n",
      "{i+1}Epoch [18/20], Step [600/600], Loss: 0.4992945194244385, Test Accuracy: 83.9%\n",
      "{i+1}Epoch [19/20], Step [50/600], Loss: 0.4968841075897217, Test Accuracy: 84.15%\n",
      "{i+1}Epoch [19/20], Step [100/600], Loss: 0.5300570130348206, Test Accuracy: 84.17%\n",
      "{i+1}Epoch [19/20], Step [150/600], Loss: 0.5210209488868713, Test Accuracy: 84.14%\n",
      "{i+1}Epoch [19/20], Step [200/600], Loss: 0.48328468203544617, Test Accuracy: 84.11%\n",
      "{i+1}Epoch [19/20], Step [250/600], Loss: 0.5067163705825806, Test Accuracy: 84.67%\n",
      "{i+1}Epoch [19/20], Step [300/600], Loss: 0.5308693051338196, Test Accuracy: 84.25%\n",
      "{i+1}Epoch [19/20], Step [350/600], Loss: 0.5016534328460693, Test Accuracy: 84.5%\n",
      "{i+1}Epoch [19/20], Step [400/600], Loss: 0.49978315830230713, Test Accuracy: 84.28%\n",
      "{i+1}Epoch [19/20], Step [450/600], Loss: 0.4945095181465149, Test Accuracy: 84.42%\n",
      "{i+1}Epoch [19/20], Step [500/600], Loss: 0.49592217803001404, Test Accuracy: 84.23%\n",
      "{i+1}Epoch [19/20], Step [550/600], Loss: 0.5012954473495483, Test Accuracy: 84.37%\n",
      "{i+1}Epoch [19/20], Step [600/600], Loss: 0.49270325899124146, Test Accuracy: 84.38%\n",
      "{i+1}Epoch [20/20], Step [50/600], Loss: 0.47400858998298645, Test Accuracy: 84.66%\n",
      "{i+1}Epoch [20/20], Step [100/600], Loss: 0.4744512140750885, Test Accuracy: 84.86%\n",
      "{i+1}Epoch [20/20], Step [150/600], Loss: 0.5189858078956604, Test Accuracy: 84.66%\n",
      "{i+1}Epoch [20/20], Step [200/600], Loss: 0.5075104236602783, Test Accuracy: 84.31%\n",
      "{i+1}Epoch [20/20], Step [250/600], Loss: 0.4844287931919098, Test Accuracy: 84.74%\n",
      "{i+1}Epoch [20/20], Step [300/600], Loss: 0.519056499004364, Test Accuracy: 84.38%\n",
      "{i+1}Epoch [20/20], Step [350/600], Loss: 0.4955715835094452, Test Accuracy: 84.36%\n",
      "{i+1}Epoch [20/20], Step [400/600], Loss: 0.4795858860015869, Test Accuracy: 84.51%\n",
      "{i+1}Epoch [20/20], Step [450/600], Loss: 0.4569658935070038, Test Accuracy: 84.91%\n",
      "{i+1}Epoch [20/20], Step [500/600], Loss: 0.5061218738555908, Test Accuracy: 84.29%\n",
      "{i+1}Epoch [20/20], Step [550/600], Loss: 0.48530909419059753, Test Accuracy: 84.65%\n",
      "{i+1}Epoch [20/20], Step [600/600], Loss: 0.5054969191551208, Test Accuracy: 84.36%\n",
      "200\n",
      "Using cuda device\n",
      "Tiny_convnet(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "{i+1}Epoch [1/20], Step [50/600], Loss: 2.2137229442596436, Test Accuracy: 13.39%\n",
      "{i+1}Epoch [1/20], Step [100/600], Loss: 1.7869857549667358, Test Accuracy: 35.91%\n",
      "{i+1}Epoch [1/20], Step [150/600], Loss: 1.2840690612792969, Test Accuracy: 57.14%\n",
      "{i+1}Epoch [1/20], Step [200/600], Loss: 1.071500301361084, Test Accuracy: 61.3%\n",
      "{i+1}Epoch [1/20], Step [250/600], Loss: 0.9636204242706299, Test Accuracy: 64.99%\n",
      "{i+1}Epoch [1/20], Step [300/600], Loss: 0.8355530500411987, Test Accuracy: 65.78%\n",
      "{i+1}Epoch [1/20], Step [350/600], Loss: 0.8398587107658386, Test Accuracy: 71.96%\n",
      "{i+1}Epoch [1/20], Step [400/600], Loss: 0.7320219278335571, Test Accuracy: 70.02%\n",
      "{i+1}Epoch [1/20], Step [450/600], Loss: 0.7774530053138733, Test Accuracy: 71.22%\n",
      "{i+1}Epoch [1/20], Step [500/600], Loss: 0.7832939624786377, Test Accuracy: 74.18%\n",
      "{i+1}Epoch [1/20], Step [550/600], Loss: 0.8941903114318848, Test Accuracy: 73.09%\n",
      "{i+1}Epoch [1/20], Step [600/600], Loss: 0.7498400211334229, Test Accuracy: 72.66%\n",
      "{i+1}Epoch [2/20], Step [50/600], Loss: 0.716735303401947, Test Accuracy: 75.29%\n",
      "{i+1}Epoch [2/20], Step [100/600], Loss: 0.7907626628875732, Test Accuracy: 73.83%\n",
      "{i+1}Epoch [2/20], Step [150/600], Loss: 0.7229089140892029, Test Accuracy: 76.42%\n",
      "{i+1}Epoch [2/20], Step [200/600], Loss: 0.7365657091140747, Test Accuracy: 74.71%\n",
      "{i+1}Epoch [2/20], Step [250/600], Loss: 0.814302384853363, Test Accuracy: 74.4%\n",
      "{i+1}Epoch [2/20], Step [300/600], Loss: 0.673676609992981, Test Accuracy: 76.66%\n",
      "{i+1}Epoch [2/20], Step [350/600], Loss: 0.6722733378410339, Test Accuracy: 73.02%\n",
      "{i+1}Epoch [2/20], Step [400/600], Loss: 0.6889024376869202, Test Accuracy: 77.84%\n",
      "{i+1}Epoch [2/20], Step [450/600], Loss: 0.7096259593963623, Test Accuracy: 74.94%\n",
      "{i+1}Epoch [2/20], Step [500/600], Loss: 0.7475870251655579, Test Accuracy: 77.42%\n",
      "{i+1}Epoch [2/20], Step [550/600], Loss: 0.7120195031166077, Test Accuracy: 78.19%\n",
      "{i+1}Epoch [2/20], Step [600/600], Loss: 0.6437579393386841, Test Accuracy: 78.35%\n",
      "{i+1}Epoch [3/20], Step [50/600], Loss: 0.6207337975502014, Test Accuracy: 78.41%\n",
      "{i+1}Epoch [3/20], Step [100/600], Loss: 0.6593328714370728, Test Accuracy: 78.4%\n",
      "{i+1}Epoch [3/20], Step [150/600], Loss: 0.6821059584617615, Test Accuracy: 78.54%\n",
      "{i+1}Epoch [3/20], Step [200/600], Loss: 0.5794112682342529, Test Accuracy: 78.84%\n",
      "{i+1}Epoch [3/20], Step [250/600], Loss: 0.6762059926986694, Test Accuracy: 80.15%\n",
      "{i+1}Epoch [3/20], Step [300/600], Loss: 0.6745518445968628, Test Accuracy: 79.09%\n",
      "{i+1}Epoch [3/20], Step [350/600], Loss: 0.6518816351890564, Test Accuracy: 79.8%\n",
      "{i+1}Epoch [3/20], Step [400/600], Loss: 0.7424638271331787, Test Accuracy: 80.29%\n",
      "{i+1}Epoch [3/20], Step [450/600], Loss: 0.57932049036026, Test Accuracy: 79.86%\n",
      "{i+1}Epoch [3/20], Step [500/600], Loss: 0.5877435207366943, Test Accuracy: 80.12%\n",
      "{i+1}Epoch [3/20], Step [550/600], Loss: 0.6295322179794312, Test Accuracy: 80.52%\n",
      "{i+1}Epoch [3/20], Step [600/600], Loss: 0.6324775815010071, Test Accuracy: 79.89%\n",
      "{i+1}Epoch [4/20], Step [50/600], Loss: 0.6257072687149048, Test Accuracy: 79.9%\n",
      "{i+1}Epoch [4/20], Step [100/600], Loss: 0.5997632741928101, Test Accuracy: 80.55%\n",
      "{i+1}Epoch [4/20], Step [150/600], Loss: 0.5753766894340515, Test Accuracy: 80.8%\n",
      "{i+1}Epoch [4/20], Step [200/600], Loss: 0.5893007516860962, Test Accuracy: 80.93%\n",
      "{i+1}Epoch [4/20], Step [250/600], Loss: 0.5272994041442871, Test Accuracy: 81.39%\n",
      "{i+1}Epoch [4/20], Step [300/600], Loss: 0.6041267514228821, Test Accuracy: 80.79%\n",
      "{i+1}Epoch [4/20], Step [350/600], Loss: 0.6085503101348877, Test Accuracy: 79.18%\n",
      "{i+1}Epoch [4/20], Step [400/600], Loss: 0.5821265578269958, Test Accuracy: 80.91%\n",
      "{i+1}Epoch [4/20], Step [450/600], Loss: 0.6371504068374634, Test Accuracy: 80.73%\n",
      "{i+1}Epoch [4/20], Step [500/600], Loss: 0.6853885054588318, Test Accuracy: 81.79%\n",
      "{i+1}Epoch [4/20], Step [550/600], Loss: 0.687160849571228, Test Accuracy: 81.0%\n",
      "{i+1}Epoch [4/20], Step [600/600], Loss: 0.6622145771980286, Test Accuracy: 81.5%\n",
      "{i+1}Epoch [5/20], Step [50/600], Loss: 0.5772539973258972, Test Accuracy: 80.84%\n",
      "{i+1}Epoch [5/20], Step [100/600], Loss: 0.6030075550079346, Test Accuracy: 80.97%\n",
      "{i+1}Epoch [5/20], Step [150/600], Loss: 0.5552126169204712, Test Accuracy: 81.97%\n",
      "{i+1}Epoch [5/20], Step [200/600], Loss: 0.4990917146205902, Test Accuracy: 81.04%\n",
      "{i+1}Epoch [5/20], Step [250/600], Loss: 0.49101465940475464, Test Accuracy: 81.74%\n",
      "{i+1}Epoch [5/20], Step [300/600], Loss: 0.620914101600647, Test Accuracy: 82.02%\n",
      "{i+1}Epoch [5/20], Step [350/600], Loss: 0.5796071887016296, Test Accuracy: 81.98%\n",
      "{i+1}Epoch [5/20], Step [400/600], Loss: 0.5320020914077759, Test Accuracy: 79.6%\n",
      "{i+1}Epoch [5/20], Step [450/600], Loss: 0.5979769229888916, Test Accuracy: 82.5%\n",
      "{i+1}Epoch [5/20], Step [500/600], Loss: 0.5419248938560486, Test Accuracy: 82.16%\n",
      "{i+1}Epoch [5/20], Step [550/600], Loss: 0.6107800006866455, Test Accuracy: 82.47%\n",
      "{i+1}Epoch [5/20], Step [600/600], Loss: 0.5527978539466858, Test Accuracy: 82.31%\n",
      "{i+1}Epoch [6/20], Step [50/600], Loss: 0.5128008723258972, Test Accuracy: 82.79%\n",
      "{i+1}Epoch [6/20], Step [100/600], Loss: 0.5286086797714233, Test Accuracy: 82.81%\n",
      "{i+1}Epoch [6/20], Step [150/600], Loss: 0.5061930418014526, Test Accuracy: 82.04%\n",
      "{i+1}Epoch [6/20], Step [200/600], Loss: 0.647727370262146, Test Accuracy: 83.02%\n",
      "{i+1}Epoch [6/20], Step [250/600], Loss: 0.5335084795951843, Test Accuracy: 82.39%\n",
      "{i+1}Epoch [6/20], Step [300/600], Loss: 0.5628562569618225, Test Accuracy: 82.2%\n",
      "{i+1}Epoch [6/20], Step [350/600], Loss: 0.560609757900238, Test Accuracy: 82.95%\n",
      "{i+1}Epoch [6/20], Step [400/600], Loss: 0.5032562017440796, Test Accuracy: 82.18%\n",
      "{i+1}Epoch [6/20], Step [450/600], Loss: 0.540884256362915, Test Accuracy: 83.31%\n",
      "{i+1}Epoch [6/20], Step [500/600], Loss: 0.5288559198379517, Test Accuracy: 83.18%\n",
      "{i+1}Epoch [6/20], Step [550/600], Loss: 0.6050947904586792, Test Accuracy: 83.21%\n",
      "{i+1}Epoch [6/20], Step [600/600], Loss: 0.6164278984069824, Test Accuracy: 83.5%\n",
      "{i+1}Epoch [7/20], Step [50/600], Loss: 0.6371949315071106, Test Accuracy: 83.5%\n",
      "{i+1}Epoch [7/20], Step [100/600], Loss: 0.5523447394371033, Test Accuracy: 83.8%\n",
      "{i+1}Epoch [7/20], Step [150/600], Loss: 0.49049949645996094, Test Accuracy: 83.66%\n",
      "{i+1}Epoch [7/20], Step [200/600], Loss: 0.5018209218978882, Test Accuracy: 83.52%\n",
      "{i+1}Epoch [7/20], Step [250/600], Loss: 0.4541955590248108, Test Accuracy: 83.25%\n",
      "{i+1}Epoch [7/20], Step [300/600], Loss: 0.5002511739730835, Test Accuracy: 83.48%\n",
      "{i+1}Epoch [7/20], Step [350/600], Loss: 0.5431431531906128, Test Accuracy: 83.25%\n",
      "{i+1}Epoch [7/20], Step [400/600], Loss: 0.47506675124168396, Test Accuracy: 83.93%\n",
      "{i+1}Epoch [7/20], Step [450/600], Loss: 0.5181336402893066, Test Accuracy: 83.4%\n",
      "{i+1}Epoch [7/20], Step [500/600], Loss: 0.5384893417358398, Test Accuracy: 83.82%\n",
      "{i+1}Epoch [7/20], Step [550/600], Loss: 0.5584537386894226, Test Accuracy: 83.01%\n",
      "{i+1}Epoch [7/20], Step [600/600], Loss: 0.5400165319442749, Test Accuracy: 82.49%\n",
      "{i+1}Epoch [8/20], Step [50/600], Loss: 0.5226831436157227, Test Accuracy: 84.23%\n",
      "{i+1}Epoch [8/20], Step [100/600], Loss: 0.5191942453384399, Test Accuracy: 84.21%\n",
      "{i+1}Epoch [8/20], Step [150/600], Loss: 0.5140232443809509, Test Accuracy: 83.6%\n",
      "{i+1}Epoch [8/20], Step [200/600], Loss: 0.4807492792606354, Test Accuracy: 83.89%\n",
      "{i+1}Epoch [8/20], Step [250/600], Loss: 0.5112966895103455, Test Accuracy: 84.03%\n",
      "{i+1}Epoch [8/20], Step [300/600], Loss: 0.49599701166152954, Test Accuracy: 84.47%\n",
      "{i+1}Epoch [8/20], Step [350/600], Loss: 0.5199877023696899, Test Accuracy: 84.33%\n",
      "{i+1}Epoch [8/20], Step [400/600], Loss: 0.5079670548439026, Test Accuracy: 83.99%\n",
      "{i+1}Epoch [8/20], Step [450/600], Loss: 0.5174089074134827, Test Accuracy: 84.18%\n",
      "{i+1}Epoch [8/20], Step [500/600], Loss: 0.534055769443512, Test Accuracy: 83.83%\n",
      "{i+1}Epoch [8/20], Step [550/600], Loss: 0.5768953561782837, Test Accuracy: 83.53%\n",
      "{i+1}Epoch [8/20], Step [600/600], Loss: 0.5001741647720337, Test Accuracy: 83.65%\n",
      "{i+1}Epoch [9/20], Step [50/600], Loss: 0.5102959871292114, Test Accuracy: 83.81%\n",
      "{i+1}Epoch [9/20], Step [100/600], Loss: 0.5596637725830078, Test Accuracy: 83.95%\n",
      "{i+1}Epoch [9/20], Step [150/600], Loss: 0.5026450753211975, Test Accuracy: 83.72%\n",
      "{i+1}Epoch [9/20], Step [200/600], Loss: 0.4826657176017761, Test Accuracy: 84.26%\n",
      "{i+1}Epoch [9/20], Step [250/600], Loss: 0.5129215717315674, Test Accuracy: 83.47%\n",
      "{i+1}Epoch [9/20], Step [300/600], Loss: 0.5467472076416016, Test Accuracy: 84.54%\n",
      "{i+1}Epoch [9/20], Step [350/600], Loss: 0.5294687747955322, Test Accuracy: 84.17%\n",
      "{i+1}Epoch [9/20], Step [400/600], Loss: 0.491746723651886, Test Accuracy: 84.13%\n",
      "{i+1}Epoch [9/20], Step [450/600], Loss: 0.4656497538089752, Test Accuracy: 84.5%\n",
      "{i+1}Epoch [9/20], Step [500/600], Loss: 0.5171236991882324, Test Accuracy: 84.35%\n",
      "{i+1}Epoch [9/20], Step [550/600], Loss: 0.48545193672180176, Test Accuracy: 84.24%\n",
      "{i+1}Epoch [9/20], Step [600/600], Loss: 0.5451407432556152, Test Accuracy: 84.67%\n",
      "{i+1}Epoch [10/20], Step [50/600], Loss: 0.5699718594551086, Test Accuracy: 84.39%\n",
      "{i+1}Epoch [10/20], Step [100/600], Loss: 0.5318189859390259, Test Accuracy: 84.47%\n",
      "{i+1}Epoch [10/20], Step [150/600], Loss: 0.5202690362930298, Test Accuracy: 84.47%\n",
      "{i+1}Epoch [10/20], Step [200/600], Loss: 0.5239954590797424, Test Accuracy: 84.6%\n",
      "{i+1}Epoch [10/20], Step [250/600], Loss: 0.47874584794044495, Test Accuracy: 84.47%\n",
      "{i+1}Epoch [10/20], Step [300/600], Loss: 0.4879717230796814, Test Accuracy: 84.58%\n",
      "{i+1}Epoch [10/20], Step [350/600], Loss: 0.4753096401691437, Test Accuracy: 84.94%\n",
      "{i+1}Epoch [10/20], Step [400/600], Loss: 0.5289464592933655, Test Accuracy: 85.08%\n",
      "{i+1}Epoch [10/20], Step [450/600], Loss: 0.4694768786430359, Test Accuracy: 85.07%\n",
      "{i+1}Epoch [10/20], Step [500/600], Loss: 0.47152864933013916, Test Accuracy: 84.41%\n",
      "{i+1}Epoch [10/20], Step [550/600], Loss: 0.5140836238861084, Test Accuracy: 84.76%\n",
      "{i+1}Epoch [10/20], Step [600/600], Loss: 0.5016175508499146, Test Accuracy: 84.98%\n",
      "{i+1}Epoch [11/20], Step [50/600], Loss: 0.472370445728302, Test Accuracy: 84.74%\n",
      "{i+1}Epoch [11/20], Step [100/600], Loss: 0.5053533911705017, Test Accuracy: 84.99%\n",
      "{i+1}Epoch [11/20], Step [150/600], Loss: 0.5083215832710266, Test Accuracy: 84.64%\n",
      "{i+1}Epoch [11/20], Step [200/600], Loss: 0.4808776080608368, Test Accuracy: 84.63%\n",
      "{i+1}Epoch [11/20], Step [250/600], Loss: 0.5499390363693237, Test Accuracy: 85.27%\n",
      "{i+1}Epoch [11/20], Step [300/600], Loss: 0.510758638381958, Test Accuracy: 85.02%\n",
      "{i+1}Epoch [11/20], Step [350/600], Loss: 0.4647129774093628, Test Accuracy: 84.78%\n",
      "{i+1}Epoch [11/20], Step [400/600], Loss: 0.5184473991394043, Test Accuracy: 84.85%\n",
      "{i+1}Epoch [11/20], Step [450/600], Loss: 0.49914807081222534, Test Accuracy: 84.61%\n",
      "{i+1}Epoch [11/20], Step [500/600], Loss: 0.49011150002479553, Test Accuracy: 84.45%\n",
      "{i+1}Epoch [11/20], Step [550/600], Loss: 0.45228302478790283, Test Accuracy: 85.32%\n",
      "{i+1}Epoch [11/20], Step [600/600], Loss: 0.45559123158454895, Test Accuracy: 85.3%\n",
      "{i+1}Epoch [12/20], Step [50/600], Loss: 0.510331928730011, Test Accuracy: 85.44%\n",
      "{i+1}Epoch [12/20], Step [100/600], Loss: 0.46173417568206787, Test Accuracy: 84.94%\n",
      "{i+1}Epoch [12/20], Step [150/600], Loss: 0.4644528925418854, Test Accuracy: 85.15%\n",
      "{i+1}Epoch [12/20], Step [200/600], Loss: 0.47298702597618103, Test Accuracy: 85.08%\n",
      "{i+1}Epoch [12/20], Step [250/600], Loss: 0.45907241106033325, Test Accuracy: 85.15%\n",
      "{i+1}Epoch [12/20], Step [300/600], Loss: 0.4931219220161438, Test Accuracy: 85.01%\n",
      "{i+1}Epoch [12/20], Step [350/600], Loss: 0.47308704257011414, Test Accuracy: 84.75%\n",
      "{i+1}Epoch [12/20], Step [400/600], Loss: 0.5119432806968689, Test Accuracy: 83.87%\n",
      "{i+1}Epoch [12/20], Step [450/600], Loss: 0.4552287757396698, Test Accuracy: 85.56%\n",
      "{i+1}Epoch [12/20], Step [500/600], Loss: 0.4753056466579437, Test Accuracy: 84.46%\n",
      "{i+1}Epoch [12/20], Step [550/600], Loss: 0.4611571431159973, Test Accuracy: 85.14%\n",
      "{i+1}Epoch [12/20], Step [600/600], Loss: 0.4784708023071289, Test Accuracy: 85.43%\n",
      "{i+1}Epoch [13/20], Step [50/600], Loss: 0.4573118984699249, Test Accuracy: 85.63%\n",
      "{i+1}Epoch [13/20], Step [100/600], Loss: 0.47645047307014465, Test Accuracy: 85.28%\n",
      "{i+1}Epoch [13/20], Step [150/600], Loss: 0.45887288451194763, Test Accuracy: 85.18%\n",
      "{i+1}Epoch [13/20], Step [200/600], Loss: 0.5333422422409058, Test Accuracy: 85.13%\n",
      "{i+1}Epoch [13/20], Step [250/600], Loss: 0.4875018000602722, Test Accuracy: 85.13%\n",
      "{i+1}Epoch [13/20], Step [300/600], Loss: 0.4292188286781311, Test Accuracy: 84.97%\n",
      "{i+1}Epoch [13/20], Step [350/600], Loss: 0.4691197872161865, Test Accuracy: 85.07%\n",
      "{i+1}Epoch [13/20], Step [400/600], Loss: 0.46312960982322693, Test Accuracy: 84.93%\n",
      "{i+1}Epoch [13/20], Step [450/600], Loss: 0.4679076671600342, Test Accuracy: 84.32%\n",
      "{i+1}Epoch [13/20], Step [500/600], Loss: 0.4232591986656189, Test Accuracy: 85.27%\n",
      "{i+1}Epoch [13/20], Step [550/600], Loss: 0.47536933422088623, Test Accuracy: 85.19%\n",
      "{i+1}Epoch [13/20], Step [600/600], Loss: 0.48419472575187683, Test Accuracy: 85.79%\n",
      "{i+1}Epoch [14/20], Step [50/600], Loss: 0.4759954810142517, Test Accuracy: 85.11%\n",
      "{i+1}Epoch [14/20], Step [100/600], Loss: 0.43059009313583374, Test Accuracy: 85.68%\n",
      "{i+1}Epoch [14/20], Step [150/600], Loss: 0.484083890914917, Test Accuracy: 85.27%\n",
      "{i+1}Epoch [14/20], Step [200/600], Loss: 0.4412548542022705, Test Accuracy: 85.45%\n",
      "{i+1}Epoch [14/20], Step [250/600], Loss: 0.44728007912635803, Test Accuracy: 85.42%\n",
      "{i+1}Epoch [14/20], Step [300/600], Loss: 0.47629719972610474, Test Accuracy: 85.81%\n",
      "{i+1}Epoch [14/20], Step [350/600], Loss: 0.4198545813560486, Test Accuracy: 85.29%\n",
      "{i+1}Epoch [14/20], Step [400/600], Loss: 0.45376065373420715, Test Accuracy: 85.81%\n",
      "{i+1}Epoch [14/20], Step [450/600], Loss: 0.4910275936126709, Test Accuracy: 85.62%\n",
      "{i+1}Epoch [14/20], Step [500/600], Loss: 0.4688882827758789, Test Accuracy: 85.85%\n",
      "{i+1}Epoch [14/20], Step [550/600], Loss: 0.4202525317668915, Test Accuracy: 85.26%\n",
      "{i+1}Epoch [14/20], Step [600/600], Loss: 0.4332026243209839, Test Accuracy: 85.89%\n",
      "{i+1}Epoch [15/20], Step [50/600], Loss: 0.42368942499160767, Test Accuracy: 85.2%\n",
      "{i+1}Epoch [15/20], Step [100/600], Loss: 0.4513290524482727, Test Accuracy: 85.17%\n",
      "{i+1}Epoch [15/20], Step [150/600], Loss: 0.42573821544647217, Test Accuracy: 85.48%\n",
      "{i+1}Epoch [15/20], Step [200/600], Loss: 0.4446549117565155, Test Accuracy: 85.94%\n",
      "{i+1}Epoch [15/20], Step [250/600], Loss: 0.4713192284107208, Test Accuracy: 85.44%\n",
      "{i+1}Epoch [15/20], Step [300/600], Loss: 0.4193006157875061, Test Accuracy: 85.9%\n",
      "{i+1}Epoch [15/20], Step [350/600], Loss: 0.43276524543762207, Test Accuracy: 85.94%\n",
      "{i+1}Epoch [15/20], Step [400/600], Loss: 0.45178136229515076, Test Accuracy: 85.65%\n",
      "{i+1}Epoch [15/20], Step [450/600], Loss: 0.46130165457725525, Test Accuracy: 85.26%\n",
      "{i+1}Epoch [15/20], Step [500/600], Loss: 0.4586503207683563, Test Accuracy: 86.06%\n",
      "{i+1}Epoch [15/20], Step [550/600], Loss: 0.4566744863986969, Test Accuracy: 85.58%\n",
      "{i+1}Epoch [15/20], Step [600/600], Loss: 0.42506492137908936, Test Accuracy: 85.22%\n",
      "{i+1}Epoch [16/20], Step [50/600], Loss: 0.44536831974983215, Test Accuracy: 85.92%\n",
      "{i+1}Epoch [16/20], Step [100/600], Loss: 0.4464510381221771, Test Accuracy: 85.98%\n",
      "{i+1}Epoch [16/20], Step [150/600], Loss: 0.44845059514045715, Test Accuracy: 85.89%\n",
      "{i+1}Epoch [16/20], Step [200/600], Loss: 0.44784656167030334, Test Accuracy: 85.86%\n",
      "{i+1}Epoch [16/20], Step [250/600], Loss: 0.4000670909881592, Test Accuracy: 85.44%\n",
      "{i+1}Epoch [16/20], Step [300/600], Loss: 0.46693724393844604, Test Accuracy: 85.08%\n",
      "{i+1}Epoch [16/20], Step [350/600], Loss: 0.4176540672779083, Test Accuracy: 86.04%\n",
      "{i+1}Epoch [16/20], Step [400/600], Loss: 0.4363665282726288, Test Accuracy: 85.51%\n",
      "{i+1}Epoch [16/20], Step [450/600], Loss: 0.4976862370967865, Test Accuracy: 85.27%\n",
      "{i+1}Epoch [16/20], Step [500/600], Loss: 0.43567293882369995, Test Accuracy: 85.84%\n",
      "{i+1}Epoch [16/20], Step [550/600], Loss: 0.4093889594078064, Test Accuracy: 85.95%\n",
      "{i+1}Epoch [16/20], Step [600/600], Loss: 0.4174457788467407, Test Accuracy: 86.16%\n",
      "{i+1}Epoch [17/20], Step [50/600], Loss: 0.4047415852546692, Test Accuracy: 85.58%\n",
      "{i+1}Epoch [17/20], Step [100/600], Loss: 0.4337296187877655, Test Accuracy: 85.89%\n",
      "{i+1}Epoch [17/20], Step [150/600], Loss: 0.411685585975647, Test Accuracy: 86.05%\n",
      "{i+1}Epoch [17/20], Step [200/600], Loss: 0.4348422884941101, Test Accuracy: 85.9%\n",
      "{i+1}Epoch [17/20], Step [250/600], Loss: 0.39949101209640503, Test Accuracy: 86.1%\n",
      "{i+1}Epoch [17/20], Step [300/600], Loss: 0.4084949493408203, Test Accuracy: 86.2%\n",
      "{i+1}Epoch [17/20], Step [350/600], Loss: 0.43374279141426086, Test Accuracy: 86.16%\n",
      "{i+1}Epoch [17/20], Step [400/600], Loss: 0.3908432126045227, Test Accuracy: 85.59%\n",
      "{i+1}Epoch [17/20], Step [450/600], Loss: 0.4700548052787781, Test Accuracy: 86.24%\n",
      "{i+1}Epoch [17/20], Step [500/600], Loss: 0.43231239914894104, Test Accuracy: 85.94%\n",
      "{i+1}Epoch [17/20], Step [550/600], Loss: 0.470270037651062, Test Accuracy: 86.13%\n",
      "{i+1}Epoch [17/20], Step [600/600], Loss: 0.45820266008377075, Test Accuracy: 86.04%\n",
      "{i+1}Epoch [18/20], Step [50/600], Loss: 0.4628863036632538, Test Accuracy: 85.9%\n",
      "{i+1}Epoch [18/20], Step [100/600], Loss: 0.46054890751838684, Test Accuracy: 86.15%\n",
      "{i+1}Epoch [18/20], Step [150/600], Loss: 0.4128818213939667, Test Accuracy: 85.81%\n",
      "{i+1}Epoch [18/20], Step [200/600], Loss: 0.45734408497810364, Test Accuracy: 85.2%\n",
      "{i+1}Epoch [18/20], Step [250/600], Loss: 0.4459091126918793, Test Accuracy: 86.03%\n",
      "{i+1}Epoch [18/20], Step [300/600], Loss: 0.404356449842453, Test Accuracy: 85.97%\n",
      "{i+1}Epoch [18/20], Step [350/600], Loss: 0.4578492045402527, Test Accuracy: 85.99%\n",
      "{i+1}Epoch [18/20], Step [400/600], Loss: 0.420622318983078, Test Accuracy: 85.68%\n",
      "{i+1}Epoch [18/20], Step [450/600], Loss: 0.4595109820365906, Test Accuracy: 86.1%\n",
      "{i+1}Epoch [18/20], Step [500/600], Loss: 0.4004470407962799, Test Accuracy: 85.59%\n",
      "{i+1}Epoch [18/20], Step [550/600], Loss: 0.4292565882205963, Test Accuracy: 86.16%\n",
      "{i+1}Epoch [18/20], Step [600/600], Loss: 0.44092193245887756, Test Accuracy: 85.92%\n",
      "{i+1}Epoch [19/20], Step [50/600], Loss: 0.45910000801086426, Test Accuracy: 86.0%\n",
      "{i+1}Epoch [19/20], Step [100/600], Loss: 0.4009256064891815, Test Accuracy: 85.95%\n",
      "{i+1}Epoch [19/20], Step [150/600], Loss: 0.3902722895145416, Test Accuracy: 86.18%\n",
      "{i+1}Epoch [19/20], Step [200/600], Loss: 0.4180118143558502, Test Accuracy: 86.07%\n",
      "{i+1}Epoch [19/20], Step [250/600], Loss: 0.46181416511535645, Test Accuracy: 85.76%\n",
      "{i+1}Epoch [19/20], Step [300/600], Loss: 0.4397318959236145, Test Accuracy: 86.35%\n",
      "{i+1}Epoch [19/20], Step [350/600], Loss: 0.4673527479171753, Test Accuracy: 86.32%\n",
      "{i+1}Epoch [19/20], Step [400/600], Loss: 0.41520145535469055, Test Accuracy: 85.83%\n",
      "{i+1}Epoch [19/20], Step [450/600], Loss: 0.49550461769104004, Test Accuracy: 86.38%\n",
      "{i+1}Epoch [19/20], Step [500/600], Loss: 0.4503762722015381, Test Accuracy: 86.53%\n",
      "{i+1}Epoch [19/20], Step [550/600], Loss: 0.4114494323730469, Test Accuracy: 86.21%\n",
      "{i+1}Epoch [19/20], Step [600/600], Loss: 0.41198962926864624, Test Accuracy: 85.9%\n",
      "{i+1}Epoch [20/20], Step [50/600], Loss: 0.42554083466529846, Test Accuracy: 85.9%\n",
      "{i+1}Epoch [20/20], Step [100/600], Loss: 0.42530035972595215, Test Accuracy: 85.96%\n",
      "{i+1}Epoch [20/20], Step [150/600], Loss: 0.3987618684768677, Test Accuracy: 86.61%\n",
      "{i+1}Epoch [20/20], Step [200/600], Loss: 0.4037160873413086, Test Accuracy: 86.41%\n",
      "{i+1}Epoch [20/20], Step [250/600], Loss: 0.44821837544441223, Test Accuracy: 86.21%\n",
      "{i+1}Epoch [20/20], Step [300/600], Loss: 0.44709938764572144, Test Accuracy: 86.01%\n",
      "{i+1}Epoch [20/20], Step [350/600], Loss: 0.41517174243927, Test Accuracy: 86.21%\n",
      "{i+1}Epoch [20/20], Step [400/600], Loss: 0.44163966178894043, Test Accuracy: 85.56%\n",
      "{i+1}Epoch [20/20], Step [450/600], Loss: 0.4483807384967804, Test Accuracy: 86.57%\n",
      "{i+1}Epoch [20/20], Step [500/600], Loss: 0.4614846110343933, Test Accuracy: 86.06%\n",
      "{i+1}Epoch [20/20], Step [550/600], Loss: 0.43293696641921997, Test Accuracy: 86.36%\n",
      "{i+1}Epoch [20/20], Step [600/600], Loss: 0.4302734136581421, Test Accuracy: 86.24%\n",
      "300\n",
      "Using cuda device\n",
      "Tiny_convnet(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "{i+1}Epoch [1/20], Step [50/600], Loss: 2.035687208175659, Test Accuracy: 25.96%\n",
      "{i+1}Epoch [1/20], Step [100/600], Loss: 1.3940746784210205, Test Accuracy: 54.86%\n",
      "{i+1}Epoch [1/20], Step [150/600], Loss: 1.1849826574325562, Test Accuracy: 63.37%\n",
      "{i+1}Epoch [1/20], Step [200/600], Loss: 1.0145635604858398, Test Accuracy: 67.03%\n",
      "{i+1}Epoch [1/20], Step [250/600], Loss: 0.8049571514129639, Test Accuracy: 67.19%\n",
      "{i+1}Epoch [1/20], Step [300/600], Loss: 0.9112630486488342, Test Accuracy: 69.65%\n",
      "{i+1}Epoch [1/20], Step [350/600], Loss: 0.8237157464027405, Test Accuracy: 71.72%\n",
      "{i+1}Epoch [1/20], Step [400/600], Loss: 0.7814004421234131, Test Accuracy: 72.08%\n",
      "{i+1}Epoch [1/20], Step [450/600], Loss: 0.7746299505233765, Test Accuracy: 75.0%\n",
      "{i+1}Epoch [1/20], Step [500/600], Loss: 0.7288334369659424, Test Accuracy: 74.99%\n",
      "{i+1}Epoch [1/20], Step [550/600], Loss: 0.8161149621009827, Test Accuracy: 74.81%\n",
      "{i+1}Epoch [1/20], Step [600/600], Loss: 0.8109182119369507, Test Accuracy: 74.78%\n",
      "{i+1}Epoch [2/20], Step [50/600], Loss: 0.7331482768058777, Test Accuracy: 76.96%\n",
      "{i+1}Epoch [2/20], Step [100/600], Loss: 0.664796769618988, Test Accuracy: 77.23%\n",
      "{i+1}Epoch [2/20], Step [150/600], Loss: 0.7229278683662415, Test Accuracy: 77.01%\n",
      "{i+1}Epoch [2/20], Step [200/600], Loss: 0.6929733753204346, Test Accuracy: 77.92%\n",
      "{i+1}Epoch [2/20], Step [250/600], Loss: 0.5886090993881226, Test Accuracy: 79.14%\n",
      "{i+1}Epoch [2/20], Step [300/600], Loss: 0.7858182787895203, Test Accuracy: 78.67%\n",
      "{i+1}Epoch [2/20], Step [350/600], Loss: 0.6111684441566467, Test Accuracy: 78.92%\n",
      "{i+1}Epoch [2/20], Step [400/600], Loss: 0.6687229871749878, Test Accuracy: 78.39%\n",
      "{i+1}Epoch [2/20], Step [450/600], Loss: 0.5551006197929382, Test Accuracy: 77.97%\n",
      "{i+1}Epoch [2/20], Step [500/600], Loss: 0.6579856872558594, Test Accuracy: 80.65%\n",
      "{i+1}Epoch [2/20], Step [550/600], Loss: 0.6036727428436279, Test Accuracy: 78.1%\n",
      "{i+1}Epoch [2/20], Step [600/600], Loss: 0.6060228943824768, Test Accuracy: 78.32%\n",
      "{i+1}Epoch [3/20], Step [50/600], Loss: 0.5771297216415405, Test Accuracy: 80.77%\n",
      "{i+1}Epoch [3/20], Step [100/600], Loss: 0.6717913746833801, Test Accuracy: 79.46%\n",
      "{i+1}Epoch [3/20], Step [150/600], Loss: 0.6102375984191895, Test Accuracy: 78.51%\n",
      "{i+1}Epoch [3/20], Step [200/600], Loss: 0.589861273765564, Test Accuracy: 80.73%\n",
      "{i+1}Epoch [3/20], Step [250/600], Loss: 0.686461865901947, Test Accuracy: 80.97%\n",
      "{i+1}Epoch [3/20], Step [300/600], Loss: 0.5662391781806946, Test Accuracy: 79.75%\n",
      "{i+1}Epoch [3/20], Step [350/600], Loss: 0.6128185987472534, Test Accuracy: 80.92%\n",
      "{i+1}Epoch [3/20], Step [400/600], Loss: 0.5427026152610779, Test Accuracy: 81.21%\n",
      "{i+1}Epoch [3/20], Step [450/600], Loss: 0.4908638298511505, Test Accuracy: 78.73%\n",
      "{i+1}Epoch [3/20], Step [500/600], Loss: 0.5413721203804016, Test Accuracy: 81.62%\n",
      "{i+1}Epoch [3/20], Step [550/600], Loss: 0.5659112334251404, Test Accuracy: 81.89%\n",
      "{i+1}Epoch [3/20], Step [600/600], Loss: 0.633868396282196, Test Accuracy: 81.28%\n",
      "{i+1}Epoch [4/20], Step [50/600], Loss: 0.5433322787284851, Test Accuracy: 80.86%\n",
      "{i+1}Epoch [4/20], Step [100/600], Loss: 0.5565142631530762, Test Accuracy: 82.79%\n",
      "{i+1}Epoch [4/20], Step [150/600], Loss: 0.5540964007377625, Test Accuracy: 81.91%\n",
      "{i+1}Epoch [4/20], Step [200/600], Loss: 0.629147469997406, Test Accuracy: 80.53%\n",
      "{i+1}Epoch [4/20], Step [250/600], Loss: 0.49530652165412903, Test Accuracy: 82.2%\n",
      "{i+1}Epoch [4/20], Step [300/600], Loss: 0.593980073928833, Test Accuracy: 82.39%\n",
      "{i+1}Epoch [4/20], Step [350/600], Loss: 0.6267022490501404, Test Accuracy: 82.18%\n",
      "{i+1}Epoch [4/20], Step [400/600], Loss: 0.6050832271575928, Test Accuracy: 82.49%\n",
      "{i+1}Epoch [4/20], Step [450/600], Loss: 0.5108476877212524, Test Accuracy: 81.67%\n",
      "{i+1}Epoch [4/20], Step [500/600], Loss: 0.5925588011741638, Test Accuracy: 82.52%\n",
      "{i+1}Epoch [4/20], Step [550/600], Loss: 0.5347880721092224, Test Accuracy: 82.84%\n",
      "{i+1}Epoch [4/20], Step [600/600], Loss: 0.497867226600647, Test Accuracy: 82.63%\n",
      "{i+1}Epoch [5/20], Step [50/600], Loss: 0.5120612978935242, Test Accuracy: 82.9%\n",
      "{i+1}Epoch [5/20], Step [100/600], Loss: 0.5744351148605347, Test Accuracy: 82.9%\n",
      "{i+1}Epoch [5/20], Step [150/600], Loss: 0.4998292028903961, Test Accuracy: 82.82%\n",
      "{i+1}Epoch [5/20], Step [200/600], Loss: 0.505261242389679, Test Accuracy: 82.96%\n",
      "{i+1}Epoch [5/20], Step [250/600], Loss: 0.5164335370063782, Test Accuracy: 82.2%\n",
      "{i+1}Epoch [5/20], Step [300/600], Loss: 0.504916250705719, Test Accuracy: 82.37%\n",
      "{i+1}Epoch [5/20], Step [350/600], Loss: 0.5425843596458435, Test Accuracy: 82.52%\n",
      "{i+1}Epoch [5/20], Step [400/600], Loss: 0.46220114827156067, Test Accuracy: 84.16%\n",
      "{i+1}Epoch [5/20], Step [450/600], Loss: 0.49707478284835815, Test Accuracy: 83.74%\n",
      "{i+1}Epoch [5/20], Step [500/600], Loss: 0.48055022954940796, Test Accuracy: 82.71%\n",
      "{i+1}Epoch [5/20], Step [550/600], Loss: 0.40465793013572693, Test Accuracy: 82.97%\n",
      "{i+1}Epoch [5/20], Step [600/600], Loss: 0.4357835054397583, Test Accuracy: 83.07%\n",
      "{i+1}Epoch [6/20], Step [50/600], Loss: 0.4251430630683899, Test Accuracy: 83.45%\n",
      "{i+1}Epoch [6/20], Step [100/600], Loss: 0.4506308436393738, Test Accuracy: 83.44%\n",
      "{i+1}Epoch [6/20], Step [150/600], Loss: 0.4926546514034271, Test Accuracy: 83.27%\n",
      "{i+1}Epoch [6/20], Step [200/600], Loss: 0.44318053126335144, Test Accuracy: 82.65%\n",
      "{i+1}Epoch [6/20], Step [250/600], Loss: 0.4071989059448242, Test Accuracy: 83.79%\n",
      "{i+1}Epoch [6/20], Step [300/600], Loss: 0.43958157300949097, Test Accuracy: 84.44%\n",
      "{i+1}Epoch [6/20], Step [350/600], Loss: 0.41891220211982727, Test Accuracy: 82.12%\n",
      "{i+1}Epoch [6/20], Step [400/600], Loss: 0.3952759802341461, Test Accuracy: 84.33%\n",
      "{i+1}Epoch [6/20], Step [450/600], Loss: 0.49555668234825134, Test Accuracy: 83.64%\n",
      "{i+1}Epoch [6/20], Step [500/600], Loss: 0.46160292625427246, Test Accuracy: 84.12%\n",
      "{i+1}Epoch [6/20], Step [550/600], Loss: 0.44407638907432556, Test Accuracy: 84.01%\n",
      "{i+1}Epoch [6/20], Step [600/600], Loss: 0.41410693526268005, Test Accuracy: 84.45%\n",
      "{i+1}Epoch [7/20], Step [50/600], Loss: 0.4484253227710724, Test Accuracy: 84.62%\n",
      "{i+1}Epoch [7/20], Step [100/600], Loss: 0.3853750228881836, Test Accuracy: 83.27%\n",
      "{i+1}Epoch [7/20], Step [150/600], Loss: 0.45911818742752075, Test Accuracy: 84.6%\n",
      "{i+1}Epoch [7/20], Step [200/600], Loss: 0.389436274766922, Test Accuracy: 83.78%\n",
      "{i+1}Epoch [7/20], Step [250/600], Loss: 0.4042529761791229, Test Accuracy: 84.59%\n",
      "{i+1}Epoch [7/20], Step [300/600], Loss: 0.41478046774864197, Test Accuracy: 84.35%\n",
      "{i+1}Epoch [7/20], Step [350/600], Loss: 0.44868505001068115, Test Accuracy: 84.83%\n",
      "{i+1}Epoch [7/20], Step [400/600], Loss: 0.41837772727012634, Test Accuracy: 84.82%\n",
      "{i+1}Epoch [7/20], Step [450/600], Loss: 0.4125758111476898, Test Accuracy: 84.65%\n",
      "{i+1}Epoch [7/20], Step [500/600], Loss: 0.39145758748054504, Test Accuracy: 84.73%\n",
      "{i+1}Epoch [7/20], Step [550/600], Loss: 0.4496884047985077, Test Accuracy: 84.14%\n",
      "{i+1}Epoch [7/20], Step [600/600], Loss: 0.4257873296737671, Test Accuracy: 85.03%\n",
      "{i+1}Epoch [8/20], Step [50/600], Loss: 0.47415661811828613, Test Accuracy: 84.8%\n",
      "{i+1}Epoch [8/20], Step [100/600], Loss: 0.402314156293869, Test Accuracy: 84.62%\n",
      "{i+1}Epoch [8/20], Step [150/600], Loss: 0.4034854471683502, Test Accuracy: 84.22%\n",
      "{i+1}Epoch [8/20], Step [200/600], Loss: 0.48385536670684814, Test Accuracy: 84.79%\n",
      "{i+1}Epoch [8/20], Step [250/600], Loss: 0.44454044103622437, Test Accuracy: 85.28%\n",
      "{i+1}Epoch [8/20], Step [300/600], Loss: 0.44512706995010376, Test Accuracy: 84.59%\n",
      "{i+1}Epoch [8/20], Step [350/600], Loss: 0.40375277400016785, Test Accuracy: 84.91%\n",
      "{i+1}Epoch [8/20], Step [400/600], Loss: 0.4297317862510681, Test Accuracy: 84.49%\n",
      "{i+1}Epoch [8/20], Step [450/600], Loss: 0.48858195543289185, Test Accuracy: 84.67%\n",
      "{i+1}Epoch [8/20], Step [500/600], Loss: 0.39328068494796753, Test Accuracy: 85.15%\n",
      "{i+1}Epoch [8/20], Step [550/600], Loss: 0.44687071442604065, Test Accuracy: 84.37%\n",
      "{i+1}Epoch [8/20], Step [600/600], Loss: 0.43977344036102295, Test Accuracy: 84.88%\n",
      "{i+1}Epoch [9/20], Step [50/600], Loss: 0.3848055899143219, Test Accuracy: 84.76%\n",
      "{i+1}Epoch [9/20], Step [100/600], Loss: 0.4119773507118225, Test Accuracy: 85.0%\n",
      "{i+1}Epoch [9/20], Step [150/600], Loss: 0.36312925815582275, Test Accuracy: 85.43%\n",
      "{i+1}Epoch [9/20], Step [200/600], Loss: 0.4075581431388855, Test Accuracy: 84.99%\n",
      "{i+1}Epoch [9/20], Step [250/600], Loss: 0.41484466195106506, Test Accuracy: 84.81%\n",
      "{i+1}Epoch [9/20], Step [300/600], Loss: 0.40893328189849854, Test Accuracy: 84.99%\n",
      "{i+1}Epoch [9/20], Step [350/600], Loss: 0.44923269748687744, Test Accuracy: 85.33%\n",
      "{i+1}Epoch [9/20], Step [400/600], Loss: 0.4084599018096924, Test Accuracy: 84.31%\n",
      "{i+1}Epoch [9/20], Step [450/600], Loss: 0.4224778115749359, Test Accuracy: 85.56%\n",
      "{i+1}Epoch [9/20], Step [500/600], Loss: 0.5135533809661865, Test Accuracy: 85.34%\n",
      "{i+1}Epoch [9/20], Step [550/600], Loss: 0.4420178532600403, Test Accuracy: 84.56%\n",
      "{i+1}Epoch [9/20], Step [600/600], Loss: 0.4652542471885681, Test Accuracy: 84.58%\n",
      "{i+1}Epoch [10/20], Step [50/600], Loss: 0.37872639298439026, Test Accuracy: 85.39%\n",
      "{i+1}Epoch [10/20], Step [100/600], Loss: 0.42015448212623596, Test Accuracy: 84.48%\n",
      "{i+1}Epoch [10/20], Step [150/600], Loss: 0.4408339262008667, Test Accuracy: 85.42%\n",
      "{i+1}Epoch [10/20], Step [200/600], Loss: 0.3969888687133789, Test Accuracy: 85.41%\n",
      "{i+1}Epoch [10/20], Step [250/600], Loss: 0.3855051100254059, Test Accuracy: 85.26%\n",
      "{i+1}Epoch [10/20], Step [300/600], Loss: 0.44285517930984497, Test Accuracy: 85.28%\n",
      "{i+1}Epoch [10/20], Step [350/600], Loss: 0.4348912537097931, Test Accuracy: 85.49%\n",
      "{i+1}Epoch [10/20], Step [400/600], Loss: 0.4311872124671936, Test Accuracy: 85.39%\n",
      "{i+1}Epoch [10/20], Step [450/600], Loss: 0.4182548522949219, Test Accuracy: 84.87%\n",
      "{i+1}Epoch [10/20], Step [500/600], Loss: 0.44154560565948486, Test Accuracy: 85.04%\n",
      "{i+1}Epoch [10/20], Step [550/600], Loss: 0.37925735116004944, Test Accuracy: 85.21%\n",
      "{i+1}Epoch [10/20], Step [600/600], Loss: 0.3686735928058624, Test Accuracy: 85.33%\n",
      "{i+1}Epoch [11/20], Step [50/600], Loss: 0.3996593952178955, Test Accuracy: 85.24%\n",
      "{i+1}Epoch [11/20], Step [100/600], Loss: 0.3410952389240265, Test Accuracy: 85.8%\n",
      "{i+1}Epoch [11/20], Step [150/600], Loss: 0.3853759467601776, Test Accuracy: 85.57%\n",
      "{i+1}Epoch [11/20], Step [200/600], Loss: 0.42528000473976135, Test Accuracy: 85.21%\n",
      "{i+1}Epoch [11/20], Step [250/600], Loss: 0.422801673412323, Test Accuracy: 85.29%\n",
      "{i+1}Epoch [11/20], Step [300/600], Loss: 0.396520733833313, Test Accuracy: 85.4%\n",
      "{i+1}Epoch [11/20], Step [350/600], Loss: 0.3678828477859497, Test Accuracy: 85.41%\n",
      "{i+1}Epoch [11/20], Step [400/600], Loss: 0.4085008203983307, Test Accuracy: 84.58%\n",
      "{i+1}Epoch [11/20], Step [450/600], Loss: 0.404016375541687, Test Accuracy: 85.64%\n",
      "{i+1}Epoch [11/20], Step [500/600], Loss: 0.4211125671863556, Test Accuracy: 85.59%\n",
      "{i+1}Epoch [11/20], Step [550/600], Loss: 0.40643757581710815, Test Accuracy: 85.65%\n",
      "{i+1}Epoch [11/20], Step [600/600], Loss: 0.40725135803222656, Test Accuracy: 85.31%\n",
      "{i+1}Epoch [12/20], Step [50/600], Loss: 0.37944236397743225, Test Accuracy: 86.07%\n",
      "{i+1}Epoch [12/20], Step [100/600], Loss: 0.42266759276390076, Test Accuracy: 85.56%\n",
      "{i+1}Epoch [12/20], Step [150/600], Loss: 0.42988842725753784, Test Accuracy: 85.96%\n",
      "{i+1}Epoch [12/20], Step [200/600], Loss: 0.39685165882110596, Test Accuracy: 84.83%\n",
      "{i+1}Epoch [12/20], Step [250/600], Loss: 0.41073930263519287, Test Accuracy: 85.53%\n",
      "{i+1}Epoch [12/20], Step [300/600], Loss: 0.41176295280456543, Test Accuracy: 85.39%\n",
      "{i+1}Epoch [12/20], Step [350/600], Loss: 0.4254700839519501, Test Accuracy: 85.65%\n",
      "{i+1}Epoch [12/20], Step [400/600], Loss: 0.46505218744277954, Test Accuracy: 85.33%\n",
      "{i+1}Epoch [12/20], Step [450/600], Loss: 0.3967444598674774, Test Accuracy: 85.94%\n",
      "{i+1}Epoch [12/20], Step [500/600], Loss: 0.43576687574386597, Test Accuracy: 84.5%\n",
      "{i+1}Epoch [12/20], Step [550/600], Loss: 0.38874873518943787, Test Accuracy: 85.52%\n",
      "{i+1}Epoch [12/20], Step [600/600], Loss: 0.4216367304325104, Test Accuracy: 85.22%\n",
      "{i+1}Epoch [13/20], Step [50/600], Loss: 0.3803647756576538, Test Accuracy: 85.7%\n",
      "{i+1}Epoch [13/20], Step [100/600], Loss: 0.37533703446388245, Test Accuracy: 85.19%\n",
      "{i+1}Epoch [13/20], Step [150/600], Loss: 0.4123774766921997, Test Accuracy: 86.08%\n",
      "{i+1}Epoch [13/20], Step [200/600], Loss: 0.4872509837150574, Test Accuracy: 85.36%\n",
      "{i+1}Epoch [13/20], Step [250/600], Loss: 0.415739506483078, Test Accuracy: 86.03%\n",
      "{i+1}Epoch [13/20], Step [300/600], Loss: 0.420994371175766, Test Accuracy: 85.88%\n",
      "{i+1}Epoch [13/20], Step [350/600], Loss: 0.37678396701812744, Test Accuracy: 85.82%\n",
      "{i+1}Epoch [13/20], Step [400/600], Loss: 0.4274144768714905, Test Accuracy: 85.69%\n",
      "{i+1}Epoch [13/20], Step [450/600], Loss: 0.38369590044021606, Test Accuracy: 85.85%\n",
      "{i+1}Epoch [13/20], Step [500/600], Loss: 0.4518892765045166, Test Accuracy: 85.47%\n",
      "{i+1}Epoch [13/20], Step [550/600], Loss: 0.4576348066329956, Test Accuracy: 85.77%\n",
      "{i+1}Epoch [13/20], Step [600/600], Loss: 0.36109280586242676, Test Accuracy: 85.86%\n",
      "{i+1}Epoch [14/20], Step [50/600], Loss: 0.40612125396728516, Test Accuracy: 85.78%\n",
      "{i+1}Epoch [14/20], Step [100/600], Loss: 0.40331795811653137, Test Accuracy: 85.8%\n",
      "{i+1}Epoch [14/20], Step [150/600], Loss: 0.3896668255329132, Test Accuracy: 85.68%\n",
      "{i+1}Epoch [14/20], Step [200/600], Loss: 0.39410239458084106, Test Accuracy: 85.97%\n",
      "{i+1}Epoch [14/20], Step [250/600], Loss: 0.37191346287727356, Test Accuracy: 86.02%\n",
      "{i+1}Epoch [14/20], Step [300/600], Loss: 0.427570641040802, Test Accuracy: 84.55%\n",
      "{i+1}Epoch [14/20], Step [350/600], Loss: 0.4138880670070648, Test Accuracy: 85.83%\n",
      "{i+1}Epoch [14/20], Step [400/600], Loss: 0.39487066864967346, Test Accuracy: 85.97%\n",
      "{i+1}Epoch [14/20], Step [450/600], Loss: 0.38365569710731506, Test Accuracy: 86.32%\n",
      "{i+1}Epoch [14/20], Step [500/600], Loss: 0.3854925036430359, Test Accuracy: 86.03%\n",
      "{i+1}Epoch [14/20], Step [550/600], Loss: 0.4184824228286743, Test Accuracy: 85.67%\n",
      "{i+1}Epoch [14/20], Step [600/600], Loss: 0.39307549595832825, Test Accuracy: 85.63%\n",
      "{i+1}Epoch [15/20], Step [50/600], Loss: 0.4217860698699951, Test Accuracy: 86.06%\n",
      "{i+1}Epoch [15/20], Step [100/600], Loss: 0.4066353142261505, Test Accuracy: 86.11%\n",
      "{i+1}Epoch [15/20], Step [150/600], Loss: 0.42195045948028564, Test Accuracy: 86.08%\n",
      "{i+1}Epoch [15/20], Step [200/600], Loss: 0.40385547280311584, Test Accuracy: 85.91%\n",
      "{i+1}Epoch [15/20], Step [250/600], Loss: 0.4619029760360718, Test Accuracy: 85.8%\n",
      "{i+1}Epoch [15/20], Step [300/600], Loss: 0.44445186853408813, Test Accuracy: 85.78%\n",
      "{i+1}Epoch [15/20], Step [350/600], Loss: 0.46927112340927124, Test Accuracy: 85.64%\n",
      "{i+1}Epoch [15/20], Step [400/600], Loss: 0.4208419919013977, Test Accuracy: 86.52%\n",
      "{i+1}Epoch [15/20], Step [450/600], Loss: 0.4446834921836853, Test Accuracy: 86.37%\n",
      "{i+1}Epoch [15/20], Step [500/600], Loss: 0.42490071058273315, Test Accuracy: 86.14%\n",
      "{i+1}Epoch [15/20], Step [550/600], Loss: 0.4382152259349823, Test Accuracy: 86.15%\n",
      "{i+1}Epoch [15/20], Step [600/600], Loss: 0.4054696559906006, Test Accuracy: 85.47%\n",
      "{i+1}Epoch [16/20], Step [50/600], Loss: 0.39160263538360596, Test Accuracy: 85.46%\n",
      "{i+1}Epoch [16/20], Step [100/600], Loss: 0.37116965651512146, Test Accuracy: 86.07%\n",
      "{i+1}Epoch [16/20], Step [150/600], Loss: 0.39649268984794617, Test Accuracy: 86.28%\n",
      "{i+1}Epoch [16/20], Step [200/600], Loss: 0.4045284688472748, Test Accuracy: 86.04%\n",
      "{i+1}Epoch [16/20], Step [250/600], Loss: 0.4055635333061218, Test Accuracy: 85.61%\n",
      "{i+1}Epoch [16/20], Step [300/600], Loss: 0.4073154330253601, Test Accuracy: 86.37%\n",
      "{i+1}Epoch [16/20], Step [350/600], Loss: 0.4034455418586731, Test Accuracy: 85.12%\n",
      "{i+1}Epoch [16/20], Step [400/600], Loss: 0.3819664418697357, Test Accuracy: 85.56%\n",
      "{i+1}Epoch [16/20], Step [450/600], Loss: 0.4031842350959778, Test Accuracy: 86.12%\n",
      "{i+1}Epoch [16/20], Step [500/600], Loss: 0.4088383615016937, Test Accuracy: 85.92%\n",
      "{i+1}Epoch [16/20], Step [550/600], Loss: 0.3580762445926666, Test Accuracy: 85.78%\n",
      "{i+1}Epoch [16/20], Step [600/600], Loss: 0.3719272315502167, Test Accuracy: 86.09%\n",
      "{i+1}Epoch [17/20], Step [50/600], Loss: 0.372226744890213, Test Accuracy: 86.24%\n",
      "{i+1}Epoch [17/20], Step [100/600], Loss: 0.35818061232566833, Test Accuracy: 86.05%\n",
      "{i+1}Epoch [17/20], Step [150/600], Loss: 0.3846132159233093, Test Accuracy: 85.83%\n",
      "{i+1}Epoch [17/20], Step [200/600], Loss: 0.391460120677948, Test Accuracy: 86.4%\n",
      "{i+1}Epoch [17/20], Step [250/600], Loss: 0.403982549905777, Test Accuracy: 85.51%\n",
      "{i+1}Epoch [17/20], Step [300/600], Loss: 0.35951516032218933, Test Accuracy: 86.25%\n",
      "{i+1}Epoch [17/20], Step [350/600], Loss: 0.3753213882446289, Test Accuracy: 86.28%\n",
      "{i+1}Epoch [17/20], Step [400/600], Loss: 0.3283252716064453, Test Accuracy: 85.96%\n",
      "{i+1}Epoch [17/20], Step [450/600], Loss: 0.3866167962551117, Test Accuracy: 86.1%\n",
      "{i+1}Epoch [17/20], Step [500/600], Loss: 0.36959949135780334, Test Accuracy: 86.03%\n",
      "{i+1}Epoch [17/20], Step [550/600], Loss: 0.3699323236942291, Test Accuracy: 86.18%\n",
      "{i+1}Epoch [17/20], Step [600/600], Loss: 0.3650018572807312, Test Accuracy: 86.3%\n",
      "{i+1}Epoch [18/20], Step [50/600], Loss: 0.38229092955589294, Test Accuracy: 86.36%\n",
      "{i+1}Epoch [18/20], Step [100/600], Loss: 0.3992987871170044, Test Accuracy: 86.21%\n",
      "{i+1}Epoch [18/20], Step [150/600], Loss: 0.37615203857421875, Test Accuracy: 86.37%\n",
      "{i+1}Epoch [18/20], Step [200/600], Loss: 0.4488111734390259, Test Accuracy: 85.84%\n",
      "{i+1}Epoch [18/20], Step [250/600], Loss: 0.3705665171146393, Test Accuracy: 86.58%\n",
      "{i+1}Epoch [18/20], Step [300/600], Loss: 0.4352108836174011, Test Accuracy: 86.62%\n",
      "{i+1}Epoch [18/20], Step [350/600], Loss: 0.3987525999546051, Test Accuracy: 86.13%\n",
      "{i+1}Epoch [18/20], Step [400/600], Loss: 0.44510018825531006, Test Accuracy: 86.4%\n",
      "{i+1}Epoch [18/20], Step [450/600], Loss: 0.38722315430641174, Test Accuracy: 86.35%\n",
      "{i+1}Epoch [18/20], Step [500/600], Loss: 0.3793102502822876, Test Accuracy: 86.47%\n",
      "{i+1}Epoch [18/20], Step [550/600], Loss: 0.41776108741760254, Test Accuracy: 86.08%\n",
      "{i+1}Epoch [18/20], Step [600/600], Loss: 0.37372180819511414, Test Accuracy: 86.12%\n",
      "{i+1}Epoch [19/20], Step [50/600], Loss: 0.42657339572906494, Test Accuracy: 86.13%\n",
      "{i+1}Epoch [19/20], Step [100/600], Loss: 0.43034350872039795, Test Accuracy: 86.23%\n",
      "{i+1}Epoch [19/20], Step [150/600], Loss: 0.4020306468009949, Test Accuracy: 86.16%\n",
      "{i+1}Epoch [19/20], Step [200/600], Loss: 0.41307708621025085, Test Accuracy: 86.5%\n",
      "{i+1}Epoch [19/20], Step [250/600], Loss: 0.47766250371932983, Test Accuracy: 86.18%\n",
      "{i+1}Epoch [19/20], Step [300/600], Loss: 0.4058801233768463, Test Accuracy: 86.12%\n",
      "{i+1}Epoch [19/20], Step [350/600], Loss: 0.44517719745635986, Test Accuracy: 86.28%\n",
      "{i+1}Epoch [19/20], Step [400/600], Loss: 0.392721951007843, Test Accuracy: 86.28%\n",
      "{i+1}Epoch [19/20], Step [450/600], Loss: 0.4074358642101288, Test Accuracy: 86.11%\n",
      "{i+1}Epoch [19/20], Step [500/600], Loss: 0.35179197788238525, Test Accuracy: 86.37%\n",
      "{i+1}Epoch [19/20], Step [550/600], Loss: 0.3975864350795746, Test Accuracy: 86.12%\n",
      "{i+1}Epoch [19/20], Step [600/600], Loss: 0.3965880274772644, Test Accuracy: 86.23%\n",
      "{i+1}Epoch [20/20], Step [50/600], Loss: 0.4163952171802521, Test Accuracy: 85.98%\n",
      "{i+1}Epoch [20/20], Step [100/600], Loss: 0.4646557569503784, Test Accuracy: 86.42%\n",
      "{i+1}Epoch [20/20], Step [150/600], Loss: 0.42049911618232727, Test Accuracy: 86.56%\n",
      "{i+1}Epoch [20/20], Step [200/600], Loss: 0.3925398290157318, Test Accuracy: 86.47%\n",
      "{i+1}Epoch [20/20], Step [250/600], Loss: 0.4251540005207062, Test Accuracy: 85.99%\n",
      "{i+1}Epoch [20/20], Step [300/600], Loss: 0.41265881061553955, Test Accuracy: 86.61%\n",
      "{i+1}Epoch [20/20], Step [350/600], Loss: 0.419022798538208, Test Accuracy: 86.33%\n",
      "{i+1}Epoch [20/20], Step [400/600], Loss: 0.3885408043861389, Test Accuracy: 86.55%\n",
      "{i+1}Epoch [20/20], Step [450/600], Loss: 0.38242077827453613, Test Accuracy: 86.35%\n",
      "{i+1}Epoch [20/20], Step [500/600], Loss: 0.39578402042388916, Test Accuracy: 86.13%\n",
      "{i+1}Epoch [20/20], Step [550/600], Loss: 0.36880970001220703, Test Accuracy: 86.38%\n",
      "{i+1}Epoch [20/20], Step [600/600], Loss: 0.3642490804195404, Test Accuracy: 86.17%\n",
      "500\n",
      "Using cuda device\n",
      "Tiny_convnet(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "{i+1}Epoch [1/20], Step [50/600], Loss: 1.5635837316513062, Test Accuracy: 40.35%\n",
      "{i+1}Epoch [1/20], Step [100/600], Loss: 0.984975278377533, Test Accuracy: 63.72%\n",
      "{i+1}Epoch [1/20], Step [150/600], Loss: 0.8876825571060181, Test Accuracy: 67.0%\n",
      "{i+1}Epoch [1/20], Step [200/600], Loss: 0.7045770883560181, Test Accuracy: 73.74%\n",
      "{i+1}Epoch [1/20], Step [250/600], Loss: 0.6913133859634399, Test Accuracy: 75.55%\n",
      "{i+1}Epoch [1/20], Step [300/600], Loss: 0.7012991905212402, Test Accuracy: 72.18%\n",
      "{i+1}Epoch [1/20], Step [350/600], Loss: 0.6939923167228699, Test Accuracy: 75.64%\n",
      "{i+1}Epoch [1/20], Step [400/600], Loss: 0.5296018123626709, Test Accuracy: 77.28%\n",
      "{i+1}Epoch [1/20], Step [450/600], Loss: 0.5852169990539551, Test Accuracy: 77.68%\n",
      "{i+1}Epoch [1/20], Step [500/600], Loss: 0.6938980221748352, Test Accuracy: 76.5%\n",
      "{i+1}Epoch [1/20], Step [550/600], Loss: 0.5991939306259155, Test Accuracy: 77.26%\n",
      "{i+1}Epoch [1/20], Step [600/600], Loss: 0.643993616104126, Test Accuracy: 78.2%\n",
      "{i+1}Epoch [2/20], Step [50/600], Loss: 0.5449299216270447, Test Accuracy: 79.4%\n",
      "{i+1}Epoch [2/20], Step [100/600], Loss: 0.587164044380188, Test Accuracy: 79.75%\n",
      "{i+1}Epoch [2/20], Step [150/600], Loss: 0.495595782995224, Test Accuracy: 80.77%\n",
      "{i+1}Epoch [2/20], Step [200/600], Loss: 0.5735244750976562, Test Accuracy: 80.38%\n",
      "{i+1}Epoch [2/20], Step [250/600], Loss: 0.5500401854515076, Test Accuracy: 81.47%\n",
      "{i+1}Epoch [2/20], Step [300/600], Loss: 0.5209039449691772, Test Accuracy: 80.96%\n",
      "{i+1}Epoch [2/20], Step [350/600], Loss: 0.5725758075714111, Test Accuracy: 80.75%\n",
      "{i+1}Epoch [2/20], Step [400/600], Loss: 0.5622576475143433, Test Accuracy: 81.89%\n",
      "{i+1}Epoch [2/20], Step [450/600], Loss: 0.6322805285453796, Test Accuracy: 80.89%\n",
      "{i+1}Epoch [2/20], Step [500/600], Loss: 0.544456422328949, Test Accuracy: 81.59%\n",
      "{i+1}Epoch [2/20], Step [550/600], Loss: 0.570534884929657, Test Accuracy: 82.53%\n",
      "{i+1}Epoch [2/20], Step [600/600], Loss: 0.4860030710697174, Test Accuracy: 81.77%\n",
      "{i+1}Epoch [3/20], Step [50/600], Loss: 0.5460864901542664, Test Accuracy: 82.62%\n",
      "{i+1}Epoch [3/20], Step [100/600], Loss: 0.5407830476760864, Test Accuracy: 81.68%\n",
      "{i+1}Epoch [3/20], Step [150/600], Loss: 0.5518265962600708, Test Accuracy: 81.99%\n",
      "{i+1}Epoch [3/20], Step [200/600], Loss: 0.47905993461608887, Test Accuracy: 82.21%\n",
      "{i+1}Epoch [3/20], Step [250/600], Loss: 0.6068229079246521, Test Accuracy: 82.72%\n",
      "{i+1}Epoch [3/20], Step [300/600], Loss: 0.6242809891700745, Test Accuracy: 82.23%\n",
      "{i+1}Epoch [3/20], Step [350/600], Loss: 0.5069704651832581, Test Accuracy: 82.77%\n",
      "{i+1}Epoch [3/20], Step [400/600], Loss: 0.49811509251594543, Test Accuracy: 82.92%\n",
      "{i+1}Epoch [3/20], Step [450/600], Loss: 0.5439075231552124, Test Accuracy: 83.03%\n",
      "{i+1}Epoch [3/20], Step [500/600], Loss: 0.530738115310669, Test Accuracy: 82.11%\n",
      "{i+1}Epoch [3/20], Step [550/600], Loss: 0.47051775455474854, Test Accuracy: 82.49%\n",
      "{i+1}Epoch [3/20], Step [600/600], Loss: 0.4553360044956207, Test Accuracy: 82.34%\n",
      "{i+1}Epoch [4/20], Step [50/600], Loss: 0.47811198234558105, Test Accuracy: 82.45%\n",
      "{i+1}Epoch [4/20], Step [100/600], Loss: 0.4954940676689148, Test Accuracy: 83.37%\n",
      "{i+1}Epoch [4/20], Step [150/600], Loss: 0.5129256248474121, Test Accuracy: 82.46%\n",
      "{i+1}Epoch [4/20], Step [200/600], Loss: 0.4964132606983185, Test Accuracy: 82.87%\n",
      "{i+1}Epoch [4/20], Step [250/600], Loss: 0.44334277510643005, Test Accuracy: 83.79%\n",
      "{i+1}Epoch [4/20], Step [300/600], Loss: 0.5044264197349548, Test Accuracy: 82.83%\n",
      "{i+1}Epoch [4/20], Step [350/600], Loss: 0.4201544523239136, Test Accuracy: 84.28%\n",
      "{i+1}Epoch [4/20], Step [400/600], Loss: 0.47002190351486206, Test Accuracy: 83.43%\n",
      "{i+1}Epoch [4/20], Step [450/600], Loss: 0.5526515245437622, Test Accuracy: 83.51%\n",
      "{i+1}Epoch [4/20], Step [500/600], Loss: 0.48000285029411316, Test Accuracy: 83.5%\n",
      "{i+1}Epoch [4/20], Step [550/600], Loss: 0.493495374917984, Test Accuracy: 83.7%\n",
      "{i+1}Epoch [4/20], Step [600/600], Loss: 0.5899689197540283, Test Accuracy: 83.7%\n",
      "{i+1}Epoch [5/20], Step [50/600], Loss: 0.4966135025024414, Test Accuracy: 83.91%\n",
      "{i+1}Epoch [5/20], Step [100/600], Loss: 0.5464677810668945, Test Accuracy: 83.35%\n",
      "{i+1}Epoch [5/20], Step [150/600], Loss: 0.5445524454116821, Test Accuracy: 83.82%\n",
      "{i+1}Epoch [5/20], Step [200/600], Loss: 0.44256630539894104, Test Accuracy: 84.14%\n",
      "{i+1}Epoch [5/20], Step [250/600], Loss: 0.5004835724830627, Test Accuracy: 83.97%\n",
      "{i+1}Epoch [5/20], Step [300/600], Loss: 0.4497043490409851, Test Accuracy: 84.49%\n",
      "{i+1}Epoch [5/20], Step [350/600], Loss: 0.47981488704681396, Test Accuracy: 83.96%\n",
      "{i+1}Epoch [5/20], Step [400/600], Loss: 0.4034106135368347, Test Accuracy: 84.45%\n",
      "{i+1}Epoch [5/20], Step [450/600], Loss: 0.4981958270072937, Test Accuracy: 84.2%\n",
      "{i+1}Epoch [5/20], Step [500/600], Loss: 0.5132720470428467, Test Accuracy: 84.08%\n",
      "{i+1}Epoch [5/20], Step [550/600], Loss: 0.5744251608848572, Test Accuracy: 84.41%\n",
      "{i+1}Epoch [5/20], Step [600/600], Loss: 0.46685877442359924, Test Accuracy: 83.99%\n",
      "{i+1}Epoch [6/20], Step [50/600], Loss: 0.4454590678215027, Test Accuracy: 84.78%\n",
      "{i+1}Epoch [6/20], Step [100/600], Loss: 0.4837217628955841, Test Accuracy: 84.01%\n",
      "{i+1}Epoch [6/20], Step [150/600], Loss: 0.4266413152217865, Test Accuracy: 83.79%\n",
      "{i+1}Epoch [6/20], Step [200/600], Loss: 0.5089308023452759, Test Accuracy: 84.25%\n",
      "{i+1}Epoch [6/20], Step [250/600], Loss: 0.5686773061752319, Test Accuracy: 83.41%\n",
      "{i+1}Epoch [6/20], Step [300/600], Loss: 0.4668693244457245, Test Accuracy: 85.33%\n",
      "{i+1}Epoch [6/20], Step [350/600], Loss: 0.5107834935188293, Test Accuracy: 84.43%\n",
      "{i+1}Epoch [6/20], Step [400/600], Loss: 0.44859886169433594, Test Accuracy: 84.42%\n",
      "{i+1}Epoch [6/20], Step [450/600], Loss: 0.49466633796691895, Test Accuracy: 84.95%\n",
      "{i+1}Epoch [6/20], Step [500/600], Loss: 0.47229817509651184, Test Accuracy: 84.83%\n",
      "{i+1}Epoch [6/20], Step [550/600], Loss: 0.4944172203540802, Test Accuracy: 85.04%\n",
      "{i+1}Epoch [6/20], Step [600/600], Loss: 0.49676746129989624, Test Accuracy: 84.44%\n",
      "{i+1}Epoch [7/20], Step [50/600], Loss: 0.4679429531097412, Test Accuracy: 85.12%\n",
      "{i+1}Epoch [7/20], Step [100/600], Loss: 0.4921647608280182, Test Accuracy: 84.45%\n",
      "{i+1}Epoch [7/20], Step [150/600], Loss: 0.49479034543037415, Test Accuracy: 85.39%\n",
      "{i+1}Epoch [7/20], Step [200/600], Loss: 0.4764299690723419, Test Accuracy: 85.1%\n",
      "{i+1}Epoch [7/20], Step [250/600], Loss: 0.4611290395259857, Test Accuracy: 85.37%\n",
      "{i+1}Epoch [7/20], Step [300/600], Loss: 0.5008838772773743, Test Accuracy: 84.29%\n",
      "{i+1}Epoch [7/20], Step [350/600], Loss: 0.45155391097068787, Test Accuracy: 85.27%\n",
      "{i+1}Epoch [7/20], Step [400/600], Loss: 0.5289686322212219, Test Accuracy: 85.0%\n",
      "{i+1}Epoch [7/20], Step [450/600], Loss: 0.47570502758026123, Test Accuracy: 84.94%\n",
      "{i+1}Epoch [7/20], Step [500/600], Loss: 0.43480366468429565, Test Accuracy: 84.58%\n",
      "{i+1}Epoch [7/20], Step [550/600], Loss: 0.5092459917068481, Test Accuracy: 85.03%\n",
      "{i+1}Epoch [7/20], Step [600/600], Loss: 0.4576241970062256, Test Accuracy: 85.15%\n",
      "{i+1}Epoch [8/20], Step [50/600], Loss: 0.5153260231018066, Test Accuracy: 85.65%\n",
      "{i+1}Epoch [8/20], Step [100/600], Loss: 0.4724004864692688, Test Accuracy: 85.48%\n",
      "{i+1}Epoch [8/20], Step [150/600], Loss: 0.48581135272979736, Test Accuracy: 85.45%\n",
      "{i+1}Epoch [8/20], Step [200/600], Loss: 0.46931353211402893, Test Accuracy: 85.1%\n",
      "{i+1}Epoch [8/20], Step [250/600], Loss: 0.45591726899147034, Test Accuracy: 85.05%\n",
      "{i+1}Epoch [8/20], Step [300/600], Loss: 0.524989902973175, Test Accuracy: 85.0%\n",
      "{i+1}Epoch [8/20], Step [350/600], Loss: 0.4962877035140991, Test Accuracy: 85.1%\n",
      "{i+1}Epoch [8/20], Step [400/600], Loss: 0.5198750495910645, Test Accuracy: 85.61%\n",
      "{i+1}Epoch [8/20], Step [450/600], Loss: 0.4714171886444092, Test Accuracy: 85.22%\n",
      "{i+1}Epoch [8/20], Step [500/600], Loss: 0.41276901960372925, Test Accuracy: 84.86%\n",
      "{i+1}Epoch [8/20], Step [550/600], Loss: 0.514641284942627, Test Accuracy: 84.92%\n",
      "{i+1}Epoch [8/20], Step [600/600], Loss: 0.43479716777801514, Test Accuracy: 85.52%\n",
      "{i+1}Epoch [9/20], Step [50/600], Loss: 0.4437682032585144, Test Accuracy: 85.14%\n",
      "{i+1}Epoch [9/20], Step [100/600], Loss: 0.4037606120109558, Test Accuracy: 85.39%\n",
      "{i+1}Epoch [9/20], Step [150/600], Loss: 0.4215717017650604, Test Accuracy: 84.89%\n",
      "{i+1}Epoch [9/20], Step [200/600], Loss: 0.3963436186313629, Test Accuracy: 85.48%\n",
      "{i+1}Epoch [9/20], Step [250/600], Loss: 0.39174598455429077, Test Accuracy: 85.19%\n",
      "{i+1}Epoch [9/20], Step [300/600], Loss: 0.4743098020553589, Test Accuracy: 85.39%\n",
      "{i+1}Epoch [9/20], Step [350/600], Loss: 0.46005287766456604, Test Accuracy: 85.63%\n",
      "{i+1}Epoch [9/20], Step [400/600], Loss: 0.43541184067726135, Test Accuracy: 85.87%\n",
      "{i+1}Epoch [9/20], Step [450/600], Loss: 0.40274718403816223, Test Accuracy: 85.06%\n",
      "{i+1}Epoch [9/20], Step [500/600], Loss: 0.4425121545791626, Test Accuracy: 85.73%\n",
      "{i+1}Epoch [9/20], Step [550/600], Loss: 0.47042155265808105, Test Accuracy: 85.57%\n",
      "{i+1}Epoch [9/20], Step [600/600], Loss: 0.4264262914657593, Test Accuracy: 85.31%\n",
      "{i+1}Epoch [10/20], Step [50/600], Loss: 0.4759599566459656, Test Accuracy: 85.88%\n",
      "{i+1}Epoch [10/20], Step [100/600], Loss: 0.44887566566467285, Test Accuracy: 86.01%\n",
      "{i+1}Epoch [10/20], Step [150/600], Loss: 0.4682323932647705, Test Accuracy: 85.95%\n",
      "{i+1}Epoch [10/20], Step [200/600], Loss: 0.4107259511947632, Test Accuracy: 86.03%\n",
      "{i+1}Epoch [10/20], Step [250/600], Loss: 0.4239477217197418, Test Accuracy: 86.2%\n",
      "{i+1}Epoch [10/20], Step [300/600], Loss: 0.4320765435695648, Test Accuracy: 86.0%\n",
      "{i+1}Epoch [10/20], Step [350/600], Loss: 0.4259369671344757, Test Accuracy: 85.6%\n",
      "{i+1}Epoch [10/20], Step [400/600], Loss: 0.4128263592720032, Test Accuracy: 85.99%\n",
      "{i+1}Epoch [10/20], Step [450/600], Loss: 0.5122619867324829, Test Accuracy: 85.43%\n",
      "{i+1}Epoch [10/20], Step [500/600], Loss: 0.4518222510814667, Test Accuracy: 85.62%\n",
      "{i+1}Epoch [10/20], Step [550/600], Loss: 0.431985467672348, Test Accuracy: 85.71%\n",
      "{i+1}Epoch [10/20], Step [600/600], Loss: 0.44206371903419495, Test Accuracy: 86.15%\n",
      "{i+1}Epoch [11/20], Step [50/600], Loss: 0.47665202617645264, Test Accuracy: 85.97%\n",
      "{i+1}Epoch [11/20], Step [100/600], Loss: 0.4099828600883484, Test Accuracy: 85.63%\n",
      "{i+1}Epoch [11/20], Step [150/600], Loss: 0.45248275995254517, Test Accuracy: 85.5%\n",
      "{i+1}Epoch [11/20], Step [200/600], Loss: 0.4227800667285919, Test Accuracy: 85.69%\n",
      "{i+1}Epoch [11/20], Step [250/600], Loss: 0.46239548921585083, Test Accuracy: 86.21%\n",
      "{i+1}Epoch [11/20], Step [300/600], Loss: 0.41721534729003906, Test Accuracy: 85.84%\n",
      "{i+1}Epoch [11/20], Step [350/600], Loss: 0.453887015581131, Test Accuracy: 85.84%\n",
      "{i+1}Epoch [11/20], Step [400/600], Loss: 0.4646100699901581, Test Accuracy: 86.12%\n",
      "{i+1}Epoch [11/20], Step [450/600], Loss: 0.43750500679016113, Test Accuracy: 84.49%\n",
      "{i+1}Epoch [11/20], Step [500/600], Loss: 0.39338916540145874, Test Accuracy: 85.83%\n",
      "{i+1}Epoch [11/20], Step [550/600], Loss: 0.40738388895988464, Test Accuracy: 85.27%\n",
      "{i+1}Epoch [11/20], Step [600/600], Loss: 0.3842991292476654, Test Accuracy: 86.06%\n",
      "{i+1}Epoch [12/20], Step [50/600], Loss: 0.41849493980407715, Test Accuracy: 86.06%\n",
      "{i+1}Epoch [12/20], Step [100/600], Loss: 0.43428725004196167, Test Accuracy: 86.12%\n",
      "{i+1}Epoch [12/20], Step [150/600], Loss: 0.40002456307411194, Test Accuracy: 85.74%\n",
      "{i+1}Epoch [12/20], Step [200/600], Loss: 0.4359767436981201, Test Accuracy: 85.53%\n",
      "{i+1}Epoch [12/20], Step [250/600], Loss: 0.40447989106178284, Test Accuracy: 85.95%\n",
      "{i+1}Epoch [12/20], Step [300/600], Loss: 0.41535812616348267, Test Accuracy: 85.83%\n",
      "{i+1}Epoch [12/20], Step [350/600], Loss: 0.43400031328201294, Test Accuracy: 86.12%\n",
      "{i+1}Epoch [12/20], Step [400/600], Loss: 0.4986472427845001, Test Accuracy: 85.93%\n",
      "{i+1}Epoch [12/20], Step [450/600], Loss: 0.45986542105674744, Test Accuracy: 85.93%\n",
      "{i+1}Epoch [12/20], Step [500/600], Loss: 0.4083096981048584, Test Accuracy: 85.84%\n",
      "{i+1}Epoch [12/20], Step [550/600], Loss: 0.45937255024909973, Test Accuracy: 86.12%\n",
      "{i+1}Epoch [12/20], Step [600/600], Loss: 0.4381917119026184, Test Accuracy: 85.59%\n",
      "{i+1}Epoch [13/20], Step [50/600], Loss: 0.4774809777736664, Test Accuracy: 85.6%\n",
      "{i+1}Epoch [13/20], Step [100/600], Loss: 0.4581793546676636, Test Accuracy: 86.08%\n",
      "{i+1}Epoch [13/20], Step [150/600], Loss: 0.4770544767379761, Test Accuracy: 86.25%\n",
      "{i+1}Epoch [13/20], Step [200/600], Loss: 0.5054119825363159, Test Accuracy: 85.64%\n",
      "{i+1}Epoch [13/20], Step [250/600], Loss: 0.47114819288253784, Test Accuracy: 85.57%\n",
      "{i+1}Epoch [13/20], Step [300/600], Loss: 0.4799540042877197, Test Accuracy: 85.84%\n",
      "{i+1}Epoch [13/20], Step [350/600], Loss: 0.5014448165893555, Test Accuracy: 86.03%\n",
      "{i+1}Epoch [13/20], Step [400/600], Loss: 0.4647359549999237, Test Accuracy: 85.92%\n",
      "{i+1}Epoch [13/20], Step [450/600], Loss: 0.4723564088344574, Test Accuracy: 85.82%\n",
      "{i+1}Epoch [13/20], Step [500/600], Loss: 0.49644991755485535, Test Accuracy: 85.5%\n",
      "{i+1}Epoch [13/20], Step [550/600], Loss: 0.4719010293483734, Test Accuracy: 86.11%\n",
      "{i+1}Epoch [13/20], Step [600/600], Loss: 0.43102991580963135, Test Accuracy: 85.95%\n",
      "{i+1}Epoch [14/20], Step [50/600], Loss: 0.4908756911754608, Test Accuracy: 85.85%\n",
      "{i+1}Epoch [14/20], Step [100/600], Loss: 0.47358638048171997, Test Accuracy: 86.02%\n",
      "{i+1}Epoch [14/20], Step [150/600], Loss: 0.4370254576206207, Test Accuracy: 85.96%\n",
      "{i+1}Epoch [14/20], Step [200/600], Loss: 0.4398476481437683, Test Accuracy: 86.28%\n",
      "{i+1}Epoch [14/20], Step [250/600], Loss: 0.4515555500984192, Test Accuracy: 85.71%\n",
      "{i+1}Epoch [14/20], Step [300/600], Loss: 0.4879608452320099, Test Accuracy: 86.27%\n",
      "{i+1}Epoch [14/20], Step [350/600], Loss: 0.511934220790863, Test Accuracy: 86.41%\n",
      "{i+1}Epoch [14/20], Step [400/600], Loss: 0.5002767443656921, Test Accuracy: 86.0%\n",
      "{i+1}Epoch [14/20], Step [450/600], Loss: 0.44804543256759644, Test Accuracy: 85.93%\n",
      "{i+1}Epoch [14/20], Step [500/600], Loss: 0.4395718276500702, Test Accuracy: 86.09%\n",
      "{i+1}Epoch [14/20], Step [550/600], Loss: 0.46281346678733826, Test Accuracy: 86.01%\n",
      "{i+1}Epoch [14/20], Step [600/600], Loss: 0.4712389409542084, Test Accuracy: 86.07%\n",
      "{i+1}Epoch [15/20], Step [50/600], Loss: 0.4807851314544678, Test Accuracy: 85.74%\n",
      "{i+1}Epoch [15/20], Step [100/600], Loss: 0.4452323913574219, Test Accuracy: 86.27%\n",
      "{i+1}Epoch [15/20], Step [150/600], Loss: 0.4857129752635956, Test Accuracy: 86.11%\n",
      "{i+1}Epoch [15/20], Step [200/600], Loss: 0.4486221969127655, Test Accuracy: 86.37%\n",
      "{i+1}Epoch [15/20], Step [250/600], Loss: 0.47330376505851746, Test Accuracy: 86.09%\n",
      "{i+1}Epoch [15/20], Step [300/600], Loss: 0.4590803384780884, Test Accuracy: 86.34%\n",
      "{i+1}Epoch [15/20], Step [350/600], Loss: 0.4490404427051544, Test Accuracy: 86.2%\n",
      "{i+1}Epoch [15/20], Step [400/600], Loss: 0.43269431591033936, Test Accuracy: 85.99%\n",
      "{i+1}Epoch [15/20], Step [450/600], Loss: 0.458204984664917, Test Accuracy: 86.35%\n",
      "{i+1}Epoch [15/20], Step [500/600], Loss: 0.45999225974082947, Test Accuracy: 86.12%\n",
      "{i+1}Epoch [15/20], Step [550/600], Loss: 0.4281346797943115, Test Accuracy: 86.31%\n",
      "{i+1}Epoch [15/20], Step [600/600], Loss: 0.4605848789215088, Test Accuracy: 86.53%\n",
      "{i+1}Epoch [16/20], Step [50/600], Loss: 0.5028740167617798, Test Accuracy: 86.46%\n",
      "{i+1}Epoch [16/20], Step [100/600], Loss: 0.4614045023918152, Test Accuracy: 86.36%\n",
      "{i+1}Epoch [16/20], Step [150/600], Loss: 0.4768342971801758, Test Accuracy: 86.36%\n",
      "{i+1}Epoch [16/20], Step [200/600], Loss: 0.45221686363220215, Test Accuracy: 85.38%\n",
      "{i+1}Epoch [16/20], Step [250/600], Loss: 0.482558012008667, Test Accuracy: 85.95%\n",
      "{i+1}Epoch [16/20], Step [300/600], Loss: 0.47803986072540283, Test Accuracy: 86.29%\n",
      "{i+1}Epoch [16/20], Step [350/600], Loss: 0.47867336869239807, Test Accuracy: 86.37%\n",
      "{i+1}Epoch [16/20], Step [400/600], Loss: 0.4772329032421112, Test Accuracy: 86.05%\n",
      "{i+1}Epoch [16/20], Step [450/600], Loss: 0.4553970694541931, Test Accuracy: 86.2%\n",
      "{i+1}Epoch [16/20], Step [500/600], Loss: 0.5411120057106018, Test Accuracy: 86.34%\n",
      "{i+1}Epoch [16/20], Step [550/600], Loss: 0.47920066118240356, Test Accuracy: 85.94%\n",
      "{i+1}Epoch [16/20], Step [600/600], Loss: 0.4527951776981354, Test Accuracy: 86.37%\n",
      "{i+1}Epoch [17/20], Step [50/600], Loss: 0.40086108446121216, Test Accuracy: 86.26%\n",
      "{i+1}Epoch [17/20], Step [100/600], Loss: 0.48032906651496887, Test Accuracy: 86.34%\n",
      "{i+1}Epoch [17/20], Step [150/600], Loss: 0.4580416977405548, Test Accuracy: 86.29%\n",
      "{i+1}Epoch [17/20], Step [200/600], Loss: 0.5067472457885742, Test Accuracy: 86.27%\n",
      "{i+1}Epoch [17/20], Step [250/600], Loss: 0.43806686997413635, Test Accuracy: 86.44%\n",
      "{i+1}Epoch [17/20], Step [300/600], Loss: 0.4488818049430847, Test Accuracy: 86.18%\n",
      "{i+1}Epoch [17/20], Step [350/600], Loss: 0.44809868931770325, Test Accuracy: 86.03%\n",
      "{i+1}Epoch [17/20], Step [400/600], Loss: 0.48344022035598755, Test Accuracy: 86.13%\n",
      "{i+1}Epoch [17/20], Step [450/600], Loss: 0.4575428068637848, Test Accuracy: 86.24%\n",
      "{i+1}Epoch [17/20], Step [500/600], Loss: 0.4303681552410126, Test Accuracy: 86.05%\n",
      "{i+1}Epoch [17/20], Step [550/600], Loss: 0.43229615688323975, Test Accuracy: 86.06%\n",
      "{i+1}Epoch [17/20], Step [600/600], Loss: 0.45576000213623047, Test Accuracy: 86.14%\n",
      "{i+1}Epoch [18/20], Step [50/600], Loss: 0.45243847370147705, Test Accuracy: 86.59%\n",
      "{i+1}Epoch [18/20], Step [100/600], Loss: 0.42399048805236816, Test Accuracy: 86.71%\n",
      "{i+1}Epoch [18/20], Step [150/600], Loss: 0.5353400707244873, Test Accuracy: 86.12%\n",
      "{i+1}Epoch [18/20], Step [200/600], Loss: 0.4339069724082947, Test Accuracy: 86.44%\n",
      "{i+1}Epoch [18/20], Step [250/600], Loss: 0.4465644061565399, Test Accuracy: 86.61%\n",
      "{i+1}Epoch [18/20], Step [300/600], Loss: 0.5228705406188965, Test Accuracy: 86.32%\n",
      "{i+1}Epoch [18/20], Step [350/600], Loss: 0.49306973814964294, Test Accuracy: 86.44%\n",
      "{i+1}Epoch [18/20], Step [400/600], Loss: 0.45499905943870544, Test Accuracy: 86.2%\n",
      "{i+1}Epoch [18/20], Step [450/600], Loss: 0.42778781056404114, Test Accuracy: 86.44%\n",
      "{i+1}Epoch [18/20], Step [500/600], Loss: 0.4636363089084625, Test Accuracy: 86.38%\n",
      "{i+1}Epoch [18/20], Step [550/600], Loss: 0.44423243403434753, Test Accuracy: 86.27%\n",
      "{i+1}Epoch [18/20], Step [600/600], Loss: 0.4705233871936798, Test Accuracy: 85.86%\n",
      "{i+1}Epoch [19/20], Step [50/600], Loss: 0.44033297896385193, Test Accuracy: 85.88%\n",
      "{i+1}Epoch [19/20], Step [100/600], Loss: 0.4581785500049591, Test Accuracy: 86.02%\n",
      "{i+1}Epoch [19/20], Step [150/600], Loss: 0.4502609670162201, Test Accuracy: 86.33%\n",
      "{i+1}Epoch [19/20], Step [200/600], Loss: 0.47505661845207214, Test Accuracy: 85.92%\n",
      "{i+1}Epoch [19/20], Step [250/600], Loss: 0.4810198247432709, Test Accuracy: 86.5%\n",
      "{i+1}Epoch [19/20], Step [300/600], Loss: 0.4864793121814728, Test Accuracy: 86.32%\n",
      "{i+1}Epoch [19/20], Step [350/600], Loss: 0.46768319606781006, Test Accuracy: 86.62%\n",
      "{i+1}Epoch [19/20], Step [400/600], Loss: 0.48673030734062195, Test Accuracy: 86.3%\n",
      "{i+1}Epoch [19/20], Step [450/600], Loss: 0.4203590452671051, Test Accuracy: 86.56%\n",
      "{i+1}Epoch [19/20], Step [500/600], Loss: 0.46950438618659973, Test Accuracy: 86.35%\n",
      "{i+1}Epoch [19/20], Step [550/600], Loss: 0.4316214621067047, Test Accuracy: 85.74%\n",
      "{i+1}Epoch [19/20], Step [600/600], Loss: 0.4237162470817566, Test Accuracy: 86.36%\n",
      "{i+1}Epoch [20/20], Step [50/600], Loss: 0.4358987808227539, Test Accuracy: 86.48%\n",
      "{i+1}Epoch [20/20], Step [100/600], Loss: 0.4520372450351715, Test Accuracy: 86.69%\n",
      "{i+1}Epoch [20/20], Step [150/600], Loss: 0.4845051169395447, Test Accuracy: 86.61%\n",
      "{i+1}Epoch [20/20], Step [200/600], Loss: 0.5053287148475647, Test Accuracy: 86.05%\n",
      "{i+1}Epoch [20/20], Step [250/600], Loss: 0.4749724268913269, Test Accuracy: 86.44%\n",
      "{i+1}Epoch [20/20], Step [300/600], Loss: 0.4440849721431732, Test Accuracy: 86.43%\n",
      "{i+1}Epoch [20/20], Step [350/600], Loss: 0.45867010951042175, Test Accuracy: 86.01%\n",
      "{i+1}Epoch [20/20], Step [400/600], Loss: 0.44179001450538635, Test Accuracy: 86.24%\n",
      "{i+1}Epoch [20/20], Step [450/600], Loss: 0.4564043879508972, Test Accuracy: 86.36%\n",
      "{i+1}Epoch [20/20], Step [500/600], Loss: 0.4368336796760559, Test Accuracy: 86.21%\n",
      "{i+1}Epoch [20/20], Step [550/600], Loss: 0.46381762623786926, Test Accuracy: 86.52%\n",
      "{i+1}Epoch [20/20], Step [600/600], Loss: 0.43930405378341675, Test Accuracy: 86.35%\n"
     ]
    }
   ],
   "source": [
    "#PEPG pop size scan\n",
    "\n",
    "n_epochs =20\n",
    "\n",
    "pop_vec = [5, 10, 20, 50, 100, 200, 300, 500]\n",
    "\n",
    "test_acc_mat_PEPG = np.zeros((len(pop_vec),12*n_epochs))\n",
    "#best_reward_mat_PEPG = np.zeros((len(pop_vec),600*n_epochs))\n",
    "\n",
    "for i,k in enumerate(pop_vec):\n",
    "    print(k)\n",
    "    NN_MNIST = Tiny_convnet()\n",
    "    N_dim = NN_MNIST.count_parameters()\n",
    "    #specify we don't need the computation graph to keep track of the gradients, we will use SPSA to update the weights\n",
    "    with torch.no_grad():\n",
    "        for param in NN_MNIST.parameters():\n",
    "            param.requires_grad = False\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    # learning parameters\n",
    "\n",
    "    init_pos = NN_MNIST.get_params()\n",
    "\n",
    "    if init_pos.requires_grad:\n",
    "        # Detach the tensor from the computation graph\n",
    "        init_pos = init_pos.detach()\n",
    "    if init_pos.is_cuda:\n",
    "        # Move the tensor to the CPU\n",
    "        init_pos = init_pos.cpu()\n",
    "    init_pos = init_pos.numpy()\n",
    "    \n",
    "    PEPG_optimizer = PEPG_opt(N_dim, pop_size = k, learning_rate=0.01, starting_mu=init_pos ,starting_sigma=0.1)\n",
    "\n",
    "    PEPG_optimizer.sigma_decay = 0.9999\n",
    "    PEPG_optimizer.sigma_alpha=0.2\n",
    "    PEPG_optimizer.sigma_limit=0.02\n",
    "    PEPG_optimizer.elite_ratio=0.1\n",
    "    PEPG_optimizer.weight_decay=0.005\n",
    "\n",
    "    test_acc_PEPG,best_reward_PEPG = train_online_pop_NN(NN_MNIST, n_epochs, train_loader_MNIST, test_loader_MNIST, loss, PEPG_optimizer)\n",
    "    \n",
    "    test_acc_mat_PEPG[i,:] = test_acc_PEPG\n",
    "    #best_reward_mat_PEPG[i,:] = best_reward_PEPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot population size scan of PEPG\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "best_acc_pop = np.max(test_acc_mat_PEPG, axis=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=pop_vec, y=best_acc_pop, mode='lines', name='PEPG'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "PEPG",
         "type": "scatter",
         "x": [
          0.044349831470640415,
          0.08869966294128083,
          0.17739932588256166,
          0.4434983147064041,
          0.8869966294128082,
          1.7739932588256164,
          2.660989888238425,
          4.434983147064041
         ],
         "y": [
          75.86,
          78.84,
          80.93,
          84.58,
          84.91,
          86.61,
          86.62,
          86.71
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot population size ratio of PEPG\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "best_acc_pop = np.max(test_acc_mat_PEPG, axis=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=100*np.array(pop_vec)/11274, y=best_acc_pop, mode='lines', name='PEPG'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
