{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from CMA_obj import CMA_opt\n",
    "from PEPG_obj import PEPG_opt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from SPSA_obj import SPSA_opt\n",
    "from Finite_diff_grad import FD_opt\n",
    "from ADAM_opt import AdamOptimizer\n",
    "from PSO_obj import PSO_opt\n",
    "from scipy.interpolate import interp1d\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "from NN_utils_IRIS import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Online Training of Neural Networks IRIS, Wine\n",
    "\n",
    "- The NN class helper functions and training loop functions are defined in NN_utils, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets\n",
    "X is the input, Y the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\PhD\\simulation\\simulation_python\\learning_strategies\\NN_utils_IRIS.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.features = torch.tensor(features, dtype=torch.float)\n",
      "c:\\Users\\Admin\\Desktop\\PhD\\simulation\\simulation_python\\learning_strategies\\NN_utils_IRIS.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.long).squeeze()  # Convert and squeeze labels\n"
     ]
    }
   ],
   "source": [
    "#Iris dataset\n",
    "iris_df = pd.read_csv(\"data\\\\IRIS\\\\iris.csv\")\n",
    "# convert the last column \n",
    "\n",
    "\n",
    "iris_raw = iris_df.values\n",
    "\n",
    "for i in range(len(iris_raw)):\n",
    "    if iris_raw[i,-1] == 'Iris-setosa':\n",
    "        iris_raw[i,-1] = 0\n",
    "    elif iris_raw[i,-1] == 'Iris-versicolor':\n",
    "        iris_raw[i,-1] = 1\n",
    "    else:\n",
    "        iris_raw[i,-1] = 2\n",
    "        \n",
    "iris_raw = iris_raw.astype(np.float32)\n",
    "#remove the first column because it is just an index\n",
    "iris_raw = iris_raw[:,1:]\n",
    "#iris raw needs to be shuffled randomly because the data is ordered by class\n",
    "np.random.shuffle(iris_raw)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.from_numpy(iris_raw[:, :-1])\n",
    "Y = torch.from_numpy(iris_raw[:, -1]).unsqueeze(1)\n",
    "\n",
    "# Create a single dataset\n",
    "full_dataset = Custom_dataset(X, Y)\n",
    "\n",
    "# Split into train and test sets, first set the size of the split\n",
    "train_size = int(0.75 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "# split into train and test sets using pytorch randomsplit\n",
    "Iris_train, Iris_test = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "Iris_train_loader = torch.utils.data.DataLoader(dataset=Iris_train, batch_size=train_size, shuffle=True)\n",
    "Iris_test_loader = torch.utils.data.DataLoader(dataset=Iris_test, batch_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Iris_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/200], Step [1/1], Loss: 1.1196235418319702, Test Accuracy: 60.526315789473685%\n",
      "Epoch [2/200], Step [1/1], Loss: 1.0772697925567627, Test Accuracy: 31.57894736842105%\n",
      "Epoch [3/200], Step [1/1], Loss: 1.0481926202774048, Test Accuracy: 31.57894736842105%\n",
      "Epoch [4/200], Step [1/1], Loss: 1.0262075662612915, Test Accuracy: 31.57894736842105%\n",
      "Epoch [5/200], Step [1/1], Loss: 1.0095471143722534, Test Accuracy: 31.57894736842105%\n",
      "Epoch [6/200], Step [1/1], Loss: 0.9973515272140503, Test Accuracy: 31.57894736842105%\n",
      "Epoch [7/200], Step [1/1], Loss: 0.9883865118026733, Test Accuracy: 31.57894736842105%\n",
      "Epoch [8/200], Step [1/1], Loss: 0.9811901450157166, Test Accuracy: 23.68421052631579%\n",
      "Epoch [9/200], Step [1/1], Loss: 0.9743272662162781, Test Accuracy: 23.68421052631579%\n",
      "Epoch [10/200], Step [1/1], Loss: 0.9666157960891724, Test Accuracy: 23.68421052631579%\n",
      "Epoch [11/200], Step [1/1], Loss: 0.957394540309906, Test Accuracy: 23.68421052631579%\n",
      "Epoch [12/200], Step [1/1], Loss: 0.9465685486793518, Test Accuracy: 36.8421052631579%\n",
      "Epoch [13/200], Step [1/1], Loss: 0.9344308972358704, Test Accuracy: 47.36842105263158%\n",
      "Epoch [14/200], Step [1/1], Loss: 0.9214221239089966, Test Accuracy: 42.10526315789474%\n",
      "Epoch [15/200], Step [1/1], Loss: 0.9079449772834778, Test Accuracy: 63.1578947368421%\n",
      "Epoch [16/200], Step [1/1], Loss: 0.8942717909812927, Test Accuracy: 73.6842105263158%\n",
      "Epoch [17/200], Step [1/1], Loss: 0.8805244565010071, Test Accuracy: 76.3157894736842%\n",
      "Epoch [18/200], Step [1/1], Loss: 0.8667150139808655, Test Accuracy: 76.3157894736842%\n",
      "Epoch [19/200], Step [1/1], Loss: 0.8527949452400208, Test Accuracy: 76.3157894736842%\n",
      "Epoch [20/200], Step [1/1], Loss: 0.8387013673782349, Test Accuracy: 76.3157894736842%\n",
      "Epoch [21/200], Step [1/1], Loss: 0.8243862390518188, Test Accuracy: 76.3157894736842%\n",
      "Epoch [22/200], Step [1/1], Loss: 0.8098254799842834, Test Accuracy: 76.3157894736842%\n",
      "Epoch [23/200], Step [1/1], Loss: 0.7950178384780884, Test Accuracy: 76.3157894736842%\n",
      "Epoch [24/200], Step [1/1], Loss: 0.7799893021583557, Test Accuracy: 76.3157894736842%\n",
      "Epoch [25/200], Step [1/1], Loss: 0.7647524476051331, Test Accuracy: 76.3157894736842%\n",
      "Epoch [26/200], Step [1/1], Loss: 0.7493295669555664, Test Accuracy: 78.94736842105263%\n",
      "Epoch [27/200], Step [1/1], Loss: 0.7337389588356018, Test Accuracy: 78.94736842105263%\n",
      "Epoch [28/200], Step [1/1], Loss: 0.7180391550064087, Test Accuracy: 81.57894736842105%\n",
      "Epoch [29/200], Step [1/1], Loss: 0.7023102045059204, Test Accuracy: 84.21052631578948%\n",
      "Epoch [30/200], Step [1/1], Loss: 0.6866467595100403, Test Accuracy: 86.84210526315789%\n",
      "Epoch [31/200], Step [1/1], Loss: 0.6711581945419312, Test Accuracy: 89.47368421052632%\n",
      "Epoch [32/200], Step [1/1], Loss: 0.6559365391731262, Test Accuracy: 92.10526315789474%\n",
      "Epoch [33/200], Step [1/1], Loss: 0.6410689353942871, Test Accuracy: 92.10526315789474%\n",
      "Epoch [34/200], Step [1/1], Loss: 0.6266339421272278, Test Accuracy: 89.47368421052632%\n",
      "Epoch [35/200], Step [1/1], Loss: 0.6126881241798401, Test Accuracy: 89.47368421052632%\n",
      "Epoch [36/200], Step [1/1], Loss: 0.5992763638496399, Test Accuracy: 89.47368421052632%\n",
      "Epoch [37/200], Step [1/1], Loss: 0.5864430069923401, Test Accuracy: 89.47368421052632%\n",
      "Epoch [38/200], Step [1/1], Loss: 0.5741519331932068, Test Accuracy: 89.47368421052632%\n",
      "Epoch [39/200], Step [1/1], Loss: 0.5623847246170044, Test Accuracy: 89.47368421052632%\n",
      "Epoch [40/200], Step [1/1], Loss: 0.5511384606361389, Test Accuracy: 92.10526315789474%\n",
      "Epoch [41/200], Step [1/1], Loss: 0.540372908115387, Test Accuracy: 92.10526315789474%\n",
      "Epoch [42/200], Step [1/1], Loss: 0.5301152467727661, Test Accuracy: 94.73684210526316%\n",
      "Epoch [43/200], Step [1/1], Loss: 0.5203002095222473, Test Accuracy: 97.36842105263158%\n",
      "Epoch [44/200], Step [1/1], Loss: 0.5109338164329529, Test Accuracy: 97.36842105263158%\n",
      "Epoch [45/200], Step [1/1], Loss: 0.5020233988761902, Test Accuracy: 97.36842105263158%\n",
      "Epoch [46/200], Step [1/1], Loss: 0.49356475472450256, Test Accuracy: 97.36842105263158%\n",
      "Epoch [47/200], Step [1/1], Loss: 0.48553749918937683, Test Accuracy: 97.36842105263158%\n",
      "Epoch [48/200], Step [1/1], Loss: 0.47781112790107727, Test Accuracy: 97.36842105263158%\n",
      "Epoch [49/200], Step [1/1], Loss: 0.4703405201435089, Test Accuracy: 97.36842105263158%\n",
      "Epoch [50/200], Step [1/1], Loss: 0.4631003439426422, Test Accuracy: 97.36842105263158%\n",
      "Epoch [51/200], Step [1/1], Loss: 0.4560478627681732, Test Accuracy: 97.36842105263158%\n",
      "Epoch [52/200], Step [1/1], Loss: 0.4491855204105377, Test Accuracy: 97.36842105263158%\n",
      "Epoch [53/200], Step [1/1], Loss: 0.4424939453601837, Test Accuracy: 97.36842105263158%\n",
      "Epoch [54/200], Step [1/1], Loss: 0.4359596371650696, Test Accuracy: 97.36842105263158%\n",
      "Epoch [55/200], Step [1/1], Loss: 0.42956122756004333, Test Accuracy: 97.36842105263158%\n",
      "Epoch [56/200], Step [1/1], Loss: 0.42326730489730835, Test Accuracy: 97.36842105263158%\n",
      "Epoch [57/200], Step [1/1], Loss: 0.4170614182949066, Test Accuracy: 97.36842105263158%\n",
      "Epoch [58/200], Step [1/1], Loss: 0.4109424948692322, Test Accuracy: 97.36842105263158%\n",
      "Epoch [59/200], Step [1/1], Loss: 0.40491244196891785, Test Accuracy: 97.36842105263158%\n",
      "Epoch [60/200], Step [1/1], Loss: 0.39896631240844727, Test Accuracy: 97.36842105263158%\n",
      "Epoch [61/200], Step [1/1], Loss: 0.39309099316596985, Test Accuracy: 97.36842105263158%\n",
      "Epoch [62/200], Step [1/1], Loss: 0.3872729241847992, Test Accuracy: 97.36842105263158%\n",
      "Epoch [63/200], Step [1/1], Loss: 0.3815040588378906, Test Accuracy: 97.36842105263158%\n",
      "Epoch [64/200], Step [1/1], Loss: 0.37578660249710083, Test Accuracy: 97.36842105263158%\n",
      "Epoch [65/200], Step [1/1], Loss: 0.3701281249523163, Test Accuracy: 97.36842105263158%\n",
      "Epoch [66/200], Step [1/1], Loss: 0.36453506350517273, Test Accuracy: 97.36842105263158%\n",
      "Epoch [67/200], Step [1/1], Loss: 0.3590005338191986, Test Accuracy: 97.36842105263158%\n",
      "Epoch [68/200], Step [1/1], Loss: 0.3535180687904358, Test Accuracy: 97.36842105263158%\n",
      "Epoch [69/200], Step [1/1], Loss: 0.3480875790119171, Test Accuracy: 97.36842105263158%\n",
      "Epoch [70/200], Step [1/1], Loss: 0.3427155911922455, Test Accuracy: 97.36842105263158%\n",
      "Epoch [71/200], Step [1/1], Loss: 0.3374079763889313, Test Accuracy: 97.36842105263158%\n",
      "Epoch [72/200], Step [1/1], Loss: 0.3321619927883148, Test Accuracy: 97.36842105263158%\n",
      "Epoch [73/200], Step [1/1], Loss: 0.32697081565856934, Test Accuracy: 97.36842105263158%\n",
      "Epoch [74/200], Step [1/1], Loss: 0.32183289527893066, Test Accuracy: 97.36842105263158%\n",
      "Epoch [75/200], Step [1/1], Loss: 0.31675347685813904, Test Accuracy: 97.36842105263158%\n",
      "Epoch [76/200], Step [1/1], Loss: 0.3117389380931854, Test Accuracy: 97.36842105263158%\n",
      "Epoch [77/200], Step [1/1], Loss: 0.3067916929721832, Test Accuracy: 97.36842105263158%\n",
      "Epoch [78/200], Step [1/1], Loss: 0.3019103705883026, Test Accuracy: 97.36842105263158%\n",
      "Epoch [79/200], Step [1/1], Loss: 0.2970947325229645, Test Accuracy: 100.0%\n",
      "Epoch [80/200], Step [1/1], Loss: 0.29234784841537476, Test Accuracy: 100.0%\n",
      "Epoch [81/200], Step [1/1], Loss: 0.28767314553260803, Test Accuracy: 100.0%\n",
      "Epoch [82/200], Step [1/1], Loss: 0.2830703556537628, Test Accuracy: 100.0%\n",
      "Epoch [83/200], Step [1/1], Loss: 0.2785376012325287, Test Accuracy: 100.0%\n",
      "Epoch [84/200], Step [1/1], Loss: 0.2740747034549713, Test Accuracy: 100.0%\n",
      "Epoch [85/200], Step [1/1], Loss: 0.26968446373939514, Test Accuracy: 100.0%\n",
      "Epoch [86/200], Step [1/1], Loss: 0.2653694152832031, Test Accuracy: 100.0%\n",
      "Epoch [87/200], Step [1/1], Loss: 0.26113080978393555, Test Accuracy: 100.0%\n",
      "Epoch [88/200], Step [1/1], Loss: 0.2569732069969177, Test Accuracy: 100.0%\n",
      "Epoch [89/200], Step [1/1], Loss: 0.25289446115493774, Test Accuracy: 100.0%\n",
      "Epoch [90/200], Step [1/1], Loss: 0.2488943487405777, Test Accuracy: 100.0%\n",
      "Epoch [91/200], Step [1/1], Loss: 0.2449749857187271, Test Accuracy: 100.0%\n",
      "Epoch [92/200], Step [1/1], Loss: 0.2411312758922577, Test Accuracy: 100.0%\n",
      "Epoch [93/200], Step [1/1], Loss: 0.23736633360385895, Test Accuracy: 100.0%\n",
      "Epoch [94/200], Step [1/1], Loss: 0.23368164896965027, Test Accuracy: 100.0%\n",
      "Epoch [95/200], Step [1/1], Loss: 0.23007333278656006, Test Accuracy: 100.0%\n",
      "Epoch [96/200], Step [1/1], Loss: 0.22654081881046295, Test Accuracy: 100.0%\n",
      "Epoch [97/200], Step [1/1], Loss: 0.22308656573295593, Test Accuracy: 100.0%\n",
      "Epoch [98/200], Step [1/1], Loss: 0.21970859169960022, Test Accuracy: 100.0%\n",
      "Epoch [99/200], Step [1/1], Loss: 0.21640488505363464, Test Accuracy: 100.0%\n",
      "Epoch [100/200], Step [1/1], Loss: 0.21317532658576965, Test Accuracy: 100.0%\n",
      "Epoch [101/200], Step [1/1], Loss: 0.21001924574375153, Test Accuracy: 100.0%\n",
      "Epoch [102/200], Step [1/1], Loss: 0.2069336324930191, Test Accuracy: 100.0%\n",
      "Epoch [103/200], Step [1/1], Loss: 0.20391765236854553, Test Accuracy: 100.0%\n",
      "Epoch [104/200], Step [1/1], Loss: 0.20097018778324127, Test Accuracy: 100.0%\n",
      "Epoch [105/200], Step [1/1], Loss: 0.19808967411518097, Test Accuracy: 100.0%\n",
      "Epoch [106/200], Step [1/1], Loss: 0.19527412950992584, Test Accuracy: 100.0%\n",
      "Epoch [107/200], Step [1/1], Loss: 0.19252237677574158, Test Accuracy: 100.0%\n",
      "Epoch [108/200], Step [1/1], Loss: 0.1898335963487625, Test Accuracy: 100.0%\n",
      "Epoch [109/200], Step [1/1], Loss: 0.18720659613609314, Test Accuracy: 100.0%\n",
      "Epoch [110/200], Step [1/1], Loss: 0.1846400648355484, Test Accuracy: 100.0%\n",
      "Epoch [111/200], Step [1/1], Loss: 0.18213339149951935, Test Accuracy: 100.0%\n",
      "Epoch [112/200], Step [1/1], Loss: 0.17968647181987762, Test Accuracy: 100.0%\n",
      "Epoch [113/200], Step [1/1], Loss: 0.17729921638965607, Test Accuracy: 100.0%\n",
      "Epoch [114/200], Step [1/1], Loss: 0.17496958374977112, Test Accuracy: 100.0%\n",
      "Epoch [115/200], Step [1/1], Loss: 0.1726960688829422, Test Accuracy: 100.0%\n",
      "Epoch [116/200], Step [1/1], Loss: 0.1704767793416977, Test Accuracy: 100.0%\n",
      "Epoch [117/200], Step [1/1], Loss: 0.16831037402153015, Test Accuracy: 100.0%\n",
      "Epoch [118/200], Step [1/1], Loss: 0.1661955863237381, Test Accuracy: 100.0%\n",
      "Epoch [119/200], Step [1/1], Loss: 0.16413143277168274, Test Accuracy: 100.0%\n",
      "Epoch [120/200], Step [1/1], Loss: 0.16211700439453125, Test Accuracy: 100.0%\n",
      "Epoch [121/200], Step [1/1], Loss: 0.16015122830867767, Test Accuracy: 100.0%\n",
      "Epoch [122/200], Step [1/1], Loss: 0.1582328826189041, Test Accuracy: 100.0%\n",
      "Epoch [123/200], Step [1/1], Loss: 0.1563609391450882, Test Accuracy: 100.0%\n",
      "Epoch [124/200], Step [1/1], Loss: 0.15453436970710754, Test Accuracy: 100.0%\n",
      "Epoch [125/200], Step [1/1], Loss: 0.15275205671787262, Test Accuracy: 100.0%\n",
      "Epoch [126/200], Step [1/1], Loss: 0.15101267397403717, Test Accuracy: 100.0%\n",
      "Epoch [127/200], Step [1/1], Loss: 0.14931531250476837, Test Accuracy: 100.0%\n",
      "Epoch [128/200], Step [1/1], Loss: 0.14765875041484833, Test Accuracy: 100.0%\n",
      "Epoch [129/200], Step [1/1], Loss: 0.14604195952415466, Test Accuracy: 100.0%\n",
      "Epoch [130/200], Step [1/1], Loss: 0.14446380734443665, Test Accuracy: 100.0%\n",
      "Epoch [131/200], Step [1/1], Loss: 0.1429232358932495, Test Accuracy: 100.0%\n",
      "Epoch [132/200], Step [1/1], Loss: 0.14141930639743805, Test Accuracy: 100.0%\n",
      "Epoch [133/200], Step [1/1], Loss: 0.13995100557804108, Test Accuracy: 100.0%\n",
      "Epoch [134/200], Step [1/1], Loss: 0.1385173797607422, Test Accuracy: 100.0%\n",
      "Epoch [135/200], Step [1/1], Loss: 0.13711750507354736, Test Accuracy: 100.0%\n",
      "Epoch [136/200], Step [1/1], Loss: 0.1357503980398178, Test Accuracy: 100.0%\n",
      "Epoch [137/200], Step [1/1], Loss: 0.13441528379917145, Test Accuracy: 100.0%\n",
      "Epoch [138/200], Step [1/1], Loss: 0.13311153650283813, Test Accuracy: 100.0%\n",
      "Epoch [139/200], Step [1/1], Loss: 0.13183791935443878, Test Accuracy: 100.0%\n",
      "Epoch [140/200], Step [1/1], Loss: 0.13059359788894653, Test Accuracy: 100.0%\n",
      "Epoch [141/200], Step [1/1], Loss: 0.12937888503074646, Test Accuracy: 100.0%\n",
      "Epoch [142/200], Step [1/1], Loss: 0.12819243967533112, Test Accuracy: 100.0%\n",
      "Epoch [143/200], Step [1/1], Loss: 0.1270330399274826, Test Accuracy: 100.0%\n",
      "Epoch [144/200], Step [1/1], Loss: 0.12589992582798004, Test Accuracy: 100.0%\n",
      "Epoch [145/200], Step [1/1], Loss: 0.12479228526353836, Test Accuracy: 100.0%\n",
      "Epoch [146/200], Step [1/1], Loss: 0.12370937317609787, Test Accuracy: 100.0%\n",
      "Epoch [147/200], Step [1/1], Loss: 0.12265058606863022, Test Accuracy: 100.0%\n",
      "Epoch [148/200], Step [1/1], Loss: 0.12161523848772049, Test Accuracy: 100.0%\n",
      "Epoch [149/200], Step [1/1], Loss: 0.12060261517763138, Test Accuracy: 100.0%\n",
      "Epoch [150/200], Step [1/1], Loss: 0.11961200088262558, Test Accuracy: 100.0%\n",
      "Epoch [151/200], Step [1/1], Loss: 0.1186428815126419, Test Accuracy: 100.0%\n",
      "Epoch [152/200], Step [1/1], Loss: 0.11769454181194305, Test Accuracy: 100.0%\n",
      "Epoch [153/200], Step [1/1], Loss: 0.11676650494337082, Test Accuracy: 100.0%\n",
      "Epoch [154/200], Step [1/1], Loss: 0.11585817486047745, Test Accuracy: 100.0%\n",
      "Epoch [155/200], Step [1/1], Loss: 0.11496911942958832, Test Accuracy: 100.0%\n",
      "Epoch [156/200], Step [1/1], Loss: 0.11409862339496613, Test Accuracy: 100.0%\n",
      "Epoch [157/200], Step [1/1], Loss: 0.11324621737003326, Test Accuracy: 100.0%\n",
      "Epoch [158/200], Step [1/1], Loss: 0.11241137981414795, Test Accuracy: 100.0%\n",
      "Epoch [159/200], Step [1/1], Loss: 0.1115935668349266, Test Accuracy: 100.0%\n",
      "Epoch [160/200], Step [1/1], Loss: 0.11079246550798416, Test Accuracy: 100.0%\n",
      "Epoch [161/200], Step [1/1], Loss: 0.11000748723745346, Test Accuracy: 100.0%\n",
      "Epoch [162/200], Step [1/1], Loss: 0.10923821479082108, Test Accuracy: 100.0%\n",
      "Epoch [163/200], Step [1/1], Loss: 0.10848426073789597, Test Accuracy: 100.0%\n",
      "Epoch [164/200], Step [1/1], Loss: 0.1077452078461647, Test Accuracy: 100.0%\n",
      "Epoch [165/200], Step [1/1], Loss: 0.10702057927846909, Test Accuracy: 100.0%\n",
      "Epoch [166/200], Step [1/1], Loss: 0.10631007701158524, Test Accuracy: 100.0%\n",
      "Epoch [167/200], Step [1/1], Loss: 0.10561323910951614, Test Accuracy: 100.0%\n",
      "Epoch [168/200], Step [1/1], Loss: 0.10492975264787674, Test Accuracy: 100.0%\n",
      "Epoch [169/200], Step [1/1], Loss: 0.10425926744937897, Test Accuracy: 97.36842105263158%\n",
      "Epoch [170/200], Step [1/1], Loss: 0.1036013811826706, Test Accuracy: 97.36842105263158%\n",
      "Epoch [171/200], Step [1/1], Loss: 0.10295584052801132, Test Accuracy: 97.36842105263158%\n",
      "Epoch [172/200], Step [1/1], Loss: 0.10232226550579071, Test Accuracy: 97.36842105263158%\n",
      "Epoch [173/200], Step [1/1], Loss: 0.10170034319162369, Test Accuracy: 97.36842105263158%\n",
      "Epoch [174/200], Step [1/1], Loss: 0.10108982026576996, Test Accuracy: 97.36842105263158%\n",
      "Epoch [175/200], Step [1/1], Loss: 0.10049029439687729, Test Accuracy: 97.36842105263158%\n",
      "Epoch [176/200], Step [1/1], Loss: 0.09990160167217255, Test Accuracy: 97.36842105263158%\n",
      "Epoch [177/200], Step [1/1], Loss: 0.09932342916727066, Test Accuracy: 97.36842105263158%\n",
      "Epoch [178/200], Step [1/1], Loss: 0.09875544160604477, Test Accuracy: 97.36842105263158%\n",
      "Epoch [179/200], Step [1/1], Loss: 0.09819741547107697, Test Accuracy: 97.36842105263158%\n",
      "Epoch [180/200], Step [1/1], Loss: 0.09764917939901352, Test Accuracy: 97.36842105263158%\n",
      "Epoch [181/200], Step [1/1], Loss: 0.09711035341024399, Test Accuracy: 97.36842105263158%\n",
      "Epoch [182/200], Step [1/1], Loss: 0.09658078849315643, Test Accuracy: 97.36842105263158%\n",
      "Epoch [183/200], Step [1/1], Loss: 0.09606031328439713, Test Accuracy: 97.36842105263158%\n",
      "Epoch [184/200], Step [1/1], Loss: 0.09554855525493622, Test Accuracy: 97.36842105263158%\n",
      "Epoch [185/200], Step [1/1], Loss: 0.09504539519548416, Test Accuracy: 97.36842105263158%\n",
      "Epoch [186/200], Step [1/1], Loss: 0.09455059468746185, Test Accuracy: 97.36842105263158%\n",
      "Epoch [187/200], Step [1/1], Loss: 0.09406393766403198, Test Accuracy: 97.36842105263158%\n",
      "Epoch [188/200], Step [1/1], Loss: 0.093585304915905, Test Accuracy: 97.36842105263158%\n",
      "Epoch [189/200], Step [1/1], Loss: 0.09311442822217941, Test Accuracy: 97.36842105263158%\n",
      "Epoch [190/200], Step [1/1], Loss: 0.09265115112066269, Test Accuracy: 97.36842105263158%\n",
      "Epoch [191/200], Step [1/1], Loss: 0.0921952947974205, Test Accuracy: 97.36842105263158%\n",
      "Epoch [192/200], Step [1/1], Loss: 0.09174667298793793, Test Accuracy: 97.36842105263158%\n",
      "Epoch [193/200], Step [1/1], Loss: 0.09130512923002243, Test Accuracy: 97.36842105263158%\n",
      "Epoch [194/200], Step [1/1], Loss: 0.0908704623579979, Test Accuracy: 97.36842105263158%\n",
      "Epoch [195/200], Step [1/1], Loss: 0.09044259041547775, Test Accuracy: 97.36842105263158%\n",
      "Epoch [196/200], Step [1/1], Loss: 0.0900212749838829, Test Accuracy: 97.36842105263158%\n",
      "Epoch [197/200], Step [1/1], Loss: 0.08960641920566559, Test Accuracy: 97.36842105263158%\n",
      "Epoch [198/200], Step [1/1], Loss: 0.08919788897037506, Test Accuracy: 97.36842105263158%\n",
      "Epoch [199/200], Step [1/1], Loss: 0.08879547566175461, Test Accuracy: 97.36842105263158%\n",
      "Epoch [200/200], Step [1/1], Loss: 0.08839908987283707, Test Accuracy: 97.36842105263158%\n"
     ]
    }
   ],
   "source": [
    "#We Now create an instance of the NN class and move if to the GPU if available\n",
    "n_neurons = 10\n",
    "NN_IRIS = Neural_Net(input_size=4, hidden_size=n_neurons, n_classes=3)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(NN_IRIS.parameters(), lr=0.01)\n",
    "\n",
    "#training the full NN\n",
    "n_epochs = 200\n",
    "test_acc = train_pytorch_NN(NN_IRIS, n_epochs, Iris_train_loader, Iris_test_loader, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                    [-1, 4]               0\n",
      "            Linear-2                   [-1, 10]              50\n",
      "              ReLU-3                   [-1, 10]               0\n",
      "            Linear-4                    [-1, 3]              33\n",
      "================================================================\n",
      "Total params: 83\n",
      "Trainable params: 0\n",
      "Non-trainable params: 83\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(NN_IRIS, input_size=(4, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the network:  83\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of parameters in the network: \",NN_IRIS.num_params)\n",
    "print(NN_IRIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Full NN",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "y": [
          60.526315789473685,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          36.8421052631579,
          47.36842105263158,
          42.10526315789474,
          63.1578947368421,
          73.6842105263158,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          78.94736842105263,
          78.94736842105263,
          81.57894736842105,
          84.21052631578948,
          86.84210526315789,
          89.47368421052632,
          92.10526315789474,
          92.10526315789474,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158
         ]
        }
       ],
       "layout": {
        "height": 400,
        "margin": {
         "b": 20,
         "l": 20,
         "r": 20,
         "t": 20
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 400
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(test_acc)), y=test_acc, mode='lines', name='Full NN'))\n",
    "fig.update_layout(template='plotly_white', width=400, height=400,margin=dict(l=20, r=20, t=20, b=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data\\\\Results\\\\NN_training\\\\online_training\\\\IRIS\\\\BP_test_acc.csv', test_acc, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "{i+1}Epoch [1/100], Step [1/1], Loss: 1.0891473293304443, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [2/100], Step [1/1], Loss: 1.0698035955429077, Test Accuracy: 13.157894736842104%\n",
      "{i+1}Epoch [3/100], Step [1/1], Loss: 1.005279779434204, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [4/100], Step [1/1], Loss: 0.9963037371635437, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [5/100], Step [1/1], Loss: 1.052076816558838, Test Accuracy: 13.157894736842104%\n",
      "{i+1}Epoch [6/100], Step [1/1], Loss: 1.0516226291656494, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [7/100], Step [1/1], Loss: 1.0145341157913208, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [8/100], Step [1/1], Loss: 1.0477441549301147, Test Accuracy: 2.6315789473684212%\n",
      "{i+1}Epoch [9/100], Step [1/1], Loss: 1.0565224885940552, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [10/100], Step [1/1], Loss: 1.0318610668182373, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [11/100], Step [1/1], Loss: 1.0392760038375854, Test Accuracy: 42.10526315789474%\n",
      "{i+1}Epoch [12/100], Step [1/1], Loss: 1.032236099243164, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [13/100], Step [1/1], Loss: 0.9482232928276062, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [14/100], Step [1/1], Loss: 0.9108810424804688, Test Accuracy: 50.0%\n",
      "{i+1}Epoch [15/100], Step [1/1], Loss: 0.963079035282135, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [16/100], Step [1/1], Loss: 0.9948235750198364, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [17/100], Step [1/1], Loss: 0.9312707781791687, Test Accuracy: 36.8421052631579%\n",
      "{i+1}Epoch [18/100], Step [1/1], Loss: 1.0188615322113037, Test Accuracy: 5.2631578947368425%\n",
      "{i+1}Epoch [19/100], Step [1/1], Loss: 0.8534961342811584, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [20/100], Step [1/1], Loss: 0.9507898092269897, Test Accuracy: 73.6842105263158%\n",
      "{i+1}Epoch [21/100], Step [1/1], Loss: 0.8540935516357422, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [22/100], Step [1/1], Loss: 0.9737884998321533, Test Accuracy: 47.36842105263158%\n",
      "{i+1}Epoch [23/100], Step [1/1], Loss: 0.9832406044006348, Test Accuracy: 39.473684210526315%\n",
      "{i+1}Epoch [24/100], Step [1/1], Loss: 0.920437753200531, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [25/100], Step [1/1], Loss: 0.9589229226112366, Test Accuracy: 60.526315789473685%\n",
      "{i+1}Epoch [26/100], Step [1/1], Loss: 0.8499660491943359, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [27/100], Step [1/1], Loss: 0.9460188150405884, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [28/100], Step [1/1], Loss: 0.9036460518836975, Test Accuracy: 52.63157894736842%\n",
      "{i+1}Epoch [29/100], Step [1/1], Loss: 0.9571692943572998, Test Accuracy: 26.31578947368421%\n",
      "{i+1}Epoch [30/100], Step [1/1], Loss: 0.7563455700874329, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [31/100], Step [1/1], Loss: 0.8625422120094299, Test Accuracy: 63.1578947368421%\n",
      "{i+1}Epoch [32/100], Step [1/1], Loss: 0.8898852467536926, Test Accuracy: 50.0%\n",
      "{i+1}Epoch [33/100], Step [1/1], Loss: 0.7559869885444641, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [34/100], Step [1/1], Loss: 0.7529138326644897, Test Accuracy: 52.63157894736842%\n",
      "{i+1}Epoch [35/100], Step [1/1], Loss: 0.8440722227096558, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [36/100], Step [1/1], Loss: 0.7683733701705933, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [37/100], Step [1/1], Loss: 0.7425494194030762, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [38/100], Step [1/1], Loss: 0.7895326018333435, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [39/100], Step [1/1], Loss: 0.687590479850769, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [40/100], Step [1/1], Loss: 0.6774184703826904, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [41/100], Step [1/1], Loss: 0.68526691198349, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [42/100], Step [1/1], Loss: 0.79729825258255, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [43/100], Step [1/1], Loss: 0.7090811133384705, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [44/100], Step [1/1], Loss: 0.6815283298492432, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [45/100], Step [1/1], Loss: 0.732292652130127, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [46/100], Step [1/1], Loss: 0.7385138273239136, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [47/100], Step [1/1], Loss: 0.6869936585426331, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [48/100], Step [1/1], Loss: 0.6826302409172058, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [49/100], Step [1/1], Loss: 0.5928412079811096, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [50/100], Step [1/1], Loss: 0.6714655756950378, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [51/100], Step [1/1], Loss: 0.6990885734558105, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [52/100], Step [1/1], Loss: 0.6171497106552124, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [53/100], Step [1/1], Loss: 0.6988212466239929, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [54/100], Step [1/1], Loss: 0.6623737812042236, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [55/100], Step [1/1], Loss: 0.6346240043640137, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [56/100], Step [1/1], Loss: 0.5999269485473633, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [57/100], Step [1/1], Loss: 0.581143319606781, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [58/100], Step [1/1], Loss: 0.662645161151886, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [59/100], Step [1/1], Loss: 0.7286055088043213, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [60/100], Step [1/1], Loss: 0.6084666848182678, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [61/100], Step [1/1], Loss: 0.5950722694396973, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [62/100], Step [1/1], Loss: 0.6305130124092102, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [63/100], Step [1/1], Loss: 0.6137377619743347, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [64/100], Step [1/1], Loss: 0.5200562477111816, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [65/100], Step [1/1], Loss: 0.5460261702537537, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [66/100], Step [1/1], Loss: 0.6321482062339783, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [67/100], Step [1/1], Loss: 0.6244279742240906, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [68/100], Step [1/1], Loss: 0.5659631490707397, Test Accuracy: 63.1578947368421%\n",
      "{i+1}Epoch [69/100], Step [1/1], Loss: 0.5225446820259094, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [70/100], Step [1/1], Loss: 0.5766537189483643, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [71/100], Step [1/1], Loss: 0.5520253777503967, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [72/100], Step [1/1], Loss: 0.5660340785980225, Test Accuracy: 52.63157894736842%\n",
      "{i+1}Epoch [73/100], Step [1/1], Loss: 0.5338821411132812, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [74/100], Step [1/1], Loss: 0.5306349396705627, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [75/100], Step [1/1], Loss: 0.5407354235649109, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [76/100], Step [1/1], Loss: 0.5317131280899048, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [77/100], Step [1/1], Loss: 0.5079997777938843, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [78/100], Step [1/1], Loss: 0.4475606083869934, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [79/100], Step [1/1], Loss: 0.4940826892852783, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [80/100], Step [1/1], Loss: 0.547686755657196, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [81/100], Step [1/1], Loss: 0.49499502778053284, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [82/100], Step [1/1], Loss: 0.4587678015232086, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [83/100], Step [1/1], Loss: 0.5227004885673523, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [84/100], Step [1/1], Loss: 0.546970009803772, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [85/100], Step [1/1], Loss: 0.48755255341529846, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [86/100], Step [1/1], Loss: 0.4786258041858673, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [87/100], Step [1/1], Loss: 0.44769802689552307, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [88/100], Step [1/1], Loss: 0.46837908029556274, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [89/100], Step [1/1], Loss: 0.498260498046875, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [90/100], Step [1/1], Loss: 0.47252678871154785, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [91/100], Step [1/1], Loss: 0.4582515060901642, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [92/100], Step [1/1], Loss: 0.4655097723007202, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [93/100], Step [1/1], Loss: 0.4633833169937134, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [94/100], Step [1/1], Loss: 0.47476842999458313, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [95/100], Step [1/1], Loss: 0.46352335810661316, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [96/100], Step [1/1], Loss: 0.45010432600975037, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [97/100], Step [1/1], Loss: 0.4525875151157379, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [98/100], Step [1/1], Loss: 0.4512411057949066, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [99/100], Step [1/1], Loss: 0.45272260904312134, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [100/100], Step [1/1], Loss: 0.4312932789325714, Test Accuracy: 94.73684210526316%\n"
     ]
    }
   ],
   "source": [
    "# Training loop PEPG for MNIST: \n",
    "\n",
    "\n",
    "#NN_MNIST.reset_weights()\n",
    "#NN_MNIST.NN_stack[0].requires_grad = True\n",
    "n_epochs =100\n",
    "NN_IRIS = Neural_Net(input_size=4, hidden_size=10, n_classes=3)\n",
    "N_dim = NN_IRIS.count_parameters()\n",
    "pop_size = 100\n",
    "\n",
    "#specify we don't need the computation graph to keep track of the gradients, we will use pepg to update the weights\n",
    "with torch.no_grad():\n",
    "    for param in NN_IRIS.parameters():\n",
    "        param.requires_grad = False\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# learning parameters\n",
    "\n",
    "\n",
    "init_pos = NN_IRIS.get_params()\n",
    "\n",
    "if init_pos.requires_grad:\n",
    "    # Detach the tensor from the computation graph\n",
    "    init_pos = init_pos.detach()\n",
    "if init_pos.is_cuda:\n",
    "    # Move the tensor to the CPU\n",
    "    init_pos = init_pos.cpu()\n",
    "init_pos = init_pos.numpy()\n",
    "\n",
    "PEPG_optimizer = PEPG_opt(N_dim, pop_size, learning_rate=0.01, starting_mu=init_pos ,starting_sigma=0.1)\n",
    "\n",
    "PEPG_optimizer.sigma_decay = 0.9999\n",
    "PEPG_optimizer.sigma_alpha=0.2\n",
    "PEPG_optimizer.sigma_limit=0.02\n",
    "PEPG_optimizer.elite_ratio=0.1\n",
    "PEPG_optimizer.weight_decay=0.005\n",
    "\n",
    "test_acc_PEPG,best_reward_PEPG = train_online_pop_NN(NN_IRIS, n_epochs, Iris_train_loader, Iris_test_loader, loss, PEPG_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "PEPG",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          50,
          47.36842105263158,
          76.3157894736842,
          76.3157894736842,
          52.63157894736842,
          31.57894736842105,
          42.10526315789474,
          44.73684210526316,
          42.10526315789474,
          52.63157894736842,
          52.63157894736842,
          52.63157894736842,
          23.68421052631579,
          31.57894736842105,
          34.21052631578947,
          78.94736842105263,
          50,
          31.57894736842105,
          47.36842105263158,
          76.3157894736842,
          42.10526315789474,
          89.47368421052632,
          76.3157894736842,
          50,
          94.73684210526316,
          55.26315789473684,
          47.36842105263158,
          39.473684210526315,
          55.26315789473684,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          50,
          31.57894736842105,
          36.8421052631579,
          31.57894736842105,
          31.57894736842105,
          97.36842105263158,
          76.3157894736842,
          52.63157894736842,
          44.73684210526316,
          97.36842105263158,
          63.1578947368421,
          97.36842105263158,
          76.3157894736842,
          52.63157894736842,
          68.42105263157895,
          50,
          26.31578947368421,
          76.3157894736842,
          52.63157894736842,
          50,
          81.57894736842105,
          47.36842105263158,
          94.73684210526316,
          76.3157894736842,
          68.42105263157895,
          52.63157894736842,
          94.73684210526316,
          73.6842105263158,
          76.3157894736842,
          31.57894736842105,
          76.3157894736842,
          94.73684210526316,
          76.3157894736842,
          76.3157894736842,
          97.36842105263158,
          44.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          89.47368421052632,
          97.36842105263158,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          92.10526315789474,
          52.63157894736842,
          76.3157894736842,
          97.36842105263158,
          94.73684210526316,
          92.10526315789474,
          86.84210526315789,
          68.42105263157895,
          76.3157894736842,
          76.3157894736842,
          78.94736842105263,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          97.36842105263158,
          92.10526315789474,
          97.36842105263158,
          76.3157894736842,
          97.36842105263158,
          78.94736842105263,
          76.3157894736842,
          81.57894736842105
         ]
        }
       ],
       "layout": {
        "height": 300,
        "margin": {
         "b": 20,
         "l": 20,
         "r": 20,
         "t": 20
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 400,
        "xaxis": {
         "title": {
          "text": "Epochs"
         },
         "type": "log"
        },
        "yaxis": {
         "title": {
          "text": "Accuracy [%]"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(test_acc_PEPG)), y=test_acc_PEPG, mode='lines', name='PEPG'))\n",
    "#change theme to white and set the sizer of the plot\n",
    "fig.update_layout(template='plotly_white', width=400, height=300,margin=dict(l=20, r=20, t=20, b=20))\n",
    "fig.update_xaxes(title_text=\"Epochs\",type = 'log')\n",
    "fig.update_yaxes(title_text=\"Accuracy [%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save pepg data\n",
    "savetxt('data\\\\Results\\\\NN_training\\\\online_training\\\\IRIS\\\\PEPG_test_acc.csv', test_acc_PEPG, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use CMA to train the FFNN\n",
    "- This doesn't work at all this simple architecture has too many parameters ... so CMA is painfully slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "{i+1}Epoch [1/100], Step [1/1], Loss: 1.340676188468933, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [2/100], Step [1/1], Loss: 1.2666423320770264, Test Accuracy: 28.94736842105263%\n",
      "{i+1}Epoch [3/100], Step [1/1], Loss: 1.15496027469635, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [4/100], Step [1/1], Loss: 1.144727349281311, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [5/100], Step [1/1], Loss: 1.1428987979888916, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [6/100], Step [1/1], Loss: 1.0938888788223267, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [7/100], Step [1/1], Loss: 1.1018266677856445, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [8/100], Step [1/1], Loss: 1.0667814016342163, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [9/100], Step [1/1], Loss: 1.0016088485717773, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [10/100], Step [1/1], Loss: 0.9394079446792603, Test Accuracy: 73.6842105263158%\n",
      "{i+1}Epoch [11/100], Step [1/1], Loss: 0.8112428784370422, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [12/100], Step [1/1], Loss: 0.7990189790725708, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [13/100], Step [1/1], Loss: 0.7434087991714478, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [14/100], Step [1/1], Loss: 0.6867893934249878, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [15/100], Step [1/1], Loss: 0.5758448839187622, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [16/100], Step [1/1], Loss: 0.5979161262512207, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [17/100], Step [1/1], Loss: 0.50002521276474, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [18/100], Step [1/1], Loss: 0.43781962990760803, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [19/100], Step [1/1], Loss: 0.4502549469470978, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [20/100], Step [1/1], Loss: 0.38951659202575684, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [21/100], Step [1/1], Loss: 0.37921807169914246, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [22/100], Step [1/1], Loss: 0.34444716572761536, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [23/100], Step [1/1], Loss: 0.3346160054206848, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [24/100], Step [1/1], Loss: 0.34110623598098755, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [25/100], Step [1/1], Loss: 0.32691970467567444, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [26/100], Step [1/1], Loss: 0.2592655420303345, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [27/100], Step [1/1], Loss: 0.2271318882703781, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [28/100], Step [1/1], Loss: 0.2790728509426117, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [29/100], Step [1/1], Loss: 0.29720643162727356, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [30/100], Step [1/1], Loss: 0.2767446041107178, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [31/100], Step [1/1], Loss: 0.1625220626592636, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [32/100], Step [1/1], Loss: 0.30745139718055725, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [33/100], Step [1/1], Loss: 0.16622672975063324, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [34/100], Step [1/1], Loss: 0.14026129245758057, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [35/100], Step [1/1], Loss: 0.2474922388792038, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [36/100], Step [1/1], Loss: 0.1732017993927002, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [37/100], Step [1/1], Loss: 0.18202100694179535, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [38/100], Step [1/1], Loss: 0.1718885600566864, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [39/100], Step [1/1], Loss: 0.1099843829870224, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [40/100], Step [1/1], Loss: 0.12628550827503204, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [41/100], Step [1/1], Loss: 0.14149317145347595, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [42/100], Step [1/1], Loss: 0.09835975617170334, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [43/100], Step [1/1], Loss: 0.08081292361021042, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [44/100], Step [1/1], Loss: 0.07665426284074783, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [45/100], Step [1/1], Loss: 0.06762471050024033, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [46/100], Step [1/1], Loss: 0.06497609615325928, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [47/100], Step [1/1], Loss: 0.0811578631401062, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [48/100], Step [1/1], Loss: 0.05730490759015083, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [49/100], Step [1/1], Loss: 0.06616847962141037, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [50/100], Step [1/1], Loss: 0.11578502506017685, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [51/100], Step [1/1], Loss: 0.08876414597034454, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [52/100], Step [1/1], Loss: 0.0784628763794899, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [53/100], Step [1/1], Loss: 0.06198897585272789, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [54/100], Step [1/1], Loss: 0.05212770774960518, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [55/100], Step [1/1], Loss: 0.04084698483347893, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [56/100], Step [1/1], Loss: 0.03973869979381561, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [57/100], Step [1/1], Loss: 0.03565211966633797, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [58/100], Step [1/1], Loss: 0.058206841349601746, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [59/100], Step [1/1], Loss: 0.04875245690345764, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [60/100], Step [1/1], Loss: 0.03815526142716408, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [61/100], Step [1/1], Loss: 0.07900404930114746, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [62/100], Step [1/1], Loss: 0.047601521015167236, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [63/100], Step [1/1], Loss: 0.04902999475598335, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [64/100], Step [1/1], Loss: 0.046090248972177505, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [65/100], Step [1/1], Loss: 0.04846571385860443, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [66/100], Step [1/1], Loss: 0.041281796991825104, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [67/100], Step [1/1], Loss: 0.048120152205228806, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [68/100], Step [1/1], Loss: 0.03945319354534149, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [69/100], Step [1/1], Loss: 0.07877185940742493, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [70/100], Step [1/1], Loss: 0.053520962595939636, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [71/100], Step [1/1], Loss: 0.043298251926898956, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [72/100], Step [1/1], Loss: 0.06301457434892654, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [73/100], Step [1/1], Loss: 0.04193064570426941, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [74/100], Step [1/1], Loss: 0.06114025413990021, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [75/100], Step [1/1], Loss: 0.05952921137213707, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [76/100], Step [1/1], Loss: 0.06699889898300171, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [77/100], Step [1/1], Loss: 0.06464487314224243, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [78/100], Step [1/1], Loss: 0.04053307697176933, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [79/100], Step [1/1], Loss: 0.10185248404741287, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [80/100], Step [1/1], Loss: 0.04775821790099144, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [81/100], Step [1/1], Loss: 0.06487192958593369, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [82/100], Step [1/1], Loss: 0.08087262511253357, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [83/100], Step [1/1], Loss: 0.0584450326859951, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [84/100], Step [1/1], Loss: 0.07245370745658875, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [85/100], Step [1/1], Loss: 0.06232975795865059, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [86/100], Step [1/1], Loss: 0.07938563823699951, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [87/100], Step [1/1], Loss: 0.05849529430270195, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [88/100], Step [1/1], Loss: 0.0689588189125061, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [89/100], Step [1/1], Loss: 0.0655951276421547, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [90/100], Step [1/1], Loss: 0.08025389909744263, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [91/100], Step [1/1], Loss: 0.070685476064682, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [92/100], Step [1/1], Loss: 0.06132210046052933, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [93/100], Step [1/1], Loss: 0.08105721324682236, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [94/100], Step [1/1], Loss: 0.06815264374017715, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [95/100], Step [1/1], Loss: 0.08151376247406006, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [96/100], Step [1/1], Loss: 0.06133434548974037, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [97/100], Step [1/1], Loss: 0.06173105537891388, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [98/100], Step [1/1], Loss: 0.03857431188225746, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [99/100], Step [1/1], Loss: 0.10352139174938202, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [100/100], Step [1/1], Loss: 0.09676993638277054, Test Accuracy: 94.73684210526316%\n"
     ]
    }
   ],
   "source": [
    "#Using CMA-ES for training the NN\n",
    "n_epochs =100\n",
    "NN_IRIS = Neural_Net(input_size=4, hidden_size=10, n_classes=3)\n",
    "N_dim = NN_IRIS.count_parameters()\n",
    "pop_size = 50\n",
    "#specify we don't need the computation graph to keep track of the gradients, we will use CMAES to update the weights\n",
    "with torch.no_grad():\n",
    "    for param in NN_IRIS.parameters():\n",
    "        param.requires_grad = False\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# learning parameters\n",
    "\n",
    "init_pos = NN_IRIS.get_params()\n",
    "\n",
    "if init_pos.requires_grad:\n",
    "    # Detach the tensor from the computation graph\n",
    "    init_pos = init_pos.detach()\n",
    "if init_pos.is_cuda:\n",
    "    # Move the tensor to the CPU\n",
    "    init_pos = init_pos.cpu()\n",
    "init_pos = init_pos.numpy()\n",
    "\n",
    "CMA_optimizer = CMA_opt(N_dim, pop_size, select_pop=int(pop_size/2), sigma_init=0.1, mean_init=init_pos)\n",
    "CMA_optimizer.eigen_update_frequency = 10\n",
    "\n",
    "test_acc_CMA,best_reward_CMA = train_online_pop_NN(NN_IRIS, n_epochs, Iris_train_loader, Iris_test_loader, loss, CMA_optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "PEPG",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          23.68421052631579,
          28.94736842105263,
          23.68421052631579,
          23.68421052631579,
          31.57894736842105,
          23.68421052631579,
          23.68421052631579,
          31.57894736842105,
          31.57894736842105,
          73.6842105263158,
          68.42105263157895,
          97.36842105263158,
          76.3157894736842,
          94.73684210526316,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          86.84210526315789,
          92.10526315789474,
          97.36842105263158,
          76.3157894736842,
          78.94736842105263,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          94.73684210526316,
          89.47368421052632,
          97.36842105263158,
          86.84210526315789,
          97.36842105263158,
          97.36842105263158,
          89.47368421052632,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          97.36842105263158,
          100,
          94.73684210526316,
          100,
          100,
          97.36842105263158,
          100,
          97.36842105263158,
          100,
          100,
          97.36842105263158,
          94.73684210526316,
          100,
          100,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          100,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          100,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          100,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          100,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          92.10526315789474,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          92.10526315789474,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          94.73684210526316,
          92.10526315789474,
          100,
          92.10526315789474,
          94.73684210526316
         ]
        }
       ],
       "layout": {
        "height": 300,
        "margin": {
         "b": 20,
         "l": 20,
         "r": 20,
         "t": 20
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 400,
        "xaxis": {
         "title": {
          "text": "Epochs"
         },
         "type": "log"
        },
        "yaxis": {
         "title": {
          "text": "Accuracy [%]"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(test_acc_CMA)), y=test_acc_CMA, mode='lines', name='PEPG'))\n",
    "#change theme to white and set the sizer of the plot\n",
    "fig.update_layout(template='plotly_white', width=400, height=300,margin=dict(l=20, r=20, t=20, b=20))\n",
    "fig.update_xaxes(title_text=\"Epochs\",type = 'log')\n",
    "fig.update_yaxes(title_text=\"Accuracy [%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt('data\\\\Results\\\\NN_training\\\\online_training\\\\IRIS\\\\CMA_test_acc.csv', test_acc_CMA, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "{i+1}Epoch [1/500], Step [1/1], Loss: 1.1367748975753784, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [2/500], Step [1/1], Loss: 1.1318310499191284, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [3/500], Step [1/1], Loss: 1.1239755153656006, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [4/500], Step [1/1], Loss: 1.1196279525756836, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [5/500], Step [1/1], Loss: 1.1148799657821655, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [6/500], Step [1/1], Loss: 1.1067562103271484, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [7/500], Step [1/1], Loss: 1.0997792482376099, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [8/500], Step [1/1], Loss: 1.0949136018753052, Test Accuracy: 47.36842105263158%\n",
      "{i+1}Epoch [9/500], Step [1/1], Loss: 1.0912179946899414, Test Accuracy: 50.0%\n",
      "{i+1}Epoch [10/500], Step [1/1], Loss: 1.0887411832809448, Test Accuracy: 50.0%\n",
      "{i+1}Epoch [11/500], Step [1/1], Loss: 1.087164044380188, Test Accuracy: 50.0%\n",
      "{i+1}Epoch [12/500], Step [1/1], Loss: 1.0862743854522705, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [13/500], Step [1/1], Loss: 1.0856972932815552, Test Accuracy: 47.36842105263158%\n",
      "{i+1}Epoch [14/500], Step [1/1], Loss: 1.08517587184906, Test Accuracy: 36.8421052631579%\n",
      "{i+1}Epoch [15/500], Step [1/1], Loss: 1.0850830078125, Test Accuracy: 34.21052631578947%\n",
      "{i+1}Epoch [16/500], Step [1/1], Loss: 1.0855518579483032, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [17/500], Step [1/1], Loss: 1.0863956212997437, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [18/500], Step [1/1], Loss: 1.0878150463104248, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [19/500], Step [1/1], Loss: 1.0883255004882812, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [20/500], Step [1/1], Loss: 1.088554859161377, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [21/500], Step [1/1], Loss: 1.089061975479126, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [22/500], Step [1/1], Loss: 1.0897685289382935, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [23/500], Step [1/1], Loss: 1.0904264450073242, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [24/500], Step [1/1], Loss: 1.0901061296463013, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [25/500], Step [1/1], Loss: 1.0885283946990967, Test Accuracy: 34.21052631578947%\n",
      "{i+1}Epoch [26/500], Step [1/1], Loss: 1.0877891778945923, Test Accuracy: 34.21052631578947%\n",
      "{i+1}Epoch [27/500], Step [1/1], Loss: 1.0881239175796509, Test Accuracy: 42.10526315789474%\n",
      "{i+1}Epoch [28/500], Step [1/1], Loss: 1.088780403137207, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [29/500], Step [1/1], Loss: 1.089959740638733, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [30/500], Step [1/1], Loss: 1.0912035703659058, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [31/500], Step [1/1], Loss: 1.0926593542099, Test Accuracy: 50.0%\n",
      "{i+1}Epoch [32/500], Step [1/1], Loss: 1.093857765197754, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [33/500], Step [1/1], Loss: 1.0948230028152466, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [34/500], Step [1/1], Loss: 1.09555983543396, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [35/500], Step [1/1], Loss: 1.0967059135437012, Test Accuracy: 42.10526315789474%\n",
      "{i+1}Epoch [36/500], Step [1/1], Loss: 1.0978364944458008, Test Accuracy: 42.10526315789474%\n",
      "{i+1}Epoch [37/500], Step [1/1], Loss: 1.0986404418945312, Test Accuracy: 42.10526315789474%\n",
      "{i+1}Epoch [38/500], Step [1/1], Loss: 1.0993732213974, Test Accuracy: 42.10526315789474%\n",
      "{i+1}Epoch [39/500], Step [1/1], Loss: 1.098952293395996, Test Accuracy: 42.10526315789474%\n",
      "{i+1}Epoch [40/500], Step [1/1], Loss: 1.0987470149993896, Test Accuracy: 42.10526315789474%\n",
      "{i+1}Epoch [41/500], Step [1/1], Loss: 1.0974247455596924, Test Accuracy: 42.10526315789474%\n",
      "{i+1}Epoch [42/500], Step [1/1], Loss: 1.0949069261550903, Test Accuracy: 39.473684210526315%\n",
      "{i+1}Epoch [43/500], Step [1/1], Loss: 1.0923601388931274, Test Accuracy: 39.473684210526315%\n",
      "{i+1}Epoch [44/500], Step [1/1], Loss: 1.090117335319519, Test Accuracy: 39.473684210526315%\n",
      "{i+1}Epoch [45/500], Step [1/1], Loss: 1.0846378803253174, Test Accuracy: 42.10526315789474%\n",
      "{i+1}Epoch [46/500], Step [1/1], Loss: 1.078680396080017, Test Accuracy: 50.0%\n",
      "{i+1}Epoch [47/500], Step [1/1], Loss: 1.0724992752075195, Test Accuracy: 50.0%\n",
      "{i+1}Epoch [48/500], Step [1/1], Loss: 1.0662078857421875, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [49/500], Step [1/1], Loss: 1.0548683404922485, Test Accuracy: 34.21052631578947%\n",
      "{i+1}Epoch [50/500], Step [1/1], Loss: 1.0449858903884888, Test Accuracy: 34.21052631578947%\n",
      "{i+1}Epoch [51/500], Step [1/1], Loss: 1.035888433456421, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [52/500], Step [1/1], Loss: 1.0274658203125, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [53/500], Step [1/1], Loss: 1.0187866687774658, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [54/500], Step [1/1], Loss: 1.0107187032699585, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [55/500], Step [1/1], Loss: 1.0018948316574097, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [56/500], Step [1/1], Loss: 0.9936545491218567, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [57/500], Step [1/1], Loss: 0.9863353371620178, Test Accuracy: 34.21052631578947%\n",
      "{i+1}Epoch [58/500], Step [1/1], Loss: 0.9799377918243408, Test Accuracy: 34.21052631578947%\n",
      "{i+1}Epoch [59/500], Step [1/1], Loss: 0.9739235043525696, Test Accuracy: 34.21052631578947%\n",
      "{i+1}Epoch [60/500], Step [1/1], Loss: 0.9671699404716492, Test Accuracy: 39.473684210526315%\n",
      "{i+1}Epoch [61/500], Step [1/1], Loss: 0.9611961841583252, Test Accuracy: 42.10526315789474%\n",
      "{i+1}Epoch [62/500], Step [1/1], Loss: 0.9553725719451904, Test Accuracy: 47.36842105263158%\n",
      "{i+1}Epoch [63/500], Step [1/1], Loss: 0.9501078724861145, Test Accuracy: 55.26315789473684%\n",
      "{i+1}Epoch [64/500], Step [1/1], Loss: 0.9454351663589478, Test Accuracy: 55.26315789473684%\n",
      "{i+1}Epoch [65/500], Step [1/1], Loss: 0.9397719502449036, Test Accuracy: 60.526315789473685%\n",
      "{i+1}Epoch [66/500], Step [1/1], Loss: 0.9345279335975647, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [67/500], Step [1/1], Loss: 0.9298467040061951, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [68/500], Step [1/1], Loss: 0.9235148429870605, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [69/500], Step [1/1], Loss: 0.9178512692451477, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [70/500], Step [1/1], Loss: 0.913719654083252, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [71/500], Step [1/1], Loss: 0.9095274209976196, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [72/500], Step [1/1], Loss: 0.901045024394989, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [73/500], Step [1/1], Loss: 0.8936632871627808, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [74/500], Step [1/1], Loss: 0.8871424794197083, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [75/500], Step [1/1], Loss: 0.8813026547431946, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [76/500], Step [1/1], Loss: 0.8746509552001953, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [77/500], Step [1/1], Loss: 0.8682665824890137, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [78/500], Step [1/1], Loss: 0.8584427237510681, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [79/500], Step [1/1], Loss: 0.8488311767578125, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [80/500], Step [1/1], Loss: 0.8402165770530701, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [81/500], Step [1/1], Loss: 0.8324708938598633, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [82/500], Step [1/1], Loss: 0.8268637657165527, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [83/500], Step [1/1], Loss: 0.8211460113525391, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [84/500], Step [1/1], Loss: 0.816819965839386, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [85/500], Step [1/1], Loss: 0.8128859996795654, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [86/500], Step [1/1], Loss: 0.8095784783363342, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [87/500], Step [1/1], Loss: 0.8064275979995728, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [88/500], Step [1/1], Loss: 0.8028967976570129, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [89/500], Step [1/1], Loss: 0.7991189360618591, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [90/500], Step [1/1], Loss: 0.795506477355957, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [91/500], Step [1/1], Loss: 0.7914332151412964, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [92/500], Step [1/1], Loss: 0.7877833843231201, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [93/500], Step [1/1], Loss: 0.7837700247764587, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [94/500], Step [1/1], Loss: 0.7801691889762878, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [95/500], Step [1/1], Loss: 0.7771918773651123, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [96/500], Step [1/1], Loss: 0.7745686769485474, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [97/500], Step [1/1], Loss: 0.7723153829574585, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [98/500], Step [1/1], Loss: 0.771648645401001, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [99/500], Step [1/1], Loss: 0.7721303701400757, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [100/500], Step [1/1], Loss: 0.7729050517082214, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [101/500], Step [1/1], Loss: 0.773739755153656, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [102/500], Step [1/1], Loss: 0.7747311592102051, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [103/500], Step [1/1], Loss: 0.7754666805267334, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [104/500], Step [1/1], Loss: 0.7765721678733826, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [105/500], Step [1/1], Loss: 0.777286171913147, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [106/500], Step [1/1], Loss: 0.7750810384750366, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [107/500], Step [1/1], Loss: 0.7732332348823547, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [108/500], Step [1/1], Loss: 0.7724356651306152, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [109/500], Step [1/1], Loss: 0.7719069719314575, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [110/500], Step [1/1], Loss: 0.7694184184074402, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [111/500], Step [1/1], Loss: 0.7673227190971375, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [112/500], Step [1/1], Loss: 0.7653871178627014, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [113/500], Step [1/1], Loss: 0.7638188004493713, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [114/500], Step [1/1], Loss: 0.762580394744873, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [115/500], Step [1/1], Loss: 0.7607405781745911, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [116/500], Step [1/1], Loss: 0.7582043409347534, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [117/500], Step [1/1], Loss: 0.7535347938537598, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [118/500], Step [1/1], Loss: 0.7488145232200623, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [119/500], Step [1/1], Loss: 0.7446849942207336, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [120/500], Step [1/1], Loss: 0.7380475401878357, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [121/500], Step [1/1], Loss: 0.73199063539505, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [122/500], Step [1/1], Loss: 0.7263798713684082, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [123/500], Step [1/1], Loss: 0.7211050987243652, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [124/500], Step [1/1], Loss: 0.7142847180366516, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [125/500], Step [1/1], Loss: 0.7076958417892456, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [126/500], Step [1/1], Loss: 0.7014628052711487, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [127/500], Step [1/1], Loss: 0.6959093809127808, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [128/500], Step [1/1], Loss: 0.6911613941192627, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [129/500], Step [1/1], Loss: 0.686583936214447, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [130/500], Step [1/1], Loss: 0.6824050545692444, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [131/500], Step [1/1], Loss: 0.6792947053909302, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [132/500], Step [1/1], Loss: 0.6755744814872742, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [133/500], Step [1/1], Loss: 0.6708735823631287, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [134/500], Step [1/1], Loss: 0.6662731170654297, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [135/500], Step [1/1], Loss: 0.6621469259262085, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [136/500], Step [1/1], Loss: 0.6584561467170715, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [137/500], Step [1/1], Loss: 0.6552937626838684, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [138/500], Step [1/1], Loss: 0.6521678566932678, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [139/500], Step [1/1], Loss: 0.6491895318031311, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [140/500], Step [1/1], Loss: 0.6445801854133606, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [141/500], Step [1/1], Loss: 0.6403883099555969, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [142/500], Step [1/1], Loss: 0.6370285153388977, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [143/500], Step [1/1], Loss: 0.6343986392021179, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [144/500], Step [1/1], Loss: 0.632092297077179, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [145/500], Step [1/1], Loss: 0.6280533671379089, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [146/500], Step [1/1], Loss: 0.6226213574409485, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [147/500], Step [1/1], Loss: 0.6177407503128052, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [148/500], Step [1/1], Loss: 0.6132071018218994, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [149/500], Step [1/1], Loss: 0.6077225208282471, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [150/500], Step [1/1], Loss: 0.6023815274238586, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [151/500], Step [1/1], Loss: 0.596558690071106, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [152/500], Step [1/1], Loss: 0.5904150009155273, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [153/500], Step [1/1], Loss: 0.5849365592002869, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [154/500], Step [1/1], Loss: 0.5802481174468994, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [155/500], Step [1/1], Loss: 0.5756416916847229, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [156/500], Step [1/1], Loss: 0.5726683139801025, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [157/500], Step [1/1], Loss: 0.5701568126678467, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [158/500], Step [1/1], Loss: 0.5681226253509521, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [159/500], Step [1/1], Loss: 0.566364586353302, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [160/500], Step [1/1], Loss: 0.5652167201042175, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [161/500], Step [1/1], Loss: 0.5642458200454712, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [162/500], Step [1/1], Loss: 0.561662495136261, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [163/500], Step [1/1], Loss: 0.5562225580215454, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [164/500], Step [1/1], Loss: 0.5518395304679871, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [165/500], Step [1/1], Loss: 0.54888516664505, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [166/500], Step [1/1], Loss: 0.5487310886383057, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [167/500], Step [1/1], Loss: 0.5499078035354614, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [168/500], Step [1/1], Loss: 0.5513536334037781, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [169/500], Step [1/1], Loss: 0.5531774163246155, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [170/500], Step [1/1], Loss: 0.5524243712425232, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [171/500], Step [1/1], Loss: 0.548331081867218, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [172/500], Step [1/1], Loss: 0.5414729118347168, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [173/500], Step [1/1], Loss: 0.5321691632270813, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [174/500], Step [1/1], Loss: 0.5243706703186035, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [175/500], Step [1/1], Loss: 0.5176504254341125, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [176/500], Step [1/1], Loss: 0.5112483501434326, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [177/500], Step [1/1], Loss: 0.505663275718689, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [178/500], Step [1/1], Loss: 0.5009022355079651, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [179/500], Step [1/1], Loss: 0.4969502091407776, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [180/500], Step [1/1], Loss: 0.49339595437049866, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [181/500], Step [1/1], Loss: 0.490395188331604, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [182/500], Step [1/1], Loss: 0.48767852783203125, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [183/500], Step [1/1], Loss: 0.48513302206993103, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [184/500], Step [1/1], Loss: 0.4830690324306488, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [185/500], Step [1/1], Loss: 0.48145315051078796, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [186/500], Step [1/1], Loss: 0.48002463579177856, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [187/500], Step [1/1], Loss: 0.47875815629959106, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [188/500], Step [1/1], Loss: 0.47756335139274597, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [189/500], Step [1/1], Loss: 0.4768020808696747, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [190/500], Step [1/1], Loss: 0.47612425684928894, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [191/500], Step [1/1], Loss: 0.47436559200286865, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [192/500], Step [1/1], Loss: 0.47332507371902466, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [193/500], Step [1/1], Loss: 0.4699561893939972, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [194/500], Step [1/1], Loss: 0.4668550491333008, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [195/500], Step [1/1], Loss: 0.4640996754169464, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [196/500], Step [1/1], Loss: 0.4623391926288605, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [197/500], Step [1/1], Loss: 0.4600495398044586, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [198/500], Step [1/1], Loss: 0.4583495259284973, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [199/500], Step [1/1], Loss: 0.4573312997817993, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [200/500], Step [1/1], Loss: 0.45621562004089355, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [201/500], Step [1/1], Loss: 0.4549520015716553, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [202/500], Step [1/1], Loss: 0.45336636900901794, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [203/500], Step [1/1], Loss: 0.44932806491851807, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [204/500], Step [1/1], Loss: 0.4458456039428711, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [205/500], Step [1/1], Loss: 0.44286030530929565, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [206/500], Step [1/1], Loss: 0.43999621272087097, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [207/500], Step [1/1], Loss: 0.4372747838497162, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [208/500], Step [1/1], Loss: 0.43433496356010437, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [209/500], Step [1/1], Loss: 0.43185850977897644, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [210/500], Step [1/1], Loss: 0.429595947265625, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [211/500], Step [1/1], Loss: 0.42753008008003235, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [212/500], Step [1/1], Loss: 0.42576107382774353, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [213/500], Step [1/1], Loss: 0.42368948459625244, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [214/500], Step [1/1], Loss: 0.42202386260032654, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [215/500], Step [1/1], Loss: 0.4207441806793213, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [216/500], Step [1/1], Loss: 0.4204287528991699, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [217/500], Step [1/1], Loss: 0.42006516456604004, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [218/500], Step [1/1], Loss: 0.4190662205219269, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [219/500], Step [1/1], Loss: 0.41804078221321106, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [220/500], Step [1/1], Loss: 0.4164089262485504, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [221/500], Step [1/1], Loss: 0.41533827781677246, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [222/500], Step [1/1], Loss: 0.41441819071769714, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [223/500], Step [1/1], Loss: 0.41307497024536133, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [224/500], Step [1/1], Loss: 0.4106970429420471, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [225/500], Step [1/1], Loss: 0.40863344073295593, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [226/500], Step [1/1], Loss: 0.40627095103263855, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [227/500], Step [1/1], Loss: 0.40395665168762207, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [228/500], Step [1/1], Loss: 0.40167611837387085, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [229/500], Step [1/1], Loss: 0.39963778853416443, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [230/500], Step [1/1], Loss: 0.3973724842071533, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [231/500], Step [1/1], Loss: 0.3952605128288269, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [232/500], Step [1/1], Loss: 0.39331191778182983, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [233/500], Step [1/1], Loss: 0.3915555477142334, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [234/500], Step [1/1], Loss: 0.38999295234680176, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [235/500], Step [1/1], Loss: 0.38846293091773987, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [236/500], Step [1/1], Loss: 0.3871351480484009, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [237/500], Step [1/1], Loss: 0.38605058193206787, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [238/500], Step [1/1], Loss: 0.3849957585334778, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [239/500], Step [1/1], Loss: 0.38396474719047546, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [240/500], Step [1/1], Loss: 0.38301798701286316, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [241/500], Step [1/1], Loss: 0.38213133811950684, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [242/500], Step [1/1], Loss: 0.38090962171554565, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [243/500], Step [1/1], Loss: 0.37987250089645386, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [244/500], Step [1/1], Loss: 0.3792509138584137, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [245/500], Step [1/1], Loss: 0.3777869939804077, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [246/500], Step [1/1], Loss: 0.37628141045570374, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [247/500], Step [1/1], Loss: 0.37521249055862427, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [248/500], Step [1/1], Loss: 0.37394002079963684, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [249/500], Step [1/1], Loss: 0.3733989894390106, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [250/500], Step [1/1], Loss: 0.37215787172317505, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [251/500], Step [1/1], Loss: 0.37080931663513184, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [252/500], Step [1/1], Loss: 0.36953189969062805, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [253/500], Step [1/1], Loss: 0.36801695823669434, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [254/500], Step [1/1], Loss: 0.36681151390075684, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [255/500], Step [1/1], Loss: 0.36572322249412537, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [256/500], Step [1/1], Loss: 0.3643982708454132, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [257/500], Step [1/1], Loss: 0.36289650201797485, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [258/500], Step [1/1], Loss: 0.3634135127067566, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [259/500], Step [1/1], Loss: 0.3641161024570465, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [260/500], Step [1/1], Loss: 0.3648505210876465, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [261/500], Step [1/1], Loss: 0.3654753565788269, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [262/500], Step [1/1], Loss: 0.36507248878479004, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [263/500], Step [1/1], Loss: 0.36463409662246704, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [264/500], Step [1/1], Loss: 0.3623054027557373, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [265/500], Step [1/1], Loss: 0.36035117506980896, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [266/500], Step [1/1], Loss: 0.358877956867218, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [267/500], Step [1/1], Loss: 0.3578396737575531, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [268/500], Step [1/1], Loss: 0.35645046830177307, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [269/500], Step [1/1], Loss: 0.3549579679965973, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [270/500], Step [1/1], Loss: 0.3530735969543457, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [271/500], Step [1/1], Loss: 0.3511241674423218, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [272/500], Step [1/1], Loss: 0.3493375778198242, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [273/500], Step [1/1], Loss: 0.34675177931785583, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [274/500], Step [1/1], Loss: 0.3441479802131653, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [275/500], Step [1/1], Loss: 0.34213632345199585, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [276/500], Step [1/1], Loss: 0.34002169966697693, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [277/500], Step [1/1], Loss: 0.33810409903526306, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [278/500], Step [1/1], Loss: 0.3364931046962738, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [279/500], Step [1/1], Loss: 0.33472761511802673, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [280/500], Step [1/1], Loss: 0.33251526951789856, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [281/500], Step [1/1], Loss: 0.3298164904117584, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [282/500], Step [1/1], Loss: 0.32649004459381104, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [283/500], Step [1/1], Loss: 0.32330334186553955, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [284/500], Step [1/1], Loss: 0.320650190114975, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [285/500], Step [1/1], Loss: 0.3178212642669678, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [286/500], Step [1/1], Loss: 0.3158136010169983, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [287/500], Step [1/1], Loss: 0.3142281174659729, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [288/500], Step [1/1], Loss: 0.31236952543258667, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [289/500], Step [1/1], Loss: 0.3108749985694885, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [290/500], Step [1/1], Loss: 0.3091970384120941, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [291/500], Step [1/1], Loss: 0.30793893337249756, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [292/500], Step [1/1], Loss: 0.30698567628860474, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [293/500], Step [1/1], Loss: 0.3060259222984314, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [294/500], Step [1/1], Loss: 0.3050009608268738, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [295/500], Step [1/1], Loss: 0.3040675222873688, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [296/500], Step [1/1], Loss: 0.3032894730567932, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [297/500], Step [1/1], Loss: 0.30231648683547974, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [298/500], Step [1/1], Loss: 0.3015216886997223, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [299/500], Step [1/1], Loss: 0.30067354440689087, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [300/500], Step [1/1], Loss: 0.29914790391921997, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [301/500], Step [1/1], Loss: 0.29756441712379456, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [302/500], Step [1/1], Loss: 0.2962450385093689, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [303/500], Step [1/1], Loss: 0.2943628132343292, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [304/500], Step [1/1], Loss: 0.29205411672592163, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [305/500], Step [1/1], Loss: 0.28971943259239197, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [306/500], Step [1/1], Loss: 0.28736189007759094, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [307/500], Step [1/1], Loss: 0.2848849892616272, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [308/500], Step [1/1], Loss: 0.282952219247818, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [309/500], Step [1/1], Loss: 0.28170421719551086, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [310/500], Step [1/1], Loss: 0.2815573215484619, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [311/500], Step [1/1], Loss: 0.2815585434436798, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [312/500], Step [1/1], Loss: 0.2813582122325897, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [313/500], Step [1/1], Loss: 0.2816658914089203, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [314/500], Step [1/1], Loss: 0.28185582160949707, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [315/500], Step [1/1], Loss: 0.2826635241508484, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [316/500], Step [1/1], Loss: 0.28270119428634644, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [317/500], Step [1/1], Loss: 0.282563179731369, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [318/500], Step [1/1], Loss: 0.28225794434547424, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [319/500], Step [1/1], Loss: 0.2821795642375946, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [320/500], Step [1/1], Loss: 0.2821807861328125, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [321/500], Step [1/1], Loss: 0.28193336725234985, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [322/500], Step [1/1], Loss: 0.2816113531589508, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [323/500], Step [1/1], Loss: 0.2812572419643402, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [324/500], Step [1/1], Loss: 0.281443327665329, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [325/500], Step [1/1], Loss: 0.28163132071495056, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [326/500], Step [1/1], Loss: 0.28208231925964355, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [327/500], Step [1/1], Loss: 0.28192657232284546, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [328/500], Step [1/1], Loss: 0.2814077138900757, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [329/500], Step [1/1], Loss: 0.2805321514606476, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [330/500], Step [1/1], Loss: 0.2779867649078369, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [331/500], Step [1/1], Loss: 0.2758823335170746, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [332/500], Step [1/1], Loss: 0.2739895284175873, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [333/500], Step [1/1], Loss: 0.2720428705215454, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [334/500], Step [1/1], Loss: 0.2705003321170807, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [335/500], Step [1/1], Loss: 0.26876649260520935, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [336/500], Step [1/1], Loss: 0.26729270815849304, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [337/500], Step [1/1], Loss: 0.2651148736476898, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [338/500], Step [1/1], Loss: 0.2629874646663666, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [339/500], Step [1/1], Loss: 0.26131054759025574, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [340/500], Step [1/1], Loss: 0.25996288657188416, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [341/500], Step [1/1], Loss: 0.2587924897670746, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [342/500], Step [1/1], Loss: 0.2577170729637146, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [343/500], Step [1/1], Loss: 0.25660625100135803, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [344/500], Step [1/1], Loss: 0.25623175501823425, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [345/500], Step [1/1], Loss: 0.25620657205581665, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [346/500], Step [1/1], Loss: 0.2570333778858185, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [347/500], Step [1/1], Loss: 0.25809594988822937, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [348/500], Step [1/1], Loss: 0.25921639800071716, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [349/500], Step [1/1], Loss: 0.2601005434989929, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [350/500], Step [1/1], Loss: 0.2608807682991028, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [351/500], Step [1/1], Loss: 0.26147007942199707, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [352/500], Step [1/1], Loss: 0.2614641487598419, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [353/500], Step [1/1], Loss: 0.26144590973854065, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [354/500], Step [1/1], Loss: 0.2614826560020447, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [355/500], Step [1/1], Loss: 0.2601240575313568, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [356/500], Step [1/1], Loss: 0.25892868638038635, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [357/500], Step [1/1], Loss: 0.256377637386322, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [358/500], Step [1/1], Loss: 0.25330016016960144, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [359/500], Step [1/1], Loss: 0.25001591444015503, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [360/500], Step [1/1], Loss: 0.24751825630664825, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [361/500], Step [1/1], Loss: 0.245554119348526, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [362/500], Step [1/1], Loss: 0.24408194422721863, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [363/500], Step [1/1], Loss: 0.24330897629261017, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [364/500], Step [1/1], Loss: 0.244288370013237, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [365/500], Step [1/1], Loss: 0.2456851750612259, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [366/500], Step [1/1], Loss: 0.2467801421880722, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [367/500], Step [1/1], Loss: 0.24901126325130463, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [368/500], Step [1/1], Loss: 0.25092241168022156, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [369/500], Step [1/1], Loss: 0.25270214676856995, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [370/500], Step [1/1], Loss: 0.2521457076072693, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [371/500], Step [1/1], Loss: 0.25049951672554016, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [372/500], Step [1/1], Loss: 0.24902530014514923, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [373/500], Step [1/1], Loss: 0.24757711589336395, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [374/500], Step [1/1], Loss: 0.2463413029909134, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [375/500], Step [1/1], Loss: 0.24521750211715698, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [376/500], Step [1/1], Loss: 0.2442552149295807, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [377/500], Step [1/1], Loss: 0.2431955337524414, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [378/500], Step [1/1], Loss: 0.2420293688774109, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [379/500], Step [1/1], Loss: 0.24087662994861603, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [380/500], Step [1/1], Loss: 0.2391117513179779, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [381/500], Step [1/1], Loss: 0.23756882548332214, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [382/500], Step [1/1], Loss: 0.2363801747560501, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [383/500], Step [1/1], Loss: 0.23532415926456451, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [384/500], Step [1/1], Loss: 0.23431003093719482, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [385/500], Step [1/1], Loss: 0.23333513736724854, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [386/500], Step [1/1], Loss: 0.23269568383693695, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [387/500], Step [1/1], Loss: 0.2321445792913437, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [388/500], Step [1/1], Loss: 0.23157280683517456, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [389/500], Step [1/1], Loss: 0.23102672398090363, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [390/500], Step [1/1], Loss: 0.23052546381950378, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [391/500], Step [1/1], Loss: 0.22980225086212158, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [392/500], Step [1/1], Loss: 0.22929184138774872, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [393/500], Step [1/1], Loss: 0.2288311868906021, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [394/500], Step [1/1], Loss: 0.2284172922372818, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [395/500], Step [1/1], Loss: 0.22739073634147644, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [396/500], Step [1/1], Loss: 0.22638383507728577, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [397/500], Step [1/1], Loss: 0.22555871307849884, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [398/500], Step [1/1], Loss: 0.2258160263299942, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [399/500], Step [1/1], Loss: 0.22605730593204498, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [400/500], Step [1/1], Loss: 0.226205974817276, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [401/500], Step [1/1], Loss: 0.22591935098171234, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [402/500], Step [1/1], Loss: 0.22509688138961792, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [403/500], Step [1/1], Loss: 0.22395926713943481, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [404/500], Step [1/1], Loss: 0.2230728268623352, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [405/500], Step [1/1], Loss: 0.22181250154972076, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [406/500], Step [1/1], Loss: 0.2200288474559784, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [407/500], Step [1/1], Loss: 0.218644917011261, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [408/500], Step [1/1], Loss: 0.2172793596982956, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [409/500], Step [1/1], Loss: 0.21596211194992065, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [410/500], Step [1/1], Loss: 0.21519778668880463, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [411/500], Step [1/1], Loss: 0.21453431248664856, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [412/500], Step [1/1], Loss: 0.21433453261852264, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [413/500], Step [1/1], Loss: 0.21517632901668549, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [414/500], Step [1/1], Loss: 0.21646447479724884, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [415/500], Step [1/1], Loss: 0.21807825565338135, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [416/500], Step [1/1], Loss: 0.2198014259338379, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [417/500], Step [1/1], Loss: 0.21861116588115692, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [418/500], Step [1/1], Loss: 0.21673071384429932, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [419/500], Step [1/1], Loss: 0.2151987999677658, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [420/500], Step [1/1], Loss: 0.21447081863880157, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [421/500], Step [1/1], Loss: 0.21383795142173767, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [422/500], Step [1/1], Loss: 0.21312600374221802, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [423/500], Step [1/1], Loss: 0.21246238052845, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [424/500], Step [1/1], Loss: 0.21187815070152283, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [425/500], Step [1/1], Loss: 0.2109455019235611, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [426/500], Step [1/1], Loss: 0.21009092032909393, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [427/500], Step [1/1], Loss: 0.20947597920894623, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [428/500], Step [1/1], Loss: 0.20878368616104126, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [429/500], Step [1/1], Loss: 0.20892278850078583, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [430/500], Step [1/1], Loss: 0.20965872704982758, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [431/500], Step [1/1], Loss: 0.21050699055194855, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [432/500], Step [1/1], Loss: 0.21144741773605347, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [433/500], Step [1/1], Loss: 0.21186205744743347, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [434/500], Step [1/1], Loss: 0.21222254633903503, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [435/500], Step [1/1], Loss: 0.21228541433811188, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [436/500], Step [1/1], Loss: 0.21228697896003723, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [437/500], Step [1/1], Loss: 0.21194465458393097, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [438/500], Step [1/1], Loss: 0.20981808006763458, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [439/500], Step [1/1], Loss: 0.20752476155757904, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [440/500], Step [1/1], Loss: 0.20460766553878784, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [441/500], Step [1/1], Loss: 0.20212653279304504, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [442/500], Step [1/1], Loss: 0.1998838186264038, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [443/500], Step [1/1], Loss: 0.1986033320426941, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [444/500], Step [1/1], Loss: 0.19750851392745972, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [445/500], Step [1/1], Loss: 0.1968064159154892, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [446/500], Step [1/1], Loss: 0.19625969231128693, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [447/500], Step [1/1], Loss: 0.19598786532878876, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [448/500], Step [1/1], Loss: 0.19566072523593903, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [449/500], Step [1/1], Loss: 0.19554756581783295, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [450/500], Step [1/1], Loss: 0.19565927982330322, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [451/500], Step [1/1], Loss: 0.1958807408809662, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [452/500], Step [1/1], Loss: 0.19495324790477753, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [453/500], Step [1/1], Loss: 0.19446246325969696, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [454/500], Step [1/1], Loss: 0.1939941644668579, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [455/500], Step [1/1], Loss: 0.1931532621383667, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [456/500], Step [1/1], Loss: 0.1924482136964798, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [457/500], Step [1/1], Loss: 0.19157421588897705, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [458/500], Step [1/1], Loss: 0.19087867438793182, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [459/500], Step [1/1], Loss: 0.1897439956665039, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [460/500], Step [1/1], Loss: 0.18885338306427002, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [461/500], Step [1/1], Loss: 0.18766537308692932, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [462/500], Step [1/1], Loss: 0.1864619106054306, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [463/500], Step [1/1], Loss: 0.18519966304302216, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [464/500], Step [1/1], Loss: 0.1840485781431198, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [465/500], Step [1/1], Loss: 0.18259350955486298, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [466/500], Step [1/1], Loss: 0.18135014176368713, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [467/500], Step [1/1], Loss: 0.18064670264720917, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [468/500], Step [1/1], Loss: 0.18028400838375092, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [469/500], Step [1/1], Loss: 0.1800292730331421, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [470/500], Step [1/1], Loss: 0.17999900877475739, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [471/500], Step [1/1], Loss: 0.18207786977291107, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [472/500], Step [1/1], Loss: 0.1847904920578003, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [473/500], Step [1/1], Loss: 0.18729066848754883, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [474/500], Step [1/1], Loss: 0.18945829570293427, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [475/500], Step [1/1], Loss: 0.1879347562789917, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [476/500], Step [1/1], Loss: 0.1859738975763321, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [477/500], Step [1/1], Loss: 0.18425223231315613, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [478/500], Step [1/1], Loss: 0.18269257247447968, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [479/500], Step [1/1], Loss: 0.18115995824337006, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [480/500], Step [1/1], Loss: 0.1798248291015625, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [481/500], Step [1/1], Loss: 0.17854666709899902, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [482/500], Step [1/1], Loss: 0.17743271589279175, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [483/500], Step [1/1], Loss: 0.17638155817985535, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [484/500], Step [1/1], Loss: 0.1753367930650711, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [485/500], Step [1/1], Loss: 0.1743842512369156, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [486/500], Step [1/1], Loss: 0.17290987074375153, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [487/500], Step [1/1], Loss: 0.17188823223114014, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [488/500], Step [1/1], Loss: 0.17279233038425446, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [489/500], Step [1/1], Loss: 0.17439919710159302, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [490/500], Step [1/1], Loss: 0.17681783437728882, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [491/500], Step [1/1], Loss: 0.1797693818807602, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [492/500], Step [1/1], Loss: 0.1788821965456009, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [493/500], Step [1/1], Loss: 0.1711520105600357, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [494/500], Step [1/1], Loss: 0.16595253348350525, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [495/500], Step [1/1], Loss: 0.16254490613937378, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [496/500], Step [1/1], Loss: 0.161142036318779, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [497/500], Step [1/1], Loss: 0.1593688726425171, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [498/500], Step [1/1], Loss: 0.15779396891593933, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [499/500], Step [1/1], Loss: 0.15644440054893494, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [500/500], Step [1/1], Loss: 0.1554121971130371, Test Accuracy: 97.36842105263158%\n"
     ]
    }
   ],
   "source": [
    "#use SPSA to optimize The Neural network\n",
    "n_epochs =500\n",
    "NN_IRIS = Neural_Net(input_size=4, hidden_size=10, n_classes=3)\n",
    "N_dim = NN_IRIS.count_parameters()\n",
    "#specify we don't need the computation graph to keep track of the gradients, we will use SPSA to update the weights\n",
    "with torch.no_grad():\n",
    "    for param in NN_IRIS.parameters():\n",
    "        param.requires_grad = False\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# learning parameters\n",
    "\n",
    "init_pos = NN_IRIS.get_params()\n",
    "\n",
    "if init_pos.requires_grad:\n",
    "    # Detach the tensor from the computation graph\n",
    "    init_pos = init_pos.detach()\n",
    "if init_pos.is_cuda:\n",
    "    # Move the tensor to the CPU\n",
    "    init_pos = init_pos.cpu()\n",
    "init_pos = init_pos.numpy()\n",
    "\n",
    "SPSA_optimizer = SPSA_opt(init_pos,alpha=1e-3,epsilon=1e-5)\n",
    "Adam = AdamOptimizer(init_pos, lr=1e-2, beta1=0.9, beta2=0.99, epsilon=1e-8)\n",
    "\n",
    "test_acc_SPSA, best_reward_SPSA = train_online_SPSA_NN(NN_IRIS, n_epochs, Iris_train_loader, Iris_test_loader, loss, SPSA_optimizer,Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "PEPG",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          44.73684210526316,
          44.73684210526316,
          44.73684210526316,
          44.73684210526316,
          44.73684210526316,
          44.73684210526316,
          44.73684210526316,
          47.36842105263158,
          50,
          50,
          50,
          44.73684210526316,
          47.36842105263158,
          36.8421052631579,
          34.21052631578947,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          34.21052631578947,
          34.21052631578947,
          42.10526315789474,
          44.73684210526316,
          44.73684210526316,
          44.73684210526316,
          50,
          44.73684210526316,
          44.73684210526316,
          44.73684210526316,
          42.10526315789474,
          42.10526315789474,
          42.10526315789474,
          42.10526315789474,
          42.10526315789474,
          42.10526315789474,
          42.10526315789474,
          39.473684210526315,
          39.473684210526315,
          39.473684210526315,
          42.10526315789474,
          50,
          50,
          44.73684210526316,
          34.21052631578947,
          34.21052631578947,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          34.21052631578947,
          34.21052631578947,
          34.21052631578947,
          39.473684210526315,
          42.10526315789474,
          47.36842105263158,
          55.26315789473684,
          55.26315789473684,
          60.526315789473685,
          68.42105263157895,
          81.57894736842105,
          89.47368421052632,
          92.10526315789474,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          92.10526315789474,
          86.84210526315789,
          81.57894736842105,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          84.21052631578948,
          86.84210526315789,
          86.84210526315789,
          89.47368421052632,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          89.47368421052632,
          89.47368421052632,
          84.21052631578948,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          84.21052631578948,
          89.47368421052632,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          89.47368421052632,
          86.84210526315789,
          86.84210526315789,
          84.21052631578948,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          81.57894736842105,
          89.47368421052632,
          92.10526315789474,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          89.47368421052632,
          89.47368421052632,
          86.84210526315789,
          84.21052631578948,
          84.21052631578948,
          81.57894736842105,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          84.21052631578948,
          86.84210526315789,
          89.47368421052632,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          97.36842105263158,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          100,
          100,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          92.10526315789474,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          100,
          94.73684210526316,
          94.73684210526316,
          100,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          97.36842105263158,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          100,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158
         ]
        }
       ],
       "layout": {
        "height": 300,
        "margin": {
         "b": 20,
         "l": 20,
         "r": 20,
         "t": 20
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 400,
        "xaxis": {
         "title": {
          "text": "Epochs"
         },
         "type": "log"
        },
        "yaxis": {
         "title": {
          "text": "Accuracy [%]"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(test_acc_SPSA)), y=test_acc_SPSA, mode='lines', name='PEPG'))\n",
    "#change theme to white and set the sizer of the plot\n",
    "fig.update_layout(template='plotly_white', width=400, height=300,margin=dict(l=20, r=20, t=20, b=20))\n",
    "fig.update_xaxes(title_text=\"Epochs\",type = 'log')\n",
    "fig.update_yaxes(title_text=\"Accuracy [%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt('data\\\\Results\\\\NN_training\\\\online_training\\\\IRIS\\\\SPSA_test_acc.csv', test_acc_SPSA, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "{i+1}Epoch [1/1000], Step [1/1], Loss: 1.3367279767990112, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [2/1000], Step [1/1], Loss: 1.3356982469558716, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [3/1000], Step [1/1], Loss: 1.3340157270431519, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [4/1000], Step [1/1], Loss: 1.3326414823532104, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [5/1000], Step [1/1], Loss: 1.331472396850586, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [6/1000], Step [1/1], Loss: 1.3304648399353027, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [7/1000], Step [1/1], Loss: 1.3297957181930542, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [8/1000], Step [1/1], Loss: 1.3283112049102783, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [9/1000], Step [1/1], Loss: 1.3269562721252441, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [10/1000], Step [1/1], Loss: 1.3247294425964355, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [11/1000], Step [1/1], Loss: 1.3201377391815186, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [12/1000], Step [1/1], Loss: 1.3160269260406494, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [13/1000], Step [1/1], Loss: 1.3123377561569214, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [14/1000], Step [1/1], Loss: 1.3090122938156128, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [15/1000], Step [1/1], Loss: 1.3060091733932495, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [16/1000], Step [1/1], Loss: 1.3032922744750977, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [17/1000], Step [1/1], Loss: 1.300983190536499, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [18/1000], Step [1/1], Loss: 1.2988868951797485, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [19/1000], Step [1/1], Loss: 1.2969127893447876, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [20/1000], Step [1/1], Loss: 1.2951927185058594, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [21/1000], Step [1/1], Loss: 1.293543815612793, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [22/1000], Step [1/1], Loss: 1.2924124002456665, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [23/1000], Step [1/1], Loss: 1.2889199256896973, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [24/1000], Step [1/1], Loss: 1.2860873937606812, Test Accuracy: 65.78947368421052%\n",
      "{i+1}Epoch [25/1000], Step [1/1], Loss: 1.283675193786621, Test Accuracy: 60.526315789473685%\n",
      "{i+1}Epoch [26/1000], Step [1/1], Loss: 1.2816177606582642, Test Accuracy: 57.89473684210526%\n",
      "{i+1}Epoch [27/1000], Step [1/1], Loss: 1.2797547578811646, Test Accuracy: 52.63157894736842%\n",
      "{i+1}Epoch [28/1000], Step [1/1], Loss: 1.278025507926941, Test Accuracy: 39.473684210526315%\n",
      "{i+1}Epoch [29/1000], Step [1/1], Loss: 1.2755804061889648, Test Accuracy: 36.8421052631579%\n",
      "{i+1}Epoch [30/1000], Step [1/1], Loss: 1.2721596956253052, Test Accuracy: 26.31578947368421%\n",
      "{i+1}Epoch [31/1000], Step [1/1], Loss: 1.2687584161758423, Test Accuracy: 26.31578947368421%\n",
      "{i+1}Epoch [32/1000], Step [1/1], Loss: 1.2641290426254272, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [33/1000], Step [1/1], Loss: 1.2596707344055176, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [34/1000], Step [1/1], Loss: 1.2557415962219238, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [35/1000], Step [1/1], Loss: 1.2522722482681274, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [36/1000], Step [1/1], Loss: 1.2495568990707397, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [37/1000], Step [1/1], Loss: 1.2471532821655273, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [38/1000], Step [1/1], Loss: 1.245021104812622, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [39/1000], Step [1/1], Loss: 1.2431261539459229, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [40/1000], Step [1/1], Loss: 1.2414392232894897, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [41/1000], Step [1/1], Loss: 1.2391377687454224, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [42/1000], Step [1/1], Loss: 1.2359721660614014, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [43/1000], Step [1/1], Loss: 1.2331466674804688, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [44/1000], Step [1/1], Loss: 1.230136513710022, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [45/1000], Step [1/1], Loss: 1.2274463176727295, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [46/1000], Step [1/1], Loss: 1.2250386476516724, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [47/1000], Step [1/1], Loss: 1.222643494606018, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [48/1000], Step [1/1], Loss: 1.2191836833953857, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [49/1000], Step [1/1], Loss: 1.2161074876785278, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [50/1000], Step [1/1], Loss: 1.2128784656524658, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [51/1000], Step [1/1], Loss: 1.2097619771957397, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [52/1000], Step [1/1], Loss: 1.2064651250839233, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [53/1000], Step [1/1], Loss: 1.2018440961837769, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [54/1000], Step [1/1], Loss: 1.1977685689926147, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [55/1000], Step [1/1], Loss: 1.194166898727417, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [56/1000], Step [1/1], Loss: 1.190079689025879, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [57/1000], Step [1/1], Loss: 1.1866711378097534, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [58/1000], Step [1/1], Loss: 1.1836280822753906, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [59/1000], Step [1/1], Loss: 1.1801425218582153, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [60/1000], Step [1/1], Loss: 1.177037000656128, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [61/1000], Step [1/1], Loss: 1.174265742301941, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [62/1000], Step [1/1], Loss: 1.1717888116836548, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [63/1000], Step [1/1], Loss: 1.169572353363037, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [64/1000], Step [1/1], Loss: 1.1671518087387085, Test Accuracy: 21.05263157894737%\n",
      "{i+1}Epoch [65/1000], Step [1/1], Loss: 1.1644011735916138, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [66/1000], Step [1/1], Loss: 1.1619449853897095, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [67/1000], Step [1/1], Loss: 1.1591992378234863, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [68/1000], Step [1/1], Loss: 1.1567182540893555, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [69/1000], Step [1/1], Loss: 1.1545089483261108, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [70/1000], Step [1/1], Loss: 1.1525226831436157, Test Accuracy: 15.789473684210526%\n",
      "{i+1}Epoch [71/1000], Step [1/1], Loss: 1.1527179479599, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [72/1000], Step [1/1], Loss: 1.152971625328064, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [73/1000], Step [1/1], Loss: 1.1532641649246216, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [74/1000], Step [1/1], Loss: 1.153714656829834, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [75/1000], Step [1/1], Loss: 1.1537612676620483, Test Accuracy: 21.05263157894737%\n",
      "{i+1}Epoch [76/1000], Step [1/1], Loss: 1.1541708707809448, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [77/1000], Step [1/1], Loss: 1.1546789407730103, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [78/1000], Step [1/1], Loss: 1.155243158340454, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [79/1000], Step [1/1], Loss: 1.1558408737182617, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [80/1000], Step [1/1], Loss: 1.1564706563949585, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [81/1000], Step [1/1], Loss: 1.1570942401885986, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [82/1000], Step [1/1], Loss: 1.1577801704406738, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [83/1000], Step [1/1], Loss: 1.158447504043579, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [84/1000], Step [1/1], Loss: 1.1587661504745483, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [85/1000], Step [1/1], Loss: 1.159070611000061, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [86/1000], Step [1/1], Loss: 1.1593598127365112, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [87/1000], Step [1/1], Loss: 1.1596324443817139, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [88/1000], Step [1/1], Loss: 1.1598137617111206, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [89/1000], Step [1/1], Loss: 1.15998375415802, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [90/1000], Step [1/1], Loss: 1.158860683441162, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [91/1000], Step [1/1], Loss: 1.1578359603881836, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [92/1000], Step [1/1], Loss: 1.1559536457061768, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [93/1000], Step [1/1], Loss: 1.154259443283081, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [94/1000], Step [1/1], Loss: 1.1531745195388794, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [95/1000], Step [1/1], Loss: 1.1522209644317627, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [96/1000], Step [1/1], Loss: 1.151379942893982, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [97/1000], Step [1/1], Loss: 1.1504151821136475, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [98/1000], Step [1/1], Loss: 1.149545669555664, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [99/1000], Step [1/1], Loss: 1.1477665901184082, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [100/1000], Step [1/1], Loss: 1.1461700201034546, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [101/1000], Step [1/1], Loss: 1.1447354555130005, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [102/1000], Step [1/1], Loss: 1.142857551574707, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [103/1000], Step [1/1], Loss: 1.1411643028259277, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [104/1000], Step [1/1], Loss: 1.1396360397338867, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [105/1000], Step [1/1], Loss: 1.1382592916488647, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [106/1000], Step [1/1], Loss: 1.1370177268981934, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [107/1000], Step [1/1], Loss: 1.1358977556228638, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [108/1000], Step [1/1], Loss: 1.1348402500152588, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [109/1000], Step [1/1], Loss: 1.1338905096054077, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [110/1000], Step [1/1], Loss: 1.1330333948135376, Test Accuracy: 21.05263157894737%\n",
      "{i+1}Epoch [111/1000], Step [1/1], Loss: 1.1297014951705933, Test Accuracy: 21.05263157894737%\n",
      "{i+1}Epoch [112/1000], Step [1/1], Loss: 1.1267976760864258, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [113/1000], Step [1/1], Loss: 1.1233152151107788, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [114/1000], Step [1/1], Loss: 1.1202770471572876, Test Accuracy: 13.157894736842104%\n",
      "{i+1}Epoch [115/1000], Step [1/1], Loss: 1.117719292640686, Test Accuracy: 7.894736842105263%\n",
      "{i+1}Epoch [116/1000], Step [1/1], Loss: 1.1128759384155273, Test Accuracy: 7.894736842105263%\n",
      "{i+1}Epoch [117/1000], Step [1/1], Loss: 1.108686089515686, Test Accuracy: 7.894736842105263%\n",
      "{i+1}Epoch [118/1000], Step [1/1], Loss: 1.1050255298614502, Test Accuracy: 10.526315789473685%\n",
      "{i+1}Epoch [119/1000], Step [1/1], Loss: 1.1018463373184204, Test Accuracy: 13.157894736842104%\n",
      "{i+1}Epoch [120/1000], Step [1/1], Loss: 1.098899245262146, Test Accuracy: 21.05263157894737%\n",
      "{i+1}Epoch [121/1000], Step [1/1], Loss: 1.0960549116134644, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [122/1000], Step [1/1], Loss: 1.0935308933258057, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [123/1000], Step [1/1], Loss: 1.0912894010543823, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [124/1000], Step [1/1], Loss: 1.0889889001846313, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [125/1000], Step [1/1], Loss: 1.0898504257202148, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [126/1000], Step [1/1], Loss: 1.0908596515655518, Test Accuracy: 26.31578947368421%\n",
      "{i+1}Epoch [127/1000], Step [1/1], Loss: 1.0911120176315308, Test Accuracy: 26.31578947368421%\n",
      "{i+1}Epoch [128/1000], Step [1/1], Loss: 1.0916211605072021, Test Accuracy: 26.31578947368421%\n",
      "{i+1}Epoch [129/1000], Step [1/1], Loss: 1.0923116207122803, Test Accuracy: 28.94736842105263%\n",
      "{i+1}Epoch [130/1000], Step [1/1], Loss: 1.091444969177246, Test Accuracy: 28.94736842105263%\n",
      "{i+1}Epoch [131/1000], Step [1/1], Loss: 1.0906000137329102, Test Accuracy: 28.94736842105263%\n",
      "{i+1}Epoch [132/1000], Step [1/1], Loss: 1.0899187326431274, Test Accuracy: 28.94736842105263%\n",
      "{i+1}Epoch [133/1000], Step [1/1], Loss: 1.0893703699111938, Test Accuracy: 28.94736842105263%\n",
      "{i+1}Epoch [134/1000], Step [1/1], Loss: 1.088729977607727, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [135/1000], Step [1/1], Loss: 1.0882248878479004, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [136/1000], Step [1/1], Loss: 1.088356614112854, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [137/1000], Step [1/1], Loss: 1.088560938835144, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [138/1000], Step [1/1], Loss: 1.0840071439743042, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [139/1000], Step [1/1], Loss: 1.0800498723983765, Test Accuracy: 28.94736842105263%\n",
      "{i+1}Epoch [140/1000], Step [1/1], Loss: 1.0746089220046997, Test Accuracy: 28.94736842105263%\n",
      "{i+1}Epoch [141/1000], Step [1/1], Loss: 1.0699727535247803, Test Accuracy: 26.31578947368421%\n",
      "{i+1}Epoch [142/1000], Step [1/1], Loss: 1.0666290521621704, Test Accuracy: 26.31578947368421%\n",
      "{i+1}Epoch [143/1000], Step [1/1], Loss: 1.0657790899276733, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [144/1000], Step [1/1], Loss: 1.065458059310913, Test Accuracy: 21.05263157894737%\n",
      "{i+1}Epoch [145/1000], Step [1/1], Loss: 1.0655869245529175, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [146/1000], Step [1/1], Loss: 1.0660336017608643, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [147/1000], Step [1/1], Loss: 1.0644737482070923, Test Accuracy: 15.789473684210526%\n",
      "{i+1}Epoch [148/1000], Step [1/1], Loss: 1.0631319284439087, Test Accuracy: 15.789473684210526%\n",
      "{i+1}Epoch [149/1000], Step [1/1], Loss: 1.0619739294052124, Test Accuracy: 15.789473684210526%\n",
      "{i+1}Epoch [150/1000], Step [1/1], Loss: 1.0596089363098145, Test Accuracy: 15.789473684210526%\n",
      "{i+1}Epoch [151/1000], Step [1/1], Loss: 1.0575040578842163, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [152/1000], Step [1/1], Loss: 1.0556306838989258, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [153/1000], Step [1/1], Loss: 1.0532115697860718, Test Accuracy: 21.05263157894737%\n",
      "{i+1}Epoch [154/1000], Step [1/1], Loss: 1.0509233474731445, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [155/1000], Step [1/1], Loss: 1.0488406419754028, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [156/1000], Step [1/1], Loss: 1.0469573736190796, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [157/1000], Step [1/1], Loss: 1.0449455976486206, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [158/1000], Step [1/1], Loss: 1.0420771837234497, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [159/1000], Step [1/1], Loss: 1.0373505353927612, Test Accuracy: 23.68421052631579%\n",
      "{i+1}Epoch [160/1000], Step [1/1], Loss: 1.0331041812896729, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [161/1000], Step [1/1], Loss: 1.0286524295806885, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [162/1000], Step [1/1], Loss: 1.024481177330017, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [163/1000], Step [1/1], Loss: 1.020676612854004, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [164/1000], Step [1/1], Loss: 1.0168699026107788, Test Accuracy: 18.42105263157895%\n",
      "{i+1}Epoch [165/1000], Step [1/1], Loss: 1.0117231607437134, Test Accuracy: 21.05263157894737%\n",
      "{i+1}Epoch [166/1000], Step [1/1], Loss: 1.0070981979370117, Test Accuracy: 21.05263157894737%\n",
      "{i+1}Epoch [167/1000], Step [1/1], Loss: 1.0029442310333252, Test Accuracy: 21.05263157894737%\n",
      "{i+1}Epoch [168/1000], Step [1/1], Loss: 0.9991777539253235, Test Accuracy: 21.05263157894737%\n",
      "{i+1}Epoch [169/1000], Step [1/1], Loss: 0.9944793581962585, Test Accuracy: 21.05263157894737%\n",
      "{i+1}Epoch [170/1000], Step [1/1], Loss: 0.9902297854423523, Test Accuracy: 26.31578947368421%\n",
      "{i+1}Epoch [171/1000], Step [1/1], Loss: 0.986255943775177, Test Accuracy: 26.31578947368421%\n",
      "{i+1}Epoch [172/1000], Step [1/1], Loss: 0.9782679677009583, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [173/1000], Step [1/1], Loss: 0.9712907671928406, Test Accuracy: 36.8421052631579%\n",
      "{i+1}Epoch [174/1000], Step [1/1], Loss: 0.9656084179878235, Test Accuracy: 39.473684210526315%\n",
      "{i+1}Epoch [175/1000], Step [1/1], Loss: 0.9605806469917297, Test Accuracy: 34.21052631578947%\n",
      "{i+1}Epoch [176/1000], Step [1/1], Loss: 0.9555923938751221, Test Accuracy: 36.8421052631579%\n",
      "{i+1}Epoch [177/1000], Step [1/1], Loss: 0.950789213180542, Test Accuracy: 44.73684210526316%\n",
      "{i+1}Epoch [178/1000], Step [1/1], Loss: 0.9458848834037781, Test Accuracy: 55.26315789473684%\n",
      "{i+1}Epoch [179/1000], Step [1/1], Loss: 0.9413271546363831, Test Accuracy: 57.89473684210526%\n",
      "{i+1}Epoch [180/1000], Step [1/1], Loss: 0.9372327923774719, Test Accuracy: 65.78947368421052%\n",
      "{i+1}Epoch [181/1000], Step [1/1], Loss: 0.93356853723526, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [182/1000], Step [1/1], Loss: 0.9299643635749817, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [183/1000], Step [1/1], Loss: 0.9267099499702454, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [184/1000], Step [1/1], Loss: 0.9252824187278748, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [185/1000], Step [1/1], Loss: 0.923864483833313, Test Accuracy: 73.6842105263158%\n",
      "{i+1}Epoch [186/1000], Step [1/1], Loss: 0.9222061634063721, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [187/1000], Step [1/1], Loss: 0.9205082058906555, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [188/1000], Step [1/1], Loss: 0.9190173149108887, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [189/1000], Step [1/1], Loss: 0.9175149202346802, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [190/1000], Step [1/1], Loss: 0.9162017703056335, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [191/1000], Step [1/1], Loss: 0.9150506854057312, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [192/1000], Step [1/1], Loss: 0.9140394330024719, Test Accuracy: 73.6842105263158%\n",
      "{i+1}Epoch [193/1000], Step [1/1], Loss: 0.9126785397529602, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [194/1000], Step [1/1], Loss: 0.9105604290962219, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [195/1000], Step [1/1], Loss: 0.9086446166038513, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [196/1000], Step [1/1], Loss: 0.9069123268127441, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [197/1000], Step [1/1], Loss: 0.905345618724823, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [198/1000], Step [1/1], Loss: 0.9039283394813538, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [199/1000], Step [1/1], Loss: 0.902646541595459, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [200/1000], Step [1/1], Loss: 0.9013260006904602, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [201/1000], Step [1/1], Loss: 0.9001316428184509, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [202/1000], Step [1/1], Loss: 0.8990505337715149, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [203/1000], Step [1/1], Loss: 0.8979315757751465, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [204/1000], Step [1/1], Loss: 0.8969190716743469, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [205/1000], Step [1/1], Loss: 0.8960033059120178, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [206/1000], Step [1/1], Loss: 0.8951743245124817, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [207/1000], Step [1/1], Loss: 0.894424557685852, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [208/1000], Step [1/1], Loss: 0.8937461376190186, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [209/1000], Step [1/1], Loss: 0.8931880593299866, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [210/1000], Step [1/1], Loss: 0.8932477235794067, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [211/1000], Step [1/1], Loss: 0.8932237029075623, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [212/1000], Step [1/1], Loss: 0.8922755718231201, Test Accuracy: 73.6842105263158%\n",
      "{i+1}Epoch [213/1000], Step [1/1], Loss: 0.8914291262626648, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [214/1000], Step [1/1], Loss: 0.8906318545341492, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [215/1000], Step [1/1], Loss: 0.8899176716804504, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [216/1000], Step [1/1], Loss: 0.8892772197723389, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [217/1000], Step [1/1], Loss: 0.8886111378669739, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [218/1000], Step [1/1], Loss: 0.8880390524864197, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [219/1000], Step [1/1], Loss: 0.8866965770721436, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [220/1000], Step [1/1], Loss: 0.8854851722717285, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [221/1000], Step [1/1], Loss: 0.884617269039154, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [222/1000], Step [1/1], Loss: 0.8838417530059814, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [223/1000], Step [1/1], Loss: 0.8843752145767212, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [224/1000], Step [1/1], Loss: 0.8849243521690369, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [225/1000], Step [1/1], Loss: 0.8849087953567505, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [226/1000], Step [1/1], Loss: 0.8838543891906738, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [227/1000], Step [1/1], Loss: 0.8819767832756042, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [228/1000], Step [1/1], Loss: 0.8803715109825134, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [229/1000], Step [1/1], Loss: 0.8784621357917786, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [230/1000], Step [1/1], Loss: 0.8765886425971985, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [231/1000], Step [1/1], Loss: 0.8749850392341614, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [232/1000], Step [1/1], Loss: 0.8736876249313354, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [233/1000], Step [1/1], Loss: 0.8725786805152893, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [234/1000], Step [1/1], Loss: 0.8716594576835632, Test Accuracy: 73.6842105263158%\n",
      "{i+1}Epoch [235/1000], Step [1/1], Loss: 0.8709367513656616, Test Accuracy: 73.6842105263158%\n",
      "{i+1}Epoch [236/1000], Step [1/1], Loss: 0.8704074025154114, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [237/1000], Step [1/1], Loss: 0.8706710934638977, Test Accuracy: 73.6842105263158%\n",
      "{i+1}Epoch [238/1000], Step [1/1], Loss: 0.8711502552032471, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [239/1000], Step [1/1], Loss: 0.8717498779296875, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [240/1000], Step [1/1], Loss: 0.872532308101654, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [241/1000], Step [1/1], Loss: 0.8729788064956665, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [242/1000], Step [1/1], Loss: 0.8734283447265625, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [243/1000], Step [1/1], Loss: 0.8738722801208496, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [244/1000], Step [1/1], Loss: 0.8731580972671509, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [245/1000], Step [1/1], Loss: 0.8726580739021301, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [246/1000], Step [1/1], Loss: 0.8723330497741699, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [247/1000], Step [1/1], Loss: 0.8721635937690735, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [248/1000], Step [1/1], Loss: 0.8720917105674744, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [249/1000], Step [1/1], Loss: 0.8721372485160828, Test Accuracy: 73.6842105263158%\n",
      "{i+1}Epoch [250/1000], Step [1/1], Loss: 0.8720133900642395, Test Accuracy: 73.6842105263158%\n",
      "{i+1}Epoch [251/1000], Step [1/1], Loss: 0.8720324635505676, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [252/1000], Step [1/1], Loss: 0.8720317482948303, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [253/1000], Step [1/1], Loss: 0.8722052574157715, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [254/1000], Step [1/1], Loss: 0.8657414317131042, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [255/1000], Step [1/1], Loss: 0.8595405220985413, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [256/1000], Step [1/1], Loss: 0.8540509939193726, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [257/1000], Step [1/1], Loss: 0.8475884795188904, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [258/1000], Step [1/1], Loss: 0.84169602394104, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [259/1000], Step [1/1], Loss: 0.8364316821098328, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [260/1000], Step [1/1], Loss: 0.8317176103591919, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [261/1000], Step [1/1], Loss: 0.8274927139282227, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [262/1000], Step [1/1], Loss: 0.8236514925956726, Test Accuracy: 71.05263157894737%\n",
      "{i+1}Epoch [263/1000], Step [1/1], Loss: 0.8202117085456848, Test Accuracy: 73.6842105263158%\n",
      "{i+1}Epoch [264/1000], Step [1/1], Loss: 0.8171257972717285, Test Accuracy: 73.6842105263158%\n",
      "{i+1}Epoch [265/1000], Step [1/1], Loss: 0.814352810382843, Test Accuracy: 73.6842105263158%\n",
      "{i+1}Epoch [266/1000], Step [1/1], Loss: 0.8091351985931396, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [267/1000], Step [1/1], Loss: 0.8045639991760254, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [268/1000], Step [1/1], Loss: 0.7996848225593567, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [269/1000], Step [1/1], Loss: 0.7952932715415955, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [270/1000], Step [1/1], Loss: 0.7912280559539795, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [271/1000], Step [1/1], Loss: 0.7877950668334961, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [272/1000], Step [1/1], Loss: 0.7847785949707031, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [273/1000], Step [1/1], Loss: 0.7821939587593079, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [274/1000], Step [1/1], Loss: 0.7798373103141785, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [275/1000], Step [1/1], Loss: 0.7777907252311707, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [276/1000], Step [1/1], Loss: 0.7764394879341125, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [277/1000], Step [1/1], Loss: 0.7749995589256287, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [278/1000], Step [1/1], Loss: 0.7737445831298828, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [279/1000], Step [1/1], Loss: 0.7726709842681885, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [280/1000], Step [1/1], Loss: 0.77232825756073, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [281/1000], Step [1/1], Loss: 0.7701260447502136, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [282/1000], Step [1/1], Loss: 0.7682136297225952, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [283/1000], Step [1/1], Loss: 0.7665945887565613, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [284/1000], Step [1/1], Loss: 0.7652029991149902, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [285/1000], Step [1/1], Loss: 0.7644813060760498, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [286/1000], Step [1/1], Loss: 0.7638825178146362, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [287/1000], Step [1/1], Loss: 0.7633832693099976, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [288/1000], Step [1/1], Loss: 0.7627323865890503, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [289/1000], Step [1/1], Loss: 0.7621111869812012, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [290/1000], Step [1/1], Loss: 0.7615776658058167, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [291/1000], Step [1/1], Loss: 0.7611181735992432, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [292/1000], Step [1/1], Loss: 0.7607213258743286, Test Accuracy: 78.94736842105263%\n",
      "{i+1}Epoch [293/1000], Step [1/1], Loss: 0.7595267295837402, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [294/1000], Step [1/1], Loss: 0.7584553360939026, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [295/1000], Step [1/1], Loss: 0.7575258016586304, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [296/1000], Step [1/1], Loss: 0.7567170858383179, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [297/1000], Step [1/1], Loss: 0.7559523582458496, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [298/1000], Step [1/1], Loss: 0.7553003430366516, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [299/1000], Step [1/1], Loss: 0.7533273100852966, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [300/1000], Step [1/1], Loss: 0.7515565752983093, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [301/1000], Step [1/1], Loss: 0.7499397397041321, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [302/1000], Step [1/1], Loss: 0.7484796047210693, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [303/1000], Step [1/1], Loss: 0.7466785907745361, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [304/1000], Step [1/1], Loss: 0.7446010708808899, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [305/1000], Step [1/1], Loss: 0.7419959902763367, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [306/1000], Step [1/1], Loss: 0.7396132946014404, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [307/1000], Step [1/1], Loss: 0.7372871041297913, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [308/1000], Step [1/1], Loss: 0.7353113889694214, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [309/1000], Step [1/1], Loss: 0.732759952545166, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [310/1000], Step [1/1], Loss: 0.730516254901886, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [311/1000], Step [1/1], Loss: 0.7285383343696594, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [312/1000], Step [1/1], Loss: 0.7264119982719421, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [313/1000], Step [1/1], Loss: 0.7245002388954163, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [314/1000], Step [1/1], Loss: 0.7223020792007446, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [315/1000], Step [1/1], Loss: 0.7203086018562317, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [316/1000], Step [1/1], Loss: 0.718583881855011, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [317/1000], Step [1/1], Loss: 0.7167045474052429, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [318/1000], Step [1/1], Loss: 0.7145983576774597, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [319/1000], Step [1/1], Loss: 0.7127346992492676, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [320/1000], Step [1/1], Loss: 0.7106689214706421, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [321/1000], Step [1/1], Loss: 0.7086154818534851, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [322/1000], Step [1/1], Loss: 0.7067432403564453, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [323/1000], Step [1/1], Loss: 0.7045251131057739, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [324/1000], Step [1/1], Loss: 0.7025392055511475, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [325/1000], Step [1/1], Loss: 0.7007598280906677, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [326/1000], Step [1/1], Loss: 0.6991641521453857, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [327/1000], Step [1/1], Loss: 0.6977319717407227, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [328/1000], Step [1/1], Loss: 0.6939011216163635, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [329/1000], Step [1/1], Loss: 0.6905330419540405, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [330/1000], Step [1/1], Loss: 0.6875717043876648, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [331/1000], Step [1/1], Loss: 0.6849599480628967, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [332/1000], Step [1/1], Loss: 0.6826496720314026, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [333/1000], Step [1/1], Loss: 0.6805249452590942, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [334/1000], Step [1/1], Loss: 0.6786888241767883, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [335/1000], Step [1/1], Loss: 0.6789403557777405, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [336/1000], Step [1/1], Loss: 0.6790836453437805, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [337/1000], Step [1/1], Loss: 0.6793082356452942, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [338/1000], Step [1/1], Loss: 0.6795855164527893, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [339/1000], Step [1/1], Loss: 0.6798753142356873, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [340/1000], Step [1/1], Loss: 0.6805049180984497, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [341/1000], Step [1/1], Loss: 0.6799209713935852, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [342/1000], Step [1/1], Loss: 0.6793084740638733, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [343/1000], Step [1/1], Loss: 0.6787810325622559, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [344/1000], Step [1/1], Loss: 0.6773238778114319, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [345/1000], Step [1/1], Loss: 0.6760340332984924, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [346/1000], Step [1/1], Loss: 0.6748886704444885, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [347/1000], Step [1/1], Loss: 0.6736891865730286, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [348/1000], Step [1/1], Loss: 0.6714252233505249, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [349/1000], Step [1/1], Loss: 0.6694052815437317, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [350/1000], Step [1/1], Loss: 0.6676004528999329, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [351/1000], Step [1/1], Loss: 0.6658468842506409, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [352/1000], Step [1/1], Loss: 0.664079487323761, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [353/1000], Step [1/1], Loss: 0.6624979376792908, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [354/1000], Step [1/1], Loss: 0.6610808372497559, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [355/1000], Step [1/1], Loss: 0.6598120331764221, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [356/1000], Step [1/1], Loss: 0.6583184599876404, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [357/1000], Step [1/1], Loss: 0.6573423743247986, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [358/1000], Step [1/1], Loss: 0.655534565448761, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [359/1000], Step [1/1], Loss: 0.653651237487793, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [360/1000], Step [1/1], Loss: 0.6520668268203735, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [361/1000], Step [1/1], Loss: 0.6507120728492737, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [362/1000], Step [1/1], Loss: 0.650084912776947, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [363/1000], Step [1/1], Loss: 0.649160623550415, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [364/1000], Step [1/1], Loss: 0.648334264755249, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [365/1000], Step [1/1], Loss: 0.6461538076400757, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [366/1000], Step [1/1], Loss: 0.6432583928108215, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [367/1000], Step [1/1], Loss: 0.6406857371330261, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [368/1000], Step [1/1], Loss: 0.6373147368431091, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [369/1000], Step [1/1], Loss: 0.6343312859535217, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [370/1000], Step [1/1], Loss: 0.6314785480499268, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [371/1000], Step [1/1], Loss: 0.6286170482635498, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [372/1000], Step [1/1], Loss: 0.625400722026825, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [373/1000], Step [1/1], Loss: 0.6225025057792664, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [374/1000], Step [1/1], Loss: 0.6216283440589905, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [375/1000], Step [1/1], Loss: 0.6208615303039551, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [376/1000], Step [1/1], Loss: 0.6198129057884216, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [377/1000], Step [1/1], Loss: 0.6186172366142273, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [378/1000], Step [1/1], Loss: 0.6175486445426941, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [379/1000], Step [1/1], Loss: 0.615565299987793, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [380/1000], Step [1/1], Loss: 0.6134341359138489, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [381/1000], Step [1/1], Loss: 0.6111549139022827, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [382/1000], Step [1/1], Loss: 0.6097556948661804, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [383/1000], Step [1/1], Loss: 0.60855633020401, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [384/1000], Step [1/1], Loss: 0.6075262427330017, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [385/1000], Step [1/1], Loss: 0.6066414713859558, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [386/1000], Step [1/1], Loss: 0.6059755086898804, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [387/1000], Step [1/1], Loss: 0.6036713123321533, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [388/1000], Step [1/1], Loss: 0.6006719470024109, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [389/1000], Step [1/1], Loss: 0.5984247326850891, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [390/1000], Step [1/1], Loss: 0.5964862704277039, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [391/1000], Step [1/1], Loss: 0.5951259136199951, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [392/1000], Step [1/1], Loss: 0.5926552414894104, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [393/1000], Step [1/1], Loss: 0.5904224514961243, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [394/1000], Step [1/1], Loss: 0.5884044766426086, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [395/1000], Step [1/1], Loss: 0.5862070918083191, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [396/1000], Step [1/1], Loss: 0.5778798460960388, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [397/1000], Step [1/1], Loss: 0.5706000328063965, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [398/1000], Step [1/1], Loss: 0.5640695095062256, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [399/1000], Step [1/1], Loss: 0.5580673813819885, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [400/1000], Step [1/1], Loss: 0.5527259707450867, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [401/1000], Step [1/1], Loss: 0.5455327033996582, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [402/1000], Step [1/1], Loss: 0.5393139123916626, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [403/1000], Step [1/1], Loss: 0.533925473690033, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [404/1000], Step [1/1], Loss: 0.5292455554008484, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [405/1000], Step [1/1], Loss: 0.524905264377594, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [406/1000], Step [1/1], Loss: 0.5215347409248352, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [407/1000], Step [1/1], Loss: 0.5196138620376587, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [408/1000], Step [1/1], Loss: 0.517595648765564, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [409/1000], Step [1/1], Loss: 0.5154376029968262, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [410/1000], Step [1/1], Loss: 0.513602077960968, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [411/1000], Step [1/1], Loss: 0.5120410919189453, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [412/1000], Step [1/1], Loss: 0.510713517665863, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [413/1000], Step [1/1], Loss: 0.5095842480659485, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [414/1000], Step [1/1], Loss: 0.5064708590507507, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [415/1000], Step [1/1], Loss: 0.5037064552307129, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [416/1000], Step [1/1], Loss: 0.5013044476509094, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [417/1000], Step [1/1], Loss: 0.4991549849510193, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [418/1000], Step [1/1], Loss: 0.49760207533836365, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [419/1000], Step [1/1], Loss: 0.4966629445552826, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [420/1000], Step [1/1], Loss: 0.4958520233631134, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [421/1000], Step [1/1], Loss: 0.49515020847320557, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [422/1000], Step [1/1], Loss: 0.49454161524772644, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [423/1000], Step [1/1], Loss: 0.49290481209754944, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [424/1000], Step [1/1], Loss: 0.4914577305316925, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [425/1000], Step [1/1], Loss: 0.49071693420410156, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [426/1000], Step [1/1], Loss: 0.4894237518310547, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [427/1000], Step [1/1], Loss: 0.48829585313796997, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [428/1000], Step [1/1], Loss: 0.48730945587158203, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [429/1000], Step [1/1], Loss: 0.48537564277648926, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [430/1000], Step [1/1], Loss: 0.48349088430404663, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [431/1000], Step [1/1], Loss: 0.4818558990955353, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [432/1000], Step [1/1], Loss: 0.4802290201187134, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [433/1000], Step [1/1], Loss: 0.47881999611854553, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [434/1000], Step [1/1], Loss: 0.47747135162353516, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [435/1000], Step [1/1], Loss: 0.47386541962623596, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [436/1000], Step [1/1], Loss: 0.47530245780944824, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [437/1000], Step [1/1], Loss: 0.4768245220184326, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [438/1000], Step [1/1], Loss: 0.4778188467025757, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [439/1000], Step [1/1], Loss: 0.47898364067077637, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [440/1000], Step [1/1], Loss: 0.4781130850315094, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [441/1000], Step [1/1], Loss: 0.4758073389530182, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [442/1000], Step [1/1], Loss: 0.4735068678855896, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [443/1000], Step [1/1], Loss: 0.4717493951320648, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [444/1000], Step [1/1], Loss: 0.47027912735939026, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [445/1000], Step [1/1], Loss: 0.46883004903793335, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [446/1000], Step [1/1], Loss: 0.4675661027431488, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [447/1000], Step [1/1], Loss: 0.4665244221687317, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [448/1000], Step [1/1], Loss: 0.4656083583831787, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [449/1000], Step [1/1], Loss: 0.4648005962371826, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [450/1000], Step [1/1], Loss: 0.46498048305511475, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [451/1000], Step [1/1], Loss: 0.46500617265701294, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [452/1000], Step [1/1], Loss: 0.4646117687225342, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [453/1000], Step [1/1], Loss: 0.4643094539642334, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [454/1000], Step [1/1], Loss: 0.46406540274620056, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [455/1000], Step [1/1], Loss: 0.46360552310943604, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [456/1000], Step [1/1], Loss: 0.4627930521965027, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [457/1000], Step [1/1], Loss: 0.46129441261291504, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [458/1000], Step [1/1], Loss: 0.4599893093109131, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [459/1000], Step [1/1], Loss: 0.4588333070278168, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [460/1000], Step [1/1], Loss: 0.45781442523002625, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [461/1000], Step [1/1], Loss: 0.45697256922721863, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [462/1000], Step [1/1], Loss: 0.4562278687953949, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [463/1000], Step [1/1], Loss: 0.4553678333759308, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [464/1000], Step [1/1], Loss: 0.45449212193489075, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [465/1000], Step [1/1], Loss: 0.4537099599838257, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [466/1000], Step [1/1], Loss: 0.45295313000679016, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [467/1000], Step [1/1], Loss: 0.4522843062877655, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [468/1000], Step [1/1], Loss: 0.45170044898986816, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [469/1000], Step [1/1], Loss: 0.4512006342411041, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [470/1000], Step [1/1], Loss: 0.4507570266723633, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [471/1000], Step [1/1], Loss: 0.44766998291015625, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [472/1000], Step [1/1], Loss: 0.4446767568588257, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [473/1000], Step [1/1], Loss: 0.4413659870624542, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [474/1000], Step [1/1], Loss: 0.4384629726409912, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [475/1000], Step [1/1], Loss: 0.4360032379627228, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [476/1000], Step [1/1], Loss: 0.43356138467788696, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [477/1000], Step [1/1], Loss: 0.4310763478279114, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [478/1000], Step [1/1], Loss: 0.4284873902797699, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [479/1000], Step [1/1], Loss: 0.4265325367450714, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [480/1000], Step [1/1], Loss: 0.42522305250167847, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [481/1000], Step [1/1], Loss: 0.42515555024147034, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [482/1000], Step [1/1], Loss: 0.4260590076446533, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [483/1000], Step [1/1], Loss: 0.42769506573677063, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [484/1000], Step [1/1], Loss: 0.43022558093070984, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [485/1000], Step [1/1], Loss: 0.4323366582393646, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [486/1000], Step [1/1], Loss: 0.4338936507701874, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [487/1000], Step [1/1], Loss: 0.4349547326564789, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [488/1000], Step [1/1], Loss: 0.4359574615955353, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [489/1000], Step [1/1], Loss: 0.4364092946052551, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [490/1000], Step [1/1], Loss: 0.43417173624038696, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [491/1000], Step [1/1], Loss: 0.432223916053772, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [492/1000], Step [1/1], Loss: 0.43045416474342346, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [493/1000], Step [1/1], Loss: 0.4288974106311798, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [494/1000], Step [1/1], Loss: 0.42752692103385925, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [495/1000], Step [1/1], Loss: 0.42630553245544434, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [496/1000], Step [1/1], Loss: 0.42277857661247253, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [497/1000], Step [1/1], Loss: 0.41997963190078735, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [498/1000], Step [1/1], Loss: 0.4181436002254486, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [499/1000], Step [1/1], Loss: 0.4167994558811188, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [500/1000], Step [1/1], Loss: 0.4163905084133148, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [501/1000], Step [1/1], Loss: 0.41632139682769775, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [502/1000], Step [1/1], Loss: 0.41636624932289124, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [503/1000], Step [1/1], Loss: 0.4165220856666565, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [504/1000], Step [1/1], Loss: 0.4167531728744507, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [505/1000], Step [1/1], Loss: 0.4170195758342743, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [506/1000], Step [1/1], Loss: 0.4170166850090027, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [507/1000], Step [1/1], Loss: 0.4173230230808258, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [508/1000], Step [1/1], Loss: 0.41754236817359924, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [509/1000], Step [1/1], Loss: 0.4178800880908966, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [510/1000], Step [1/1], Loss: 0.4165419638156891, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [511/1000], Step [1/1], Loss: 0.41513127088546753, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [512/1000], Step [1/1], Loss: 0.4139356017112732, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [513/1000], Step [1/1], Loss: 0.4137800335884094, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [514/1000], Step [1/1], Loss: 0.41340819001197815, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [515/1000], Step [1/1], Loss: 0.41245484352111816, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [516/1000], Step [1/1], Loss: 0.41433951258659363, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [517/1000], Step [1/1], Loss: 0.4166569411754608, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [518/1000], Step [1/1], Loss: 0.41897714138031006, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [519/1000], Step [1/1], Loss: 0.4208068549633026, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [520/1000], Step [1/1], Loss: 0.4226284623146057, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [521/1000], Step [1/1], Loss: 0.4241655170917511, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [522/1000], Step [1/1], Loss: 0.4256744384765625, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [523/1000], Step [1/1], Loss: 0.4260534942150116, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [524/1000], Step [1/1], Loss: 0.41933560371398926, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [525/1000], Step [1/1], Loss: 0.4135321080684662, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [526/1000], Step [1/1], Loss: 0.40890899300575256, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [527/1000], Step [1/1], Loss: 0.4052339792251587, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [528/1000], Step [1/1], Loss: 0.40216851234436035, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [529/1000], Step [1/1], Loss: 0.3996782898902893, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [530/1000], Step [1/1], Loss: 0.3980481028556824, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [531/1000], Step [1/1], Loss: 0.39693117141723633, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [532/1000], Step [1/1], Loss: 0.39610472321510315, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [533/1000], Step [1/1], Loss: 0.39562973380088806, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [534/1000], Step [1/1], Loss: 0.3951604664325714, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [535/1000], Step [1/1], Loss: 0.39481672644615173, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [536/1000], Step [1/1], Loss: 0.3945339024066925, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [537/1000], Step [1/1], Loss: 0.39467936754226685, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [538/1000], Step [1/1], Loss: 0.3946375548839569, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [539/1000], Step [1/1], Loss: 0.3946840763092041, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [540/1000], Step [1/1], Loss: 0.39472612738609314, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [541/1000], Step [1/1], Loss: 0.3937020003795624, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [542/1000], Step [1/1], Loss: 0.39279934763908386, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [543/1000], Step [1/1], Loss: 0.39162376523017883, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [544/1000], Step [1/1], Loss: 0.390749990940094, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [545/1000], Step [1/1], Loss: 0.3901514410972595, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [546/1000], Step [1/1], Loss: 0.38997069001197815, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [547/1000], Step [1/1], Loss: 0.389913946390152, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [548/1000], Step [1/1], Loss: 0.3906112015247345, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [549/1000], Step [1/1], Loss: 0.3914834260940552, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [550/1000], Step [1/1], Loss: 0.3924710154533386, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [551/1000], Step [1/1], Loss: 0.3931175470352173, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [552/1000], Step [1/1], Loss: 0.3924245238304138, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [553/1000], Step [1/1], Loss: 0.39188164472579956, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [554/1000], Step [1/1], Loss: 0.39142510294914246, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [555/1000], Step [1/1], Loss: 0.3910333812236786, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [556/1000], Step [1/1], Loss: 0.39072108268737793, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [557/1000], Step [1/1], Loss: 0.3904806971549988, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [558/1000], Step [1/1], Loss: 0.3902762532234192, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [559/1000], Step [1/1], Loss: 0.3889383375644684, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [560/1000], Step [1/1], Loss: 0.3877805471420288, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [561/1000], Step [1/1], Loss: 0.3862801492214203, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [562/1000], Step [1/1], Loss: 0.38495922088623047, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [563/1000], Step [1/1], Loss: 0.38348260521888733, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [564/1000], Step [1/1], Loss: 0.3808155953884125, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [565/1000], Step [1/1], Loss: 0.37857314944267273, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [566/1000], Step [1/1], Loss: 0.376478910446167, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [567/1000], Step [1/1], Loss: 0.37507596611976624, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [568/1000], Step [1/1], Loss: 0.37384718656539917, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [569/1000], Step [1/1], Loss: 0.37276849150657654, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [570/1000], Step [1/1], Loss: 0.37137091159820557, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [571/1000], Step [1/1], Loss: 0.3699420988559723, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [572/1000], Step [1/1], Loss: 0.36935240030288696, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [573/1000], Step [1/1], Loss: 0.36896130442619324, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [574/1000], Step [1/1], Loss: 0.3684486746788025, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [575/1000], Step [1/1], Loss: 0.3676586449146271, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [576/1000], Step [1/1], Loss: 0.36668890714645386, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [577/1000], Step [1/1], Loss: 0.3658161759376526, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [578/1000], Step [1/1], Loss: 0.3650303781032562, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [579/1000], Step [1/1], Loss: 0.36411747336387634, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [580/1000], Step [1/1], Loss: 0.3632936179637909, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [581/1000], Step [1/1], Loss: 0.3625500500202179, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [582/1000], Step [1/1], Loss: 0.3612199127674103, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [583/1000], Step [1/1], Loss: 0.36002880334854126, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [584/1000], Step [1/1], Loss: 0.358107328414917, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [585/1000], Step [1/1], Loss: 0.35623547434806824, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [586/1000], Step [1/1], Loss: 0.35460275411605835, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [587/1000], Step [1/1], Loss: 0.35322752594947815, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [588/1000], Step [1/1], Loss: 0.3519444465637207, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [589/1000], Step [1/1], Loss: 0.35081592202186584, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [590/1000], Step [1/1], Loss: 0.3498218059539795, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [591/1000], Step [1/1], Loss: 0.3486712574958801, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [592/1000], Step [1/1], Loss: 0.34766077995300293, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [593/1000], Step [1/1], Loss: 0.34674331545829773, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [594/1000], Step [1/1], Loss: 0.3457931876182556, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [595/1000], Step [1/1], Loss: 0.3446232080459595, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [596/1000], Step [1/1], Loss: 0.34359145164489746, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [597/1000], Step [1/1], Loss: 0.3436008393764496, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [598/1000], Step [1/1], Loss: 0.34374499320983887, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [599/1000], Step [1/1], Loss: 0.34416037797927856, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [600/1000], Step [1/1], Loss: 0.3449254333972931, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [601/1000], Step [1/1], Loss: 0.34450358152389526, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [602/1000], Step [1/1], Loss: 0.344211608171463, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [603/1000], Step [1/1], Loss: 0.3424499034881592, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [604/1000], Step [1/1], Loss: 0.3408302068710327, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [605/1000], Step [1/1], Loss: 0.339498907327652, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [606/1000], Step [1/1], Loss: 0.33835452795028687, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [607/1000], Step [1/1], Loss: 0.3373701870441437, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [608/1000], Step [1/1], Loss: 0.33637890219688416, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [609/1000], Step [1/1], Loss: 0.33550143241882324, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [610/1000], Step [1/1], Loss: 0.3354836702346802, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [611/1000], Step [1/1], Loss: 0.3342680037021637, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [612/1000], Step [1/1], Loss: 0.33322250843048096, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [613/1000], Step [1/1], Loss: 0.3323366045951843, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [614/1000], Step [1/1], Loss: 0.33155086636543274, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [615/1000], Step [1/1], Loss: 0.3307426869869232, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [616/1000], Step [1/1], Loss: 0.33001208305358887, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [617/1000], Step [1/1], Loss: 0.3293112814426422, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [618/1000], Step [1/1], Loss: 0.3286910951137543, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [619/1000], Step [1/1], Loss: 0.3281399607658386, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [620/1000], Step [1/1], Loss: 0.32732900977134705, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [621/1000], Step [1/1], Loss: 0.3272198736667633, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [622/1000], Step [1/1], Loss: 0.32714587450027466, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [623/1000], Step [1/1], Loss: 0.3270993232727051, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [624/1000], Step [1/1], Loss: 0.32699310779571533, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [625/1000], Step [1/1], Loss: 0.32690882682800293, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [626/1000], Step [1/1], Loss: 0.3264319896697998, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [627/1000], Step [1/1], Loss: 0.326015442609787, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [628/1000], Step [1/1], Loss: 0.32562413811683655, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [629/1000], Step [1/1], Loss: 0.32513269782066345, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [630/1000], Step [1/1], Loss: 0.3245576322078705, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [631/1000], Step [1/1], Loss: 0.3238505423069, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [632/1000], Step [1/1], Loss: 0.323225736618042, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [633/1000], Step [1/1], Loss: 0.3224915564060211, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [634/1000], Step [1/1], Loss: 0.3218429386615753, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [635/1000], Step [1/1], Loss: 0.32112917304039, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [636/1000], Step [1/1], Loss: 0.320404976606369, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [637/1000], Step [1/1], Loss: 0.31975361704826355, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [638/1000], Step [1/1], Loss: 0.3191790282726288, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [639/1000], Step [1/1], Loss: 0.31861960887908936, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [640/1000], Step [1/1], Loss: 0.3180276155471802, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [641/1000], Step [1/1], Loss: 0.3174688518047333, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [642/1000], Step [1/1], Loss: 0.3170318603515625, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [643/1000], Step [1/1], Loss: 0.31736594438552856, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [644/1000], Step [1/1], Loss: 0.31741929054260254, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [645/1000], Step [1/1], Loss: 0.3174934983253479, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [646/1000], Step [1/1], Loss: 0.31762537360191345, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [647/1000], Step [1/1], Loss: 0.31868720054626465, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [648/1000], Step [1/1], Loss: 0.3198491930961609, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [649/1000], Step [1/1], Loss: 0.3210678696632385, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [650/1000], Step [1/1], Loss: 0.3223094046115875, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [651/1000], Step [1/1], Loss: 0.32355621457099915, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [652/1000], Step [1/1], Loss: 0.32414767146110535, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [653/1000], Step [1/1], Loss: 0.3247321844100952, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [654/1000], Step [1/1], Loss: 0.32508188486099243, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [655/1000], Step [1/1], Loss: 0.3248593807220459, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [656/1000], Step [1/1], Loss: 0.32433199882507324, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [657/1000], Step [1/1], Loss: 0.32387661933898926, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [658/1000], Step [1/1], Loss: 0.32293862104415894, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [659/1000], Step [1/1], Loss: 0.3220019042491913, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [660/1000], Step [1/1], Loss: 0.3212059438228607, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [661/1000], Step [1/1], Loss: 0.3194730579853058, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [662/1000], Step [1/1], Loss: 0.318002313375473, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [663/1000], Step [1/1], Loss: 0.3165019154548645, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [664/1000], Step [1/1], Loss: 0.31329289078712463, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [665/1000], Step [1/1], Loss: 0.3105299472808838, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [666/1000], Step [1/1], Loss: 0.30817586183547974, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [667/1000], Step [1/1], Loss: 0.30606260895729065, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [668/1000], Step [1/1], Loss: 0.3043196201324463, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [669/1000], Step [1/1], Loss: 0.3027670383453369, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [670/1000], Step [1/1], Loss: 0.30138257145881653, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [671/1000], Step [1/1], Loss: 0.3005622327327728, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [672/1000], Step [1/1], Loss: 0.29997867345809937, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [673/1000], Step [1/1], Loss: 0.29994311928749084, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [674/1000], Step [1/1], Loss: 0.30001410841941833, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [675/1000], Step [1/1], Loss: 0.3001701235771179, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [676/1000], Step [1/1], Loss: 0.3001250624656677, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [677/1000], Step [1/1], Loss: 0.30007418990135193, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [678/1000], Step [1/1], Loss: 0.2998763620853424, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [679/1000], Step [1/1], Loss: 0.2993732690811157, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [680/1000], Step [1/1], Loss: 0.2989403009414673, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [681/1000], Step [1/1], Loss: 0.2975393235683441, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [682/1000], Step [1/1], Loss: 0.2960550785064697, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [683/1000], Step [1/1], Loss: 0.2945355176925659, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [684/1000], Step [1/1], Loss: 0.29374730587005615, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [685/1000], Step [1/1], Loss: 0.29161009192466736, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [686/1000], Step [1/1], Loss: 0.29020601511001587, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [687/1000], Step [1/1], Loss: 0.28900837898254395, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [688/1000], Step [1/1], Loss: 0.2879921495914459, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [689/1000], Step [1/1], Loss: 0.28593993186950684, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [690/1000], Step [1/1], Loss: 0.2842346727848053, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [691/1000], Step [1/1], Loss: 0.28264743089675903, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [692/1000], Step [1/1], Loss: 0.2813463807106018, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [693/1000], Step [1/1], Loss: 0.2803235650062561, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [694/1000], Step [1/1], Loss: 0.27932825684547424, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [695/1000], Step [1/1], Loss: 0.27848151326179504, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [696/1000], Step [1/1], Loss: 0.2777612805366516, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [697/1000], Step [1/1], Loss: 0.2777433395385742, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [698/1000], Step [1/1], Loss: 0.2785890996456146, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [699/1000], Step [1/1], Loss: 0.2794593572616577, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [700/1000], Step [1/1], Loss: 0.280881404876709, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [701/1000], Step [1/1], Loss: 0.2828494906425476, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [702/1000], Step [1/1], Loss: 0.2854282259941101, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [703/1000], Step [1/1], Loss: 0.2882600724697113, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [704/1000], Step [1/1], Loss: 0.29108792543411255, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [705/1000], Step [1/1], Loss: 0.2939031422138214, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [706/1000], Step [1/1], Loss: 0.2966791093349457, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [707/1000], Step [1/1], Loss: 0.29839709401130676, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [708/1000], Step [1/1], Loss: 0.3000237047672272, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [709/1000], Step [1/1], Loss: 0.3011890649795532, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [710/1000], Step [1/1], Loss: 0.30196723341941833, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [711/1000], Step [1/1], Loss: 0.3027079999446869, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [712/1000], Step [1/1], Loss: 0.30339711904525757, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [713/1000], Step [1/1], Loss: 0.30323606729507446, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [714/1000], Step [1/1], Loss: 0.3030930459499359, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [715/1000], Step [1/1], Loss: 0.30296584963798523, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [716/1000], Step [1/1], Loss: 0.30206623673439026, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [717/1000], Step [1/1], Loss: 0.30127382278442383, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [718/1000], Step [1/1], Loss: 0.3005744218826294, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [719/1000], Step [1/1], Loss: 0.29995566606521606, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [720/1000], Step [1/1], Loss: 0.29940757155418396, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [721/1000], Step [1/1], Loss: 0.29892122745513916, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [722/1000], Step [1/1], Loss: 0.29554513096809387, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [723/1000], Step [1/1], Loss: 0.29164326190948486, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [724/1000], Step [1/1], Loss: 0.2884176969528198, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [725/1000], Step [1/1], Loss: 0.2859033942222595, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [726/1000], Step [1/1], Loss: 0.2841242849826813, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [727/1000], Step [1/1], Loss: 0.2824306786060333, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [728/1000], Step [1/1], Loss: 0.28114113211631775, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [729/1000], Step [1/1], Loss: 0.2802499830722809, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [730/1000], Step [1/1], Loss: 0.27971261739730835, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [731/1000], Step [1/1], Loss: 0.27935591340065, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [732/1000], Step [1/1], Loss: 0.281109482049942, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [733/1000], Step [1/1], Loss: 0.28288769721984863, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [734/1000], Step [1/1], Loss: 0.2844933569431305, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [735/1000], Step [1/1], Loss: 0.2860473692417145, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [736/1000], Step [1/1], Loss: 0.2873956859111786, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [737/1000], Step [1/1], Loss: 0.289005309343338, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [738/1000], Step [1/1], Loss: 0.29049766063690186, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [739/1000], Step [1/1], Loss: 0.2914171516895294, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [740/1000], Step [1/1], Loss: 0.28819409012794495, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [741/1000], Step [1/1], Loss: 0.2853235602378845, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [742/1000], Step [1/1], Loss: 0.282703697681427, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [743/1000], Step [1/1], Loss: 0.2799205780029297, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [744/1000], Step [1/1], Loss: 0.2778622806072235, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [745/1000], Step [1/1], Loss: 0.2762916088104248, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [746/1000], Step [1/1], Loss: 0.2750414311885834, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [747/1000], Step [1/1], Loss: 0.2741778492927551, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [748/1000], Step [1/1], Loss: 0.27347224950790405, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [749/1000], Step [1/1], Loss: 0.2727409303188324, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [750/1000], Step [1/1], Loss: 0.271903932094574, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [751/1000], Step [1/1], Loss: 0.2692693769931793, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [752/1000], Step [1/1], Loss: 0.26836857199668884, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [753/1000], Step [1/1], Loss: 0.26769423484802246, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [754/1000], Step [1/1], Loss: 0.2670283615589142, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [755/1000], Step [1/1], Loss: 0.26641955971717834, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [756/1000], Step [1/1], Loss: 0.2659693658351898, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [757/1000], Step [1/1], Loss: 0.26550939679145813, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [758/1000], Step [1/1], Loss: 0.2651583254337311, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [759/1000], Step [1/1], Loss: 0.2642124593257904, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [760/1000], Step [1/1], Loss: 0.26337048411369324, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [761/1000], Step [1/1], Loss: 0.26261985301971436, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [762/1000], Step [1/1], Loss: 0.26266488432884216, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [763/1000], Step [1/1], Loss: 0.2620609998703003, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [764/1000], Step [1/1], Loss: 0.2619682848453522, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [765/1000], Step [1/1], Loss: 0.26183581352233887, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [766/1000], Step [1/1], Loss: 0.2617590129375458, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [767/1000], Step [1/1], Loss: 0.2617321312427521, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [768/1000], Step [1/1], Loss: 0.2616879940032959, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [769/1000], Step [1/1], Loss: 0.2616746127605438, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [770/1000], Step [1/1], Loss: 0.26168447732925415, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [771/1000], Step [1/1], Loss: 0.2614000737667084, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [772/1000], Step [1/1], Loss: 0.25966617465019226, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [773/1000], Step [1/1], Loss: 0.25790682435035706, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [774/1000], Step [1/1], Loss: 0.25478431582450867, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [775/1000], Step [1/1], Loss: 0.2521009147167206, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [776/1000], Step [1/1], Loss: 0.24954712390899658, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [777/1000], Step [1/1], Loss: 0.2477826029062271, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [778/1000], Step [1/1], Loss: 0.24628187716007233, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [779/1000], Step [1/1], Loss: 0.2445974349975586, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [780/1000], Step [1/1], Loss: 0.2431829571723938, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [781/1000], Step [1/1], Loss: 0.24181601405143738, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [782/1000], Step [1/1], Loss: 0.240634948015213, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [783/1000], Step [1/1], Loss: 0.2396371215581894, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [784/1000], Step [1/1], Loss: 0.23878984153270721, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [785/1000], Step [1/1], Loss: 0.23896515369415283, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [786/1000], Step [1/1], Loss: 0.23948805034160614, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [787/1000], Step [1/1], Loss: 0.24034906923770905, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [788/1000], Step [1/1], Loss: 0.24282360076904297, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [789/1000], Step [1/1], Loss: 0.2457360178232193, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [790/1000], Step [1/1], Loss: 0.2489311546087265, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [791/1000], Step [1/1], Loss: 0.25199422240257263, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [792/1000], Step [1/1], Loss: 0.2550940215587616, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [793/1000], Step [1/1], Loss: 0.2551242411136627, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [794/1000], Step [1/1], Loss: 0.252949595451355, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [795/1000], Step [1/1], Loss: 0.25101137161254883, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [796/1000], Step [1/1], Loss: 0.24872516095638275, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [797/1000], Step [1/1], Loss: 0.24673838913440704, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [798/1000], Step [1/1], Loss: 0.24505025148391724, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [799/1000], Step [1/1], Loss: 0.2436058670282364, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [800/1000], Step [1/1], Loss: 0.2422104924917221, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [801/1000], Step [1/1], Loss: 0.24035431444644928, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [802/1000], Step [1/1], Loss: 0.23872970044612885, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [803/1000], Step [1/1], Loss: 0.23730586469173431, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [804/1000], Step [1/1], Loss: 0.23624347150325775, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [805/1000], Step [1/1], Loss: 0.23529471457004547, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [806/1000], Step [1/1], Loss: 0.2343910187482834, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [807/1000], Step [1/1], Loss: 0.2335892766714096, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [808/1000], Step [1/1], Loss: 0.23302429914474487, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [809/1000], Step [1/1], Loss: 0.23299774527549744, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [810/1000], Step [1/1], Loss: 0.23257651925086975, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [811/1000], Step [1/1], Loss: 0.2322334200143814, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [812/1000], Step [1/1], Loss: 0.23146717250347137, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [813/1000], Step [1/1], Loss: 0.23064440488815308, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [814/1000], Step [1/1], Loss: 0.22991780936717987, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [815/1000], Step [1/1], Loss: 0.22980289161205292, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [816/1000], Step [1/1], Loss: 0.22975093126296997, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [817/1000], Step [1/1], Loss: 0.22927716374397278, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [818/1000], Step [1/1], Loss: 0.22885175049304962, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [819/1000], Step [1/1], Loss: 0.2277660369873047, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [820/1000], Step [1/1], Loss: 0.2249521166086197, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [821/1000], Step [1/1], Loss: 0.22263920307159424, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [822/1000], Step [1/1], Loss: 0.2215743362903595, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [823/1000], Step [1/1], Loss: 0.22062663733959198, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [824/1000], Step [1/1], Loss: 0.21978294849395752, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [825/1000], Step [1/1], Loss: 0.21876229345798492, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [826/1000], Step [1/1], Loss: 0.2178627997636795, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [827/1000], Step [1/1], Loss: 0.21698026359081268, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [828/1000], Step [1/1], Loss: 0.21620024740695953, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [829/1000], Step [1/1], Loss: 0.2155095636844635, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [830/1000], Step [1/1], Loss: 0.2148970514535904, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [831/1000], Step [1/1], Loss: 0.21435290575027466, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [832/1000], Step [1/1], Loss: 0.21386873722076416, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [833/1000], Step [1/1], Loss: 0.21343743801116943, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [834/1000], Step [1/1], Loss: 0.21305270493030548, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [835/1000], Step [1/1], Loss: 0.21280133724212646, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [836/1000], Step [1/1], Loss: 0.212646484375, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [837/1000], Step [1/1], Loss: 0.21250395476818085, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [838/1000], Step [1/1], Loss: 0.21341858804225922, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [839/1000], Step [1/1], Loss: 0.21456778049468994, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [840/1000], Step [1/1], Loss: 0.21710637211799622, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [841/1000], Step [1/1], Loss: 0.22023428976535797, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [842/1000], Step [1/1], Loss: 0.22150392830371857, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [843/1000], Step [1/1], Loss: 0.2215583771467209, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [844/1000], Step [1/1], Loss: 0.2190883606672287, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [845/1000], Step [1/1], Loss: 0.21684277057647705, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [846/1000], Step [1/1], Loss: 0.2131645828485489, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [847/1000], Step [1/1], Loss: 0.20916648209095, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [848/1000], Step [1/1], Loss: 0.20586267113685608, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [849/1000], Step [1/1], Loss: 0.20313042402267456, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [850/1000], Step [1/1], Loss: 0.20172567665576935, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [851/1000], Step [1/1], Loss: 0.20027132332324982, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [852/1000], Step [1/1], Loss: 0.1990146040916443, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [853/1000], Step [1/1], Loss: 0.19792574644088745, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [854/1000], Step [1/1], Loss: 0.19698169827461243, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [855/1000], Step [1/1], Loss: 0.1961638182401657, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [856/1000], Step [1/1], Loss: 0.19545243680477142, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [857/1000], Step [1/1], Loss: 0.19483095407485962, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [858/1000], Step [1/1], Loss: 0.19427862763404846, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [859/1000], Step [1/1], Loss: 0.19379445910453796, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [860/1000], Step [1/1], Loss: 0.19336414337158203, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [861/1000], Step [1/1], Loss: 0.19308562576770782, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [862/1000], Step [1/1], Loss: 0.19283710420131683, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [863/1000], Step [1/1], Loss: 0.1927250474691391, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [864/1000], Step [1/1], Loss: 0.19266760349273682, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [865/1000], Step [1/1], Loss: 0.1926514208316803, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [866/1000], Step [1/1], Loss: 0.19322489202022552, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [867/1000], Step [1/1], Loss: 0.19373102486133575, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [868/1000], Step [1/1], Loss: 0.19543635845184326, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [869/1000], Step [1/1], Loss: 0.1972225308418274, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [870/1000], Step [1/1], Loss: 0.19912901520729065, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [871/1000], Step [1/1], Loss: 0.2009369432926178, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [872/1000], Step [1/1], Loss: 0.20276391506195068, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [873/1000], Step [1/1], Loss: 0.20456959307193756, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [874/1000], Step [1/1], Loss: 0.20439986884593964, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [875/1000], Step [1/1], Loss: 0.20354178547859192, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [876/1000], Step [1/1], Loss: 0.2028377205133438, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [877/1000], Step [1/1], Loss: 0.2018713504076004, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [878/1000], Step [1/1], Loss: 0.2006443589925766, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [879/1000], Step [1/1], Loss: 0.199554443359375, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [880/1000], Step [1/1], Loss: 0.19770893454551697, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [881/1000], Step [1/1], Loss: 0.1948174387216568, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [882/1000], Step [1/1], Loss: 0.19163532555103302, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [883/1000], Step [1/1], Loss: 0.18911215662956238, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [884/1000], Step [1/1], Loss: 0.18712709844112396, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [885/1000], Step [1/1], Loss: 0.18562424182891846, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [886/1000], Step [1/1], Loss: 0.18442407250404358, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [887/1000], Step [1/1], Loss: 0.1834266036748886, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [888/1000], Step [1/1], Loss: 0.18251235783100128, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [889/1000], Step [1/1], Loss: 0.18175214529037476, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [890/1000], Step [1/1], Loss: 0.18151631951332092, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [891/1000], Step [1/1], Loss: 0.1813407689332962, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [892/1000], Step [1/1], Loss: 0.1818310022354126, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [893/1000], Step [1/1], Loss: 0.18232066929340363, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [894/1000], Step [1/1], Loss: 0.182957261800766, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [895/1000], Step [1/1], Loss: 0.18361875414848328, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [896/1000], Step [1/1], Loss: 0.1842762976884842, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [897/1000], Step [1/1], Loss: 0.18493306636810303, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [898/1000], Step [1/1], Loss: 0.18573002517223358, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [899/1000], Step [1/1], Loss: 0.18747474253177643, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [900/1000], Step [1/1], Loss: 0.18841032683849335, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [901/1000], Step [1/1], Loss: 0.18911117315292358, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [902/1000], Step [1/1], Loss: 0.18978217244148254, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [903/1000], Step [1/1], Loss: 0.19042165577411652, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [904/1000], Step [1/1], Loss: 0.1910274624824524, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [905/1000], Step [1/1], Loss: 0.19159528613090515, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [906/1000], Step [1/1], Loss: 0.1921250969171524, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [907/1000], Step [1/1], Loss: 0.19087329506874084, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [908/1000], Step [1/1], Loss: 0.189768448472023, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [909/1000], Step [1/1], Loss: 0.18835031986236572, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [910/1000], Step [1/1], Loss: 0.1864810287952423, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [911/1000], Step [1/1], Loss: 0.18500109016895294, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [912/1000], Step [1/1], Loss: 0.18290816247463226, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [913/1000], Step [1/1], Loss: 0.18252770602703094, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [914/1000], Step [1/1], Loss: 0.1822679489850998, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [915/1000], Step [1/1], Loss: 0.18187947571277618, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [916/1000], Step [1/1], Loss: 0.18155455589294434, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [917/1000], Step [1/1], Loss: 0.18150852620601654, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [918/1000], Step [1/1], Loss: 0.18150511384010315, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [919/1000], Step [1/1], Loss: 0.18153274059295654, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [920/1000], Step [1/1], Loss: 0.18103091418743134, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [921/1000], Step [1/1], Loss: 0.18045540153980255, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [922/1000], Step [1/1], Loss: 0.1799599528312683, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [923/1000], Step [1/1], Loss: 0.17953230440616608, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [924/1000], Step [1/1], Loss: 0.17919814586639404, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [925/1000], Step [1/1], Loss: 0.17890693247318268, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [926/1000], Step [1/1], Loss: 0.1786525845527649, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [927/1000], Step [1/1], Loss: 0.17852430045604706, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [928/1000], Step [1/1], Loss: 0.17820847034454346, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [929/1000], Step [1/1], Loss: 0.17792615294456482, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [930/1000], Step [1/1], Loss: 0.1776755303144455, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [931/1000], Step [1/1], Loss: 0.17716291546821594, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [932/1000], Step [1/1], Loss: 0.17672836780548096, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [933/1000], Step [1/1], Loss: 0.17595070600509644, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [934/1000], Step [1/1], Loss: 0.17466764152050018, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [935/1000], Step [1/1], Loss: 0.17357076704502106, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [936/1000], Step [1/1], Loss: 0.17263051867485046, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [937/1000], Step [1/1], Loss: 0.17182250320911407, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [938/1000], Step [1/1], Loss: 0.17112617194652557, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [939/1000], Step [1/1], Loss: 0.17037498950958252, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [940/1000], Step [1/1], Loss: 0.1701263040304184, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [941/1000], Step [1/1], Loss: 0.17004729807376862, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [942/1000], Step [1/1], Loss: 0.1699811965227127, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [943/1000], Step [1/1], Loss: 0.1708480417728424, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [944/1000], Step [1/1], Loss: 0.17179255187511444, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [945/1000], Step [1/1], Loss: 0.17291033267974854, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [946/1000], Step [1/1], Loss: 0.17361941933631897, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [947/1000], Step [1/1], Loss: 0.1724727898836136, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [948/1000], Step [1/1], Loss: 0.1709652990102768, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [949/1000], Step [1/1], Loss: 0.16967761516571045, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [950/1000], Step [1/1], Loss: 0.168697789311409, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [951/1000], Step [1/1], Loss: 0.1677122861146927, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [952/1000], Step [1/1], Loss: 0.1668461561203003, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [953/1000], Step [1/1], Loss: 0.16608929634094238, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [954/1000], Step [1/1], Loss: 0.16535525023937225, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [955/1000], Step [1/1], Loss: 0.16473495960235596, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [956/1000], Step [1/1], Loss: 0.16433781385421753, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [957/1000], Step [1/1], Loss: 0.16402195394039154, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [958/1000], Step [1/1], Loss: 0.16380758583545685, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [959/1000], Step [1/1], Loss: 0.1636328101158142, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [960/1000], Step [1/1], Loss: 0.1636163741350174, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [961/1000], Step [1/1], Loss: 0.16367146372795105, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [962/1000], Step [1/1], Loss: 0.16382059454917908, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [963/1000], Step [1/1], Loss: 0.16400134563446045, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [964/1000], Step [1/1], Loss: 0.16418328881263733, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [965/1000], Step [1/1], Loss: 0.1643732488155365, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [966/1000], Step [1/1], Loss: 0.16387663781642914, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [967/1000], Step [1/1], Loss: 0.16372816264629364, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [968/1000], Step [1/1], Loss: 0.16316711902618408, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [969/1000], Step [1/1], Loss: 0.16274535655975342, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [970/1000], Step [1/1], Loss: 0.1623687744140625, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [971/1000], Step [1/1], Loss: 0.1620321422815323, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [972/1000], Step [1/1], Loss: 0.1615392416715622, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [973/1000], Step [1/1], Loss: 0.16110213100910187, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [974/1000], Step [1/1], Loss: 0.16071753203868866, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [975/1000], Step [1/1], Loss: 0.15998651087284088, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [976/1000], Step [1/1], Loss: 0.15940387547016144, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [977/1000], Step [1/1], Loss: 0.15864604711532593, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [978/1000], Step [1/1], Loss: 0.15809567272663116, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [979/1000], Step [1/1], Loss: 0.15741971135139465, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [980/1000], Step [1/1], Loss: 0.15658941864967346, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [981/1000], Step [1/1], Loss: 0.15584993362426758, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [982/1000], Step [1/1], Loss: 0.15519052743911743, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [983/1000], Step [1/1], Loss: 0.1546015441417694, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [984/1000], Step [1/1], Loss: 0.15407495200634003, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [985/1000], Step [1/1], Loss: 0.15405425429344177, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [986/1000], Step [1/1], Loss: 0.15431296825408936, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [987/1000], Step [1/1], Loss: 0.15527750551700592, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [988/1000], Step [1/1], Loss: 0.15628167986869812, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [989/1000], Step [1/1], Loss: 0.15719197690486908, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [990/1000], Step [1/1], Loss: 0.15746848285198212, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [991/1000], Step [1/1], Loss: 0.1577485203742981, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [992/1000], Step [1/1], Loss: 0.15802693367004395, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [993/1000], Step [1/1], Loss: 0.15829971432685852, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [994/1000], Step [1/1], Loss: 0.15856412053108215, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [995/1000], Step [1/1], Loss: 0.15869712829589844, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [996/1000], Step [1/1], Loss: 0.15796507894992828, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [997/1000], Step [1/1], Loss: 0.157319575548172, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [998/1000], Step [1/1], Loss: 0.1560935527086258, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [999/1000], Step [1/1], Loss: 0.15503594279289246, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [1000/1000], Step [1/1], Loss: 0.15329621732234955, Test Accuracy: 92.10526315789474%\n"
     ]
    }
   ],
   "source": [
    "#use FD to optimize The Neural network\n",
    "n_epochs =1000\n",
    "NN_IRIS = Neural_Net(input_size=4, hidden_size=10, n_classes=3)\n",
    "N_dim = NN_IRIS.count_parameters()\n",
    "grad_dim = 1\n",
    "\n",
    "#specify we don't need the computation graph to keep track of the gradients, we will use SPSA to update the weights\n",
    "with torch.no_grad():\n",
    "    for param in NN_IRIS.parameters():\n",
    "        param.requires_grad = False\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# learning parameters\n",
    "\n",
    "init_pos = NN_IRIS.get_params()\n",
    "\n",
    "if init_pos.requires_grad:\n",
    "    # Detach the tensor from the computation graph\n",
    "    init_pos = init_pos.detach()\n",
    "if init_pos.is_cuda:\n",
    "    # Move the tensor to the CPU\n",
    "    init_pos = init_pos.cpu()\n",
    "init_pos = init_pos.numpy()\n",
    "\n",
    "FD_optimizer = FD_opt(init_pos,n_perturb=grad_dim,alpha=1e-3,epsilon=1e-5)\n",
    "Adam = AdamOptimizer(init_pos, lr=1e-2, beta1=0.9, beta2=0.99, epsilon=1e-8)\n",
    "\n",
    "test_acc_FD, best_reward_FD = train_online_FD_NN(NN_IRIS,N_dim, n_epochs,  Iris_train_loader, Iris_test_loader, loss, FD_optimizer,Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "PEPG",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "y": [
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          65.78947368421052,
          60.526315789473685,
          57.89473684210526,
          52.63157894736842,
          39.473684210526315,
          36.8421052631579,
          26.31578947368421,
          26.31578947368421,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          21.05263157894737,
          18.42105263157895,
          18.42105263157895,
          18.42105263157895,
          18.42105263157895,
          18.42105263157895,
          15.789473684210526,
          18.42105263157895,
          18.42105263157895,
          18.42105263157895,
          18.42105263157895,
          21.05263157894737,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          21.05263157894737,
          21.05263157894737,
          18.42105263157895,
          18.42105263157895,
          13.157894736842104,
          7.894736842105263,
          7.894736842105263,
          7.894736842105263,
          10.526315789473685,
          13.157894736842104,
          21.05263157894737,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          26.31578947368421,
          26.31578947368421,
          26.31578947368421,
          28.94736842105263,
          28.94736842105263,
          28.94736842105263,
          28.94736842105263,
          28.94736842105263,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          31.57894736842105,
          28.94736842105263,
          28.94736842105263,
          26.31578947368421,
          26.31578947368421,
          23.68421052631579,
          21.05263157894737,
          18.42105263157895,
          18.42105263157895,
          15.789473684210526,
          15.789473684210526,
          15.789473684210526,
          15.789473684210526,
          18.42105263157895,
          18.42105263157895,
          21.05263157894737,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          23.68421052631579,
          18.42105263157895,
          18.42105263157895,
          18.42105263157895,
          18.42105263157895,
          18.42105263157895,
          21.05263157894737,
          21.05263157894737,
          21.05263157894737,
          21.05263157894737,
          21.05263157894737,
          26.31578947368421,
          26.31578947368421,
          31.57894736842105,
          36.8421052631579,
          39.473684210526315,
          34.21052631578947,
          36.8421052631579,
          44.73684210526316,
          55.26315789473684,
          57.89473684210526,
          65.78947368421052,
          68.42105263157895,
          68.42105263157895,
          71.05263157894737,
          71.05263157894737,
          73.6842105263158,
          76.3157894736842,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          71.05263157894737,
          76.3157894736842,
          73.6842105263158,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          81.57894736842105,
          78.94736842105263,
          78.94736842105263,
          76.3157894736842,
          73.6842105263158,
          71.05263157894737,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          68.42105263157895,
          71.05263157894737,
          76.3157894736842,
          81.57894736842105,
          81.57894736842105,
          81.57894736842105,
          81.57894736842105,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          76.3157894736842,
          73.6842105263158,
          73.6842105263158,
          71.05263157894737,
          73.6842105263158,
          76.3157894736842,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          81.57894736842105,
          81.57894736842105,
          81.57894736842105,
          86.84210526315789,
          81.57894736842105,
          78.94736842105263,
          76.3157894736842,
          73.6842105263158,
          73.6842105263158,
          71.05263157894737,
          71.05263157894737,
          71.05263157894737,
          71.05263157894737,
          71.05263157894737,
          68.42105263157895,
          71.05263157894737,
          71.05263157894737,
          71.05263157894737,
          71.05263157894737,
          71.05263157894737,
          71.05263157894737,
          73.6842105263158,
          73.6842105263158,
          73.6842105263158,
          76.3157894736842,
          81.57894736842105,
          86.84210526315789,
          86.84210526315789,
          81.57894736842105,
          81.57894736842105,
          78.94736842105263,
          81.57894736842105,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          78.94736842105263,
          78.94736842105263,
          78.94736842105263,
          81.57894736842105,
          86.84210526315789,
          86.84210526315789,
          84.21052631578948,
          84.21052631578948,
          81.57894736842105,
          81.57894736842105,
          81.57894736842105,
          81.57894736842105,
          81.57894736842105,
          81.57894736842105,
          81.57894736842105,
          81.57894736842105,
          86.84210526315789,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          84.21052631578948,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          84.21052631578948,
          86.84210526315789,
          86.84210526315789,
          89.47368421052632,
          89.47368421052632,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          89.47368421052632,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          89.47368421052632,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          89.47368421052632,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          89.47368421052632,
          92.10526315789474,
          92.10526315789474,
          89.47368421052632,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          86.84210526315789,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          89.47368421052632,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          97.36842105263158,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474,
          92.10526315789474
         ]
        }
       ],
       "layout": {
        "height": 300,
        "margin": {
         "b": 20,
         "l": 20,
         "r": 20,
         "t": 20
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 400,
        "xaxis": {
         "title": {
          "text": "Epochs"
         },
         "type": "log"
        },
        "yaxis": {
         "title": {
          "text": "Accuracy [%]"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(test_acc_FD)), y=test_acc_FD, mode='lines', name='PEPG'))\n",
    "#change theme to white and set the sizer of the plot\n",
    "fig.update_layout(template='plotly_white', width=400, height=300,margin=dict(l=20, r=20, t=20, b=20))\n",
    "fig.update_xaxes(title_text=\"Epochs\",type = 'log')\n",
    "fig.update_yaxes(title_text=\"Accuracy [%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt('data\\\\Results\\\\NN_training\\\\online_training\\\\IRIS\\\\FD-1_test_acc.csv', test_acc_FD, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "{i+1}Epoch [1/100], Step [1/1], Loss: 1.1198173761367798, Test Accuracy: 34.21052631578947%\n",
      "{i+1}Epoch [2/100], Step [1/1], Loss: 1.0918654203414917, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [3/100], Step [1/1], Loss: 1.0703763961791992, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [4/100], Step [1/1], Loss: 1.0582610368728638, Test Accuracy: 31.57894736842105%\n",
      "{i+1}Epoch [5/100], Step [1/1], Loss: 1.0257458686828613, Test Accuracy: 50.0%\n",
      "{i+1}Epoch [6/100], Step [1/1], Loss: 0.9863336682319641, Test Accuracy: 36.8421052631579%\n",
      "{i+1}Epoch [7/100], Step [1/1], Loss: 0.953170895576477, Test Accuracy: 68.42105263157895%\n",
      "{i+1}Epoch [8/100], Step [1/1], Loss: 0.915444552898407, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [9/100], Step [1/1], Loss: 0.8910824656486511, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [10/100], Step [1/1], Loss: 0.8797400593757629, Test Accuracy: 76.3157894736842%\n",
      "{i+1}Epoch [11/100], Step [1/1], Loss: 0.8841671943664551, Test Accuracy: 73.6842105263158%\n",
      "{i+1}Epoch [12/100], Step [1/1], Loss: 0.8710078001022339, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [13/100], Step [1/1], Loss: 0.8518785238265991, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [14/100], Step [1/1], Loss: 0.8585118651390076, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [15/100], Step [1/1], Loss: 0.8347583413124084, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [16/100], Step [1/1], Loss: 0.8243176937103271, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [17/100], Step [1/1], Loss: 0.8198984265327454, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [18/100], Step [1/1], Loss: 0.8111138939857483, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [19/100], Step [1/1], Loss: 0.8107431530952454, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [20/100], Step [1/1], Loss: 0.801902174949646, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [21/100], Step [1/1], Loss: 0.7795853614807129, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [22/100], Step [1/1], Loss: 0.7852373719215393, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [23/100], Step [1/1], Loss: 0.7711833715438843, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [24/100], Step [1/1], Loss: 0.7590989470481873, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [25/100], Step [1/1], Loss: 0.7699411511421204, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [26/100], Step [1/1], Loss: 0.7414758801460266, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [27/100], Step [1/1], Loss: 0.7366110682487488, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [28/100], Step [1/1], Loss: 0.7272998690605164, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [29/100], Step [1/1], Loss: 0.7292540669441223, Test Accuracy: 92.10526315789474%\n",
      "{i+1}Epoch [30/100], Step [1/1], Loss: 0.7148668766021729, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [31/100], Step [1/1], Loss: 0.7175086140632629, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [32/100], Step [1/1], Loss: 0.7103412747383118, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [33/100], Step [1/1], Loss: 0.7036703824996948, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [34/100], Step [1/1], Loss: 0.7022668123245239, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [35/100], Step [1/1], Loss: 0.7022534608840942, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [36/100], Step [1/1], Loss: 0.703223705291748, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [37/100], Step [1/1], Loss: 0.7068923115730286, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [38/100], Step [1/1], Loss: 0.7048551440238953, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [39/100], Step [1/1], Loss: 0.7071554064750671, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [40/100], Step [1/1], Loss: 0.705060601234436, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [41/100], Step [1/1], Loss: 0.6967079043388367, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [42/100], Step [1/1], Loss: 0.7017959356307983, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [43/100], Step [1/1], Loss: 0.6994380950927734, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [44/100], Step [1/1], Loss: 0.6936842203140259, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [45/100], Step [1/1], Loss: 0.6816449165344238, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [46/100], Step [1/1], Loss: 0.685434103012085, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [47/100], Step [1/1], Loss: 0.6790521740913391, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [48/100], Step [1/1], Loss: 0.6768798232078552, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [49/100], Step [1/1], Loss: 0.6744996905326843, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [50/100], Step [1/1], Loss: 0.6745468378067017, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [51/100], Step [1/1], Loss: 0.6736496090888977, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [52/100], Step [1/1], Loss: 0.6730866432189941, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [53/100], Step [1/1], Loss: 0.6732409000396729, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [54/100], Step [1/1], Loss: 0.6729786396026611, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [55/100], Step [1/1], Loss: 0.6694096326828003, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [56/100], Step [1/1], Loss: 0.6669660806655884, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [57/100], Step [1/1], Loss: 0.6650329828262329, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [58/100], Step [1/1], Loss: 0.6687249541282654, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [59/100], Step [1/1], Loss: 0.6614067554473877, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [60/100], Step [1/1], Loss: 0.6614596247673035, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [61/100], Step [1/1], Loss: 0.6594388484954834, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [62/100], Step [1/1], Loss: 0.6570714116096497, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [63/100], Step [1/1], Loss: 0.6535325050354004, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [64/100], Step [1/1], Loss: 0.6565630435943604, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [65/100], Step [1/1], Loss: 0.6563248634338379, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [66/100], Step [1/1], Loss: 0.6534424424171448, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [67/100], Step [1/1], Loss: 0.6525042653083801, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [68/100], Step [1/1], Loss: 0.6528286933898926, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [69/100], Step [1/1], Loss: 0.651257336139679, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [70/100], Step [1/1], Loss: 0.6500709652900696, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [71/100], Step [1/1], Loss: 0.6485945582389832, Test Accuracy: 94.73684210526316%\n",
      "{i+1}Epoch [72/100], Step [1/1], Loss: 0.6461448669433594, Test Accuracy: 100.0%\n",
      "{i+1}Epoch [73/100], Step [1/1], Loss: 0.6439289450645447, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [74/100], Step [1/1], Loss: 0.6429080367088318, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [75/100], Step [1/1], Loss: 0.6401151418685913, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [76/100], Step [1/1], Loss: 0.6381040811538696, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [77/100], Step [1/1], Loss: 0.6354292631149292, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [78/100], Step [1/1], Loss: 0.6332914233207703, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [79/100], Step [1/1], Loss: 0.6313602924346924, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [80/100], Step [1/1], Loss: 0.6294749975204468, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [81/100], Step [1/1], Loss: 0.6292667984962463, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [82/100], Step [1/1], Loss: 0.6280134320259094, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [83/100], Step [1/1], Loss: 0.6248254776000977, Test Accuracy: 81.57894736842105%\n",
      "{i+1}Epoch [84/100], Step [1/1], Loss: 0.6245846152305603, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [85/100], Step [1/1], Loss: 0.622107207775116, Test Accuracy: 84.21052631578948%\n",
      "{i+1}Epoch [86/100], Step [1/1], Loss: 0.6219693422317505, Test Accuracy: 86.84210526315789%\n",
      "{i+1}Epoch [87/100], Step [1/1], Loss: 0.6232409477233887, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [88/100], Step [1/1], Loss: 0.6234809756278992, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [89/100], Step [1/1], Loss: 0.6227037310600281, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [90/100], Step [1/1], Loss: 0.6224323511123657, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [91/100], Step [1/1], Loss: 0.6223950386047363, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [92/100], Step [1/1], Loss: 0.6235191822052002, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [93/100], Step [1/1], Loss: 0.6231210827827454, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [94/100], Step [1/1], Loss: 0.6220685243606567, Test Accuracy: 89.47368421052632%\n",
      "{i+1}Epoch [95/100], Step [1/1], Loss: 0.622368574142456, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [96/100], Step [1/1], Loss: 0.6230577230453491, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [97/100], Step [1/1], Loss: 0.6218859553337097, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [98/100], Step [1/1], Loss: 0.6225300431251526, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [99/100], Step [1/1], Loss: 0.6217664480209351, Test Accuracy: 97.36842105263158%\n",
      "{i+1}Epoch [100/100], Step [1/1], Loss: 0.6218209266662598, Test Accuracy: 97.36842105263158%\n"
     ]
    }
   ],
   "source": [
    "#Using PSO for training the NN\n",
    "n_epochs =100\n",
    "NN_IRIS = Neural_Net(input_size=4, hidden_size=10, n_classes=3)\n",
    "N_dim = NN_IRIS.count_parameters()\n",
    "pop_size = 50\n",
    "#specify we don't need the computation graph to keep track of the gradients, we will use CMAES to update the weights\n",
    "with torch.no_grad():\n",
    "    for param in NN_IRIS.parameters():\n",
    "        param.requires_grad = False\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# learning parameters\n",
    "\n",
    "init_pos = NN_IRIS.get_params()\n",
    "\n",
    "if init_pos.requires_grad:\n",
    "    # Detach the tensor from the computation graph\n",
    "    init_pos = init_pos.detach()\n",
    "if init_pos.is_cuda:\n",
    "    # Move the tensor to the CPU\n",
    "    init_pos = init_pos.cpu()\n",
    "init_pos = init_pos.numpy()\n",
    "\n",
    "#params dictionary\n",
    "upper_bound = 0.2\n",
    "lower_bound = -0.2\n",
    "\n",
    "params = {'c_1': 2, \n",
    "          'c_2': 1,\n",
    "          'w': 0.7,\n",
    "          'Vmax': 0.15*(upper_bound-lower_bound),\n",
    "          'upper_bound': upper_bound,\n",
    "          'lower_bound': lower_bound,\n",
    "          'pop_size' :pop_size,\n",
    "          }\n",
    "\n",
    "init_pos = (upper_bound - lower_bound) * np.random.rand(N_dim, pop_size) + lower_bound\n",
    "V_init = 0.1 * np.random.rand(N_dim, pop_size)\n",
    "PSO_optimizer = PSO_opt(X_init = init_pos,V_init = V_init,params=params)\n",
    "\n",
    "test_acc_PSO,best_reward_PSO = train_online_pop_NN(NN_IRIS, n_epochs,  Iris_train_loader, Iris_test_loader, loss, PSO_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt('data\\\\Results\\\\NN_training\\\\online_training\\\\IRIS\\\\PSO_test_acc.csv', test_acc_PSO, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "PEPG",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          31.57894736842105,
          42.10526315789474,
          28.94736842105263,
          52.63157894736842,
          26.31578947368421,
          23.68421052631579,
          23.68421052631579,
          44.73684210526316,
          31.57894736842105,
          31.57894736842105,
          52.63157894736842,
          50,
          47.36842105263158,
          42.10526315789474,
          50,
          31.57894736842105,
          39.473684210526315,
          34.21052631578947,
          68.42105263157895,
          78.94736842105263,
          94.73684210526316,
          76.3157894736842,
          76.3157894736842,
          94.73684210526316,
          94.73684210526316,
          92.10526315789474,
          89.47368421052632,
          89.47368421052632,
          92.10526315789474,
          92.10526315789474,
          97.36842105263158,
          92.10526315789474,
          97.36842105263158,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158,
          100,
          97.36842105263158,
          89.47368421052632,
          89.47368421052632,
          78.94736842105263,
          78.94736842105263,
          86.84210526315789,
          84.21052631578948,
          84.21052631578948,
          89.47368421052632,
          94.73684210526316,
          97.36842105263158,
          81.57894736842105,
          97.36842105263158,
          92.10526315789474,
          86.84210526315789,
          100,
          97.36842105263158,
          92.10526315789474,
          94.73684210526316,
          97.36842105263158,
          89.47368421052632,
          89.47368421052632,
          97.36842105263158,
          89.47368421052632,
          97.36842105263158,
          94.73684210526316,
          86.84210526315789,
          92.10526315789474,
          81.57894736842105,
          78.94736842105263,
          76.3157894736842,
          76.3157894736842,
          76.3157894736842,
          86.84210526315789,
          86.84210526315789,
          84.21052631578948,
          84.21052631578948,
          81.57894736842105,
          84.21052631578948,
          97.36842105263158,
          76.3157894736842,
          89.47368421052632,
          89.47368421052632,
          86.84210526315789,
          89.47368421052632,
          89.47368421052632,
          78.94736842105263,
          89.47368421052632,
          81.57894736842105,
          89.47368421052632,
          94.73684210526316,
          89.47368421052632,
          84.21052631578948,
          94.73684210526316,
          89.47368421052632,
          94.73684210526316,
          97.36842105263158,
          81.57894736842105,
          89.47368421052632,
          97.36842105263158,
          94.73684210526316,
          97.36842105263158,
          97.36842105263158
         ]
        }
       ],
       "layout": {
        "height": 300,
        "margin": {
         "b": 20,
         "l": 20,
         "r": 20,
         "t": 20
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 400,
        "xaxis": {
         "title": {
          "text": "Epochs"
         },
         "type": "log"
        },
        "yaxis": {
         "title": {
          "text": "Accuracy [%]"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(test_acc_PSO)), y=test_acc_PSO, mode='lines', name='PEPG'))\n",
    "#change theme to white and set the sizer of the plot\n",
    "fig.update_layout(template='plotly_white', width=400, height=300,margin=dict(l=20, r=20, t=20, b=20))\n",
    "fig.update_xaxes(title_text=\"Epochs\",type = 'log')\n",
    "fig.update_yaxes(title_text=\"Accuracy [%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN_MNIST\n",
    "\n",
    "# Initialize a list to store the figures\n",
    "figs = []\n",
    "\n",
    "# Iterate through each model parameter\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:  # Filter out only weight parameters\n",
    "        # Flatten the weights\n",
    "        weights = param.detach().cpu().numpy().flatten()\n",
    "        \n",
    "        # Create a histogram for the weights\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Histogram(x=weights, name=name))\n",
    "        \n",
    "        # Update layout to add titles and improve readability\n",
    "        fig.update_layout(\n",
    "            title=f'Histogram of Weights for Layer: {name}',\n",
    "            xaxis_title='Weight values',\n",
    "            yaxis_title='Frequency',\n",
    "            bargap=0.2\n",
    "        )\n",
    "        \n",
    "        # Append the figure to the list\n",
    "        figs.append(fig)\n",
    "\n",
    "# Show all histograms\n",
    "for fig in figs:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Wine dataset\n",
    "wine_df = pd.read_csv(\"data\\\\WINE\\\\winequality-red.csv\")\n",
    "\n",
    "wine_raw = wine_df.values.astype(np.float32)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.from_numpy(wine_raw[:, :-1])\n",
    "Y = torch.from_numpy(wine_raw[:, -1]).unsqueeze(1)\n",
    "\n",
    "# Create a single dataset\n",
    "full_dataset = Custom_dataset(X, Y)\n",
    "\n",
    "# Split into train and test sets, first set the size of the split\n",
    "train_size = int(0.75 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "# split into train and test sets using pytorch randomsplit\n",
    "\n",
    "Wine_train, Wine_test = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "Wine_train_loader = torch.utils.data.DataLoader(dataset=Wine_train, batch_size=100, shuffle=True)\n",
    "Wine_test_loader = torch.utils.data.DataLoader(dataset=Wine_test, batch_size=100, shuffle=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
