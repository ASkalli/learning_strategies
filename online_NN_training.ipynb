{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from functions_to_optimize import f_rastrigin\n",
    "from CMA_obj import CMA_opt\n",
    "from PEPG_obj import PEPG_opt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from SPSA_obj import SPSA_opt\n",
    "from ADAM_opt import AdamOptimizer\n",
    "from PSO_obj import PSO_opt\n",
    "from scipy.interpolate import interp1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Online training of Neural Networks\n",
    "\n",
    "## 1) Defining a simple neural network\n",
    "- Define the feed forward NN class\n",
    "- Define the linear classifier class for comparison\n",
    "- Define a custom dataset class to help interfacing with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a simple single layer feed forward NN with ReLU activation and adjustable hidden layer size\n",
    "class Neural_Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_classes):\n",
    "        \"init method that defines the NN architecture and inherits from nn.Module\"\n",
    "        super(Neural_Net, self).__init__()\n",
    "        \n",
    "        self.NN_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_classes),\n",
    "            #nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        self.num_params = sum(p.data.numel() for p in self.parameters())\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"forward pass\"\n",
    "        logits = self.NN_stack(X)\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "    def reset_weights(self):\n",
    "        \"method to reset the weights of the NN\"\n",
    "        for layer in self.NN_stack:\n",
    "            if isinstance(layer,nn.Linear):\n",
    "                layer.reset_parameters()\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = True\n",
    "                \n",
    "    def get_params(self):\n",
    "        \"Method to get parameters from the neural network\"\n",
    "        params_list = []\n",
    "        \n",
    "        for param in self.parameters():\n",
    "            params_list.append(param.view(-1))\n",
    "        \n",
    "        full_params = torch.cat(params_list)\n",
    "        return full_params\n",
    "    \n",
    "    def set_params(self,params_to_send):\n",
    "        \"Method to set parameters params in the neural network for online training. params_to_send is a column vector \"\n",
    "        idx_prev = 0\n",
    "        for param in self.parameters():\n",
    "           n_params = param.data.numel()\n",
    "           new_param =  torch.reshape(torch.from_numpy(params_to_send[idx_prev: idx_prev + n_params ]),shape=param.data.shape)\n",
    "           param.data.copy_(new_param)\n",
    "           idx_prev += n_params\n",
    "    \n",
    "    def forward_pass_params(self,params_to_send,X):\n",
    "        \"This method is a forward pass that also takes in the parameters of the neural network as a variable, to use in online learning\"\n",
    "        self.set_params(params_to_send)\n",
    "        logits = self.NN_stack(X)\n",
    "        return logits\n",
    "        \n",
    "\n",
    "#class for a linear classifier\n",
    "\n",
    "class Lin_classifier(nn.Module):\n",
    "    def __init__(self, input_size, n_classes):\n",
    "        super(Lin_classifier,self).__init__()\n",
    "        \n",
    "        self.NN_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_size, n_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self,X):\n",
    "        logits = self.NN_stack(X)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "\n",
    "# custom dataset class for datasets that are not included in torchvision like wine or IRIS\n",
    "\n",
    "class Custom_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define some helper functions to train the model in a loop\n",
    "- Define a function that quantizes a given model to study the impact of parameter resolution on performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training loop od pytorch NN as a function\n",
    "\n",
    "def train_pytorch_NN(model, n_epochs, train_loader, test_loader, loss, optimizer):\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"Using {device} device\")\n",
    "    print(model)\n",
    "    \n",
    "    #array to store the accuracy of the model\n",
    "    accuracy_list = []\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for i, (images,labels) in enumerate(train_loader):\n",
    "            #move data to gpu for faster processing\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            #forward pass\n",
    "            Y_pred = model.forward(images)\n",
    "            loss_value = loss(Y_pred,labels)\n",
    "            #backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            #print accuracy every 100 steps for the test set\n",
    "            if (i+1) % 100 == 0:\n",
    "                model.eval()\n",
    "                correct = 0 \n",
    "                total = 0\n",
    "                for images, labels in test_loader:\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    Y_pred = model.forward(images)\n",
    "                    _, predicted = torch.max(Y_pred.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                accuracy = ( 100*correct/total)\n",
    "                accuracy_list.append(accuracy)\n",
    "                print(f'Epoch [{epoch+1}/{n_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss_value.item()}, Test Accuracy: {accuracy}%')\n",
    "    return accuracy_list\n",
    "\n",
    "\n",
    "def train_online_pop_NN(model, n_epochs, train_loader, test_loader, loss, optimizer):\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"Using {device} device\")\n",
    "    print(model)\n",
    "    \n",
    "    best_reward = np.ones([n_epochs,1])\n",
    "    rewards = []\n",
    "    for epoch in range(n_epochs):\n",
    "        model.eval()\n",
    "        for i, (features,labels) in enumerate(train_loader):\n",
    "            \n",
    "            coordinates = optimizer.ask()\n",
    "            \n",
    "            for k in range(coordinates.shape[0]):\n",
    "                if device == 'cuda':\n",
    "                    features = features.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    Y_pred = model.forward_pass_params(coordinates[k,:],features)\n",
    "                if device == 'cpu':\n",
    "                    Y_pred = model.forward_pass_params(coordinates[k,:],features)    \n",
    "                loss_value = loss(Y_pred,labels)\n",
    "                rewards.append(loss_value)\n",
    "\n",
    "            rewards = np.ndarray(rewards)[:,np.newaxis]\n",
    "            optimizer.tell(rewards)\n",
    "            best_params = coordinates[:,np.argmin(rewards)]\n",
    "            \n",
    "                #print accuracy every 100 steps for the test set\n",
    "            if (i+1) % 100 == 0:\n",
    "                model.eval()\n",
    "                correct = 0 \n",
    "                total = 0\n",
    "                for features, labels in test_loader:\n",
    "                    features = features.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    Y_pred = model.forward_pass_params(best_params,features)\n",
    "                    _, predicted = torch.max(Y_pred.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                accuracy = ( 100*correct/total)\n",
    "                accuracy_list.append(accuracy)\n",
    "                print(f'Epoch [{epoch+1}/{n_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss_value.item()}, Test Accuracy: {accuracy}%')\n",
    "    return accuracy_list\n",
    "    \n",
    "def quantize_model(model,quant_levels):\n",
    "    \"function to quantize weights of model on a layer by layer basis, quant_levels is the number of quantization steps\"\n",
    "    with torch.no_grad():\n",
    "            \n",
    "        for param in model.parameters():\n",
    "            min_param = param.min()\n",
    "            max_param = param.max()\n",
    "            step = (max_param - min_param ) / (quant_levels)\n",
    "            \n",
    "            n_steps = ((param - min_param) / step).round()\n",
    "            \n",
    "            quantized_value = min_param + step * n_steps\n",
    "            \n",
    "            param.copy_(quantized_value)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets\n",
    "X is the input, Y the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "MNIST_train = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "MNIST_test = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader_MNIST = torch.utils.data.DataLoader(dataset=MNIST_train, batch_size=100, shuffle=True)\n",
    "test_loader_MNIST = torch.utils.data.DataLoader(dataset=MNIST_test, batch_size=100, shuffle=False)\n",
    "\n",
    "X_train_MNIST, Y_train_MNIST = next(iter(train_loader_MNIST))\n",
    "X_test_MNIST, Y_test_MNIST = next(iter(test_loader_MNIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine dataset\n",
    "wine_df = pd.read_csv(\"data\\\\WINE\\\\winequality-red.csv\")\n",
    "\n",
    "wine_raw = wine_df.values.astype(np.float32)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.from_numpy(wine_raw[:, :-1])\n",
    "Y = torch.from_numpy(wine_raw[:, -1]).unsqueeze(1)\n",
    "\n",
    "# Create a single dataset\n",
    "full_dataset = Custom_dataset(X, Y)\n",
    "\n",
    "# Split into train and test sets, first set the size of the split\n",
    "train_size = int(0.75 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "# split into train and test sets using pytorch randomsplit\n",
    "\n",
    "Wine_train, Wine_test = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "Wine_train_loader = torch.utils.data.DataLoader(dataset=Wine_train, batch_size=100, shuffle=True)\n",
    "Wine_test_loader = torch.utils.data.DataLoader(dataset=Wine_test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iris dataset\n",
    "iris_df = pd.read_csv(\"data\\\\IRIS\\\\iris.csv\")\n",
    "# convert the last column \n",
    "\n",
    "\n",
    "iris_raw = iris_df.values\n",
    "\n",
    "for i in range(len(iris_raw)):\n",
    "    if iris_raw[i,-1] == 'Iris-setosa':\n",
    "        iris_raw[i,-1] = 0\n",
    "    elif iris_raw[i,-1] == 'Iris-versicolor':\n",
    "        iris_raw[i,-1] = 1\n",
    "    else:\n",
    "        iris_raw[i,-1] = 2\n",
    "        \n",
    "iris_raw = iris_raw.astype(np.float32)\n",
    "#iris raw needs to be shuffled randomly because the data is ordered by class\n",
    "np.random.shuffle(iris_raw)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.from_numpy(iris_raw[:, :-1])\n",
    "Y = torch.from_numpy(iris_raw[:, -1]).unsqueeze(1)\n",
    "\n",
    "# Create a single dataset\n",
    "full_dataset = Custom_dataset(X, Y)\n",
    "\n",
    "# Split into train and test sets, first set the size of the split\n",
    "train_size = int(0.75 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "# split into train and test sets using pytorch randomsplit\n",
    "Iris_train, Iris_test = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "Iris_train_loader = torch.utils.data.DataLoader(dataset=Iris_train, batch_size=train_size, shuffle=True)\n",
    "Iris_test_loader = torch.utils.data.DataLoader(dataset=Iris_test, batch_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train a feed forward neural network of 100 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/10], Step [100/600], Loss: 0.4191577136516571, Test Accuracy: 88.8%\n",
      "Epoch [1/10], Step [200/600], Loss: 0.2891732454299927, Test Accuracy: 90.58%\n",
      "Epoch [1/10], Step [300/600], Loss: 0.2360798418521881, Test Accuracy: 91.81%\n",
      "Epoch [1/10], Step [400/600], Loss: 0.25218361616134644, Test Accuracy: 91.74%\n",
      "Epoch [1/10], Step [500/600], Loss: 0.26800140738487244, Test Accuracy: 92.99%\n",
      "Epoch [1/10], Step [600/600], Loss: 0.14968359470367432, Test Accuracy: 93.45%\n",
      "Epoch [2/10], Step [100/600], Loss: 0.11221376061439514, Test Accuracy: 93.85%\n",
      "Epoch [2/10], Step [200/600], Loss: 0.13010767102241516, Test Accuracy: 93.96%\n",
      "Epoch [2/10], Step [300/600], Loss: 0.21192686259746552, Test Accuracy: 94.36%\n",
      "Epoch [2/10], Step [400/600], Loss: 0.18822617828845978, Test Accuracy: 94.59%\n",
      "Epoch [2/10], Step [500/600], Loss: 0.1198585256934166, Test Accuracy: 94.69%\n",
      "Epoch [2/10], Step [600/600], Loss: 0.24072428047657013, Test Accuracy: 95.05%\n",
      "Epoch [3/10], Step [100/600], Loss: 0.16364526748657227, Test Accuracy: 95.36%\n",
      "Epoch [3/10], Step [200/600], Loss: 0.17755378782749176, Test Accuracy: 95.57%\n",
      "Epoch [3/10], Step [300/600], Loss: 0.13216984272003174, Test Accuracy: 95.81%\n",
      "Epoch [3/10], Step [400/600], Loss: 0.09633275866508484, Test Accuracy: 96.1%\n",
      "Epoch [3/10], Step [500/600], Loss: 0.21352727711200714, Test Accuracy: 95.91%\n",
      "Epoch [3/10], Step [600/600], Loss: 0.09706266224384308, Test Accuracy: 95.92%\n",
      "Epoch [4/10], Step [100/600], Loss: 0.06310775876045227, Test Accuracy: 96.22%\n",
      "Epoch [4/10], Step [200/600], Loss: 0.09643100947141647, Test Accuracy: 96.35%\n",
      "Epoch [4/10], Step [300/600], Loss: 0.039607010781764984, Test Accuracy: 96.54%\n",
      "Epoch [4/10], Step [400/600], Loss: 0.163185715675354, Test Accuracy: 96.61%\n",
      "Epoch [4/10], Step [500/600], Loss: 0.19410640001296997, Test Accuracy: 96.64%\n",
      "Epoch [4/10], Step [600/600], Loss: 0.12075941264629364, Test Accuracy: 96.77%\n",
      "Epoch [5/10], Step [100/600], Loss: 0.03731480985879898, Test Accuracy: 96.83%\n",
      "Epoch [5/10], Step [200/600], Loss: 0.039435774087905884, Test Accuracy: 96.76%\n",
      "Epoch [5/10], Step [300/600], Loss: 0.05017924681305885, Test Accuracy: 96.94%\n",
      "Epoch [5/10], Step [400/600], Loss: 0.08146609365940094, Test Accuracy: 96.72%\n",
      "Epoch [5/10], Step [500/600], Loss: 0.11106181144714355, Test Accuracy: 97.04%\n",
      "Epoch [5/10], Step [600/600], Loss: 0.04489057511091232, Test Accuracy: 96.87%\n",
      "Epoch [6/10], Step [100/600], Loss: 0.0845000147819519, Test Accuracy: 97.25%\n",
      "Epoch [6/10], Step [200/600], Loss: 0.05449331924319267, Test Accuracy: 97.22%\n",
      "Epoch [6/10], Step [300/600], Loss: 0.12179753184318542, Test Accuracy: 97.04%\n",
      "Epoch [6/10], Step [400/600], Loss: 0.10198420286178589, Test Accuracy: 97.09%\n",
      "Epoch [6/10], Step [500/600], Loss: 0.11826740205287933, Test Accuracy: 97.12%\n",
      "Epoch [6/10], Step [600/600], Loss: 0.046261925250291824, Test Accuracy: 97.32%\n",
      "Epoch [7/10], Step [100/600], Loss: 0.0346098430454731, Test Accuracy: 97.52%\n",
      "Epoch [7/10], Step [200/600], Loss: 0.12914933264255524, Test Accuracy: 97.36%\n",
      "Epoch [7/10], Step [300/600], Loss: 0.03643062338232994, Test Accuracy: 97.46%\n",
      "Epoch [7/10], Step [400/600], Loss: 0.04859505966305733, Test Accuracy: 97.33%\n",
      "Epoch [7/10], Step [500/600], Loss: 0.05823959410190582, Test Accuracy: 97.33%\n",
      "Epoch [7/10], Step [600/600], Loss: 0.03990740701556206, Test Accuracy: 97.43%\n",
      "Epoch [8/10], Step [100/600], Loss: 0.08517850190401077, Test Accuracy: 97.27%\n",
      "Epoch [8/10], Step [200/600], Loss: 0.05458435043692589, Test Accuracy: 97.38%\n",
      "Epoch [8/10], Step [300/600], Loss: 0.015978161245584488, Test Accuracy: 97.59%\n",
      "Epoch [8/10], Step [400/600], Loss: 0.01754128374159336, Test Accuracy: 97.45%\n",
      "Epoch [8/10], Step [500/600], Loss: 0.022750694304704666, Test Accuracy: 97.54%\n",
      "Epoch [8/10], Step [600/600], Loss: 0.08753623813390732, Test Accuracy: 97.58%\n",
      "Epoch [9/10], Step [100/600], Loss: 0.05188853293657303, Test Accuracy: 97.58%\n",
      "Epoch [9/10], Step [200/600], Loss: 0.03642066568136215, Test Accuracy: 97.48%\n",
      "Epoch [9/10], Step [300/600], Loss: 0.0556432344019413, Test Accuracy: 97.43%\n",
      "Epoch [9/10], Step [400/600], Loss: 0.033705104142427444, Test Accuracy: 97.43%\n",
      "Epoch [9/10], Step [500/600], Loss: 0.08223950117826462, Test Accuracy: 97.54%\n",
      "Epoch [9/10], Step [600/600], Loss: 0.009314427152276039, Test Accuracy: 97.58%\n",
      "Epoch [10/10], Step [100/600], Loss: 0.01853940449655056, Test Accuracy: 97.61%\n",
      "Epoch [10/10], Step [200/600], Loss: 0.041776467114686966, Test Accuracy: 97.37%\n",
      "Epoch [10/10], Step [300/600], Loss: 0.007774787023663521, Test Accuracy: 97.55%\n",
      "Epoch [10/10], Step [400/600], Loss: 0.029170921072363853, Test Accuracy: 97.35%\n",
      "Epoch [10/10], Step [500/600], Loss: 0.02173151820898056, Test Accuracy: 97.69%\n",
      "Epoch [10/10], Step [600/600], Loss: 0.04369497671723366, Test Accuracy: 97.68%\n"
     ]
    }
   ],
   "source": [
    "#We Now create an instance of the NN class and move if to the GPU if available\n",
    "n_neurons = 100\n",
    "NN_MNIST = Neural_Net(input_size=28*28, hidden_size=n_neurons, n_classes=10)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(NN_MNIST.parameters(), lr=0.001)\n",
    "\n",
    "#training the full NN\n",
    "n_epochs = 10\n",
    "test_acc = train_pytorch_NN(NN_MNIST, n_epochs, train_loader_MNIST, test_loader_MNIST, loss, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train an extreme learning machine of the same size, we can just set the input weights and biases to not uses gradients and we reset them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/10], Step [100/600], Loss: 1.271210789680481, Test Accuracy: 76.16%\n",
      "Epoch [1/10], Step [200/600], Loss: 1.0079594850540161, Test Accuracy: 79.18%\n",
      "Epoch [1/10], Step [300/600], Loss: 0.9305825233459473, Test Accuracy: 80.97%\n",
      "Epoch [1/10], Step [400/600], Loss: 0.6689517498016357, Test Accuracy: 82.45%\n",
      "Epoch [1/10], Step [500/600], Loss: 0.535764217376709, Test Accuracy: 83.31%\n",
      "Epoch [1/10], Step [600/600], Loss: 0.694669246673584, Test Accuracy: 84.08%\n",
      "Epoch [2/10], Step [100/600], Loss: 0.7473541498184204, Test Accuracy: 84.07%\n",
      "Epoch [2/10], Step [200/600], Loss: 0.6482231616973877, Test Accuracy: 84.73%\n",
      "Epoch [2/10], Step [300/600], Loss: 0.6407319903373718, Test Accuracy: 84.9%\n",
      "Epoch [2/10], Step [400/600], Loss: 0.5210379958152771, Test Accuracy: 85.06%\n",
      "Epoch [2/10], Step [500/600], Loss: 0.5508687496185303, Test Accuracy: 85.36%\n",
      "Epoch [2/10], Step [600/600], Loss: 0.7575923204421997, Test Accuracy: 85.47%\n",
      "Epoch [3/10], Step [100/600], Loss: 0.5159051418304443, Test Accuracy: 85.71%\n",
      "Epoch [3/10], Step [200/600], Loss: 0.4546104371547699, Test Accuracy: 85.77%\n",
      "Epoch [3/10], Step [300/600], Loss: 0.42524319887161255, Test Accuracy: 85.89%\n",
      "Epoch [3/10], Step [400/600], Loss: 0.43329256772994995, Test Accuracy: 86.05%\n",
      "Epoch [3/10], Step [500/600], Loss: 0.35817721486091614, Test Accuracy: 86.07%\n",
      "Epoch [3/10], Step [600/600], Loss: 0.5086542963981628, Test Accuracy: 86.1%\n",
      "Epoch [4/10], Step [100/600], Loss: 0.4337760806083679, Test Accuracy: 86.25%\n",
      "Epoch [4/10], Step [200/600], Loss: 0.43588975071907043, Test Accuracy: 86.16%\n",
      "Epoch [4/10], Step [300/600], Loss: 0.541317343711853, Test Accuracy: 86.4%\n",
      "Epoch [4/10], Step [400/600], Loss: 0.4092230200767517, Test Accuracy: 86.46%\n",
      "Epoch [4/10], Step [500/600], Loss: 0.5588963031768799, Test Accuracy: 86.45%\n",
      "Epoch [4/10], Step [600/600], Loss: 0.5665614604949951, Test Accuracy: 86.34%\n",
      "Epoch [5/10], Step [100/600], Loss: 0.436335951089859, Test Accuracy: 86.44%\n",
      "Epoch [5/10], Step [200/600], Loss: 0.4773801565170288, Test Accuracy: 86.67%\n",
      "Epoch [5/10], Step [300/600], Loss: 0.42667487263679504, Test Accuracy: 86.6%\n",
      "Epoch [5/10], Step [400/600], Loss: 0.4829382598400116, Test Accuracy: 86.73%\n",
      "Epoch [5/10], Step [500/600], Loss: 0.42458972334861755, Test Accuracy: 86.48%\n",
      "Epoch [5/10], Step [600/600], Loss: 0.5022169351577759, Test Accuracy: 86.73%\n",
      "Epoch [6/10], Step [100/600], Loss: 0.33781906962394714, Test Accuracy: 86.6%\n",
      "Epoch [6/10], Step [200/600], Loss: 0.43451327085494995, Test Accuracy: 86.56%\n",
      "Epoch [6/10], Step [300/600], Loss: 0.36615899205207825, Test Accuracy: 86.95%\n",
      "Epoch [6/10], Step [400/600], Loss: 0.4231177568435669, Test Accuracy: 86.77%\n",
      "Epoch [6/10], Step [500/600], Loss: 0.3536311388015747, Test Accuracy: 86.77%\n",
      "Epoch [6/10], Step [600/600], Loss: 0.32306089997291565, Test Accuracy: 86.76%\n",
      "Epoch [7/10], Step [100/600], Loss: 0.4041944444179535, Test Accuracy: 86.99%\n",
      "Epoch [7/10], Step [200/600], Loss: 0.44493284821510315, Test Accuracy: 86.85%\n",
      "Epoch [7/10], Step [300/600], Loss: 0.5516194701194763, Test Accuracy: 86.75%\n",
      "Epoch [7/10], Step [400/600], Loss: 0.34245529770851135, Test Accuracy: 86.97%\n",
      "Epoch [7/10], Step [500/600], Loss: 0.4305122494697571, Test Accuracy: 86.81%\n",
      "Epoch [7/10], Step [600/600], Loss: 0.49987292289733887, Test Accuracy: 86.92%\n",
      "Epoch [8/10], Step [100/600], Loss: 0.41889968514442444, Test Accuracy: 86.94%\n",
      "Epoch [8/10], Step [200/600], Loss: 0.41977497935295105, Test Accuracy: 86.84%\n",
      "Epoch [8/10], Step [300/600], Loss: 0.45990875363349915, Test Accuracy: 87.02%\n",
      "Epoch [8/10], Step [400/600], Loss: 0.3747079372406006, Test Accuracy: 86.89%\n",
      "Epoch [8/10], Step [500/600], Loss: 0.42924433946609497, Test Accuracy: 86.95%\n",
      "Epoch [8/10], Step [600/600], Loss: 0.463090181350708, Test Accuracy: 86.96%\n",
      "Epoch [9/10], Step [100/600], Loss: 0.609661340713501, Test Accuracy: 86.87%\n",
      "Epoch [9/10], Step [200/600], Loss: 0.3755240738391876, Test Accuracy: 86.82%\n",
      "Epoch [9/10], Step [300/600], Loss: 0.4303557574748993, Test Accuracy: 87.02%\n",
      "Epoch [9/10], Step [400/600], Loss: 0.4602879583835602, Test Accuracy: 87.06%\n",
      "Epoch [9/10], Step [500/600], Loss: 0.4388773441314697, Test Accuracy: 86.77%\n",
      "Epoch [9/10], Step [600/600], Loss: 0.3308076858520508, Test Accuracy: 86.89%\n",
      "Epoch [10/10], Step [100/600], Loss: 0.5642014741897583, Test Accuracy: 87.01%\n",
      "Epoch [10/10], Step [200/600], Loss: 0.5596432089805603, Test Accuracy: 87.04%\n",
      "Epoch [10/10], Step [300/600], Loss: 0.6000545620918274, Test Accuracy: 86.9%\n",
      "Epoch [10/10], Step [400/600], Loss: 0.6394399404525757, Test Accuracy: 86.84%\n",
      "Epoch [10/10], Step [500/600], Loss: 0.33618834614753723, Test Accuracy: 86.89%\n",
      "Epoch [10/10], Step [600/600], Loss: 0.6121709942817688, Test Accuracy: 86.99%\n"
     ]
    }
   ],
   "source": [
    "# Training loop for MNIST but without training the input layer (extreme learning machine)\n",
    "\n",
    "#first reset the model we trained before\n",
    "NN_MNIST.reset_weights()\n",
    "\n",
    "#set the input layer to not require gradients\n",
    "NN_MNIST.NN_stack[1].weight.requires_grad = False\n",
    "NN_MNIST.NN_stack[1].bias.requires_grad = False\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(NN_MNIST.parameters(), lr=0.01)\n",
    "\n",
    "n_epochs = 10\n",
    "test_acc_ELM = train_pytorch_NN(NN_MNIST, n_epochs, train_loader_MNIST, test_loader_MNIST, loss, optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For reference we train a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Lin_classifier(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/10], Step [100/600], Loss: 0.8847620487213135, Test Accuracy: 83.91%\n",
      "Epoch [1/10], Step [200/600], Loss: 0.536886990070343, Test Accuracy: 87.79%\n",
      "Epoch [1/10], Step [300/600], Loss: 0.5970674753189087, Test Accuracy: 88.8%\n",
      "Epoch [1/10], Step [400/600], Loss: 0.4797896444797516, Test Accuracy: 89.85%\n",
      "Epoch [1/10], Step [500/600], Loss: 0.36830952763557434, Test Accuracy: 90.29%\n",
      "Epoch [1/10], Step [600/600], Loss: 0.49706733226776123, Test Accuracy: 90.58%\n",
      "Epoch [2/10], Step [100/600], Loss: 0.47784319519996643, Test Accuracy: 90.75%\n",
      "Epoch [2/10], Step [200/600], Loss: 0.2628822326660156, Test Accuracy: 91.16%\n",
      "Epoch [2/10], Step [300/600], Loss: 0.29350030422210693, Test Accuracy: 91.19%\n",
      "Epoch [2/10], Step [400/600], Loss: 0.3803710639476776, Test Accuracy: 91.34%\n",
      "Epoch [2/10], Step [500/600], Loss: 0.4366645812988281, Test Accuracy: 91.52%\n",
      "Epoch [2/10], Step [600/600], Loss: 0.29885104298591614, Test Accuracy: 91.42%\n",
      "Epoch [3/10], Step [100/600], Loss: 0.32246944308280945, Test Accuracy: 91.53%\n",
      "Epoch [3/10], Step [200/600], Loss: 0.41688841581344604, Test Accuracy: 91.73%\n",
      "Epoch [3/10], Step [300/600], Loss: 0.181418776512146, Test Accuracy: 91.64%\n",
      "Epoch [3/10], Step [400/600], Loss: 0.21438440680503845, Test Accuracy: 91.83%\n",
      "Epoch [3/10], Step [500/600], Loss: 0.34096482396125793, Test Accuracy: 91.76%\n",
      "Epoch [3/10], Step [600/600], Loss: 0.43503493070602417, Test Accuracy: 92.01%\n",
      "Epoch [4/10], Step [100/600], Loss: 0.2546902000904083, Test Accuracy: 92.0%\n",
      "Epoch [4/10], Step [200/600], Loss: 0.385076642036438, Test Accuracy: 92.04%\n",
      "Epoch [4/10], Step [300/600], Loss: 0.2952694892883301, Test Accuracy: 92.13%\n",
      "Epoch [4/10], Step [400/600], Loss: 0.30270111560821533, Test Accuracy: 92.39%\n",
      "Epoch [4/10], Step [500/600], Loss: 0.30215251445770264, Test Accuracy: 92.19%\n",
      "Epoch [4/10], Step [600/600], Loss: 0.17713241279125214, Test Accuracy: 92.29%\n",
      "Epoch [5/10], Step [100/600], Loss: 0.26535820960998535, Test Accuracy: 92.1%\n",
      "Epoch [5/10], Step [200/600], Loss: 0.18384608626365662, Test Accuracy: 92.4%\n",
      "Epoch [5/10], Step [300/600], Loss: 0.20603719353675842, Test Accuracy: 92.28%\n",
      "Epoch [5/10], Step [400/600], Loss: 0.5280998349189758, Test Accuracy: 92.33%\n",
      "Epoch [5/10], Step [500/600], Loss: 0.36691516637802124, Test Accuracy: 92.38%\n",
      "Epoch [5/10], Step [600/600], Loss: 0.25297802686691284, Test Accuracy: 92.36%\n",
      "Epoch [6/10], Step [100/600], Loss: 0.16289499402046204, Test Accuracy: 92.42%\n",
      "Epoch [6/10], Step [200/600], Loss: 0.2011324167251587, Test Accuracy: 92.29%\n",
      "Epoch [6/10], Step [300/600], Loss: 0.2491452991962433, Test Accuracy: 92.35%\n",
      "Epoch [6/10], Step [400/600], Loss: 0.2584660053253174, Test Accuracy: 92.39%\n",
      "Epoch [6/10], Step [500/600], Loss: 0.27964481711387634, Test Accuracy: 92.46%\n",
      "Epoch [6/10], Step [600/600], Loss: 0.12723450362682343, Test Accuracy: 92.51%\n",
      "Epoch [7/10], Step [100/600], Loss: 0.1603952795267105, Test Accuracy: 92.44%\n",
      "Epoch [7/10], Step [200/600], Loss: 0.14012007415294647, Test Accuracy: 92.48%\n",
      "Epoch [7/10], Step [300/600], Loss: 0.26934877038002014, Test Accuracy: 92.44%\n",
      "Epoch [7/10], Step [400/600], Loss: 0.20182499289512634, Test Accuracy: 92.51%\n",
      "Epoch [7/10], Step [500/600], Loss: 0.16752323508262634, Test Accuracy: 92.36%\n",
      "Epoch [7/10], Step [600/600], Loss: 0.19080768525600433, Test Accuracy: 92.53%\n",
      "Epoch [8/10], Step [100/600], Loss: 0.21213626861572266, Test Accuracy: 92.52%\n",
      "Epoch [8/10], Step [200/600], Loss: 0.32276129722595215, Test Accuracy: 92.64%\n",
      "Epoch [8/10], Step [300/600], Loss: 0.2668028771877289, Test Accuracy: 92.37%\n",
      "Epoch [8/10], Step [400/600], Loss: 0.25362905859947205, Test Accuracy: 92.41%\n",
      "Epoch [8/10], Step [500/600], Loss: 0.2332860380411148, Test Accuracy: 92.5%\n",
      "Epoch [8/10], Step [600/600], Loss: 0.28892314434051514, Test Accuracy: 92.81%\n",
      "Epoch [9/10], Step [100/600], Loss: 0.13755738735198975, Test Accuracy: 92.57%\n",
      "Epoch [9/10], Step [200/600], Loss: 0.3926294445991516, Test Accuracy: 92.46%\n",
      "Epoch [9/10], Step [300/600], Loss: 0.27095136046409607, Test Accuracy: 92.57%\n",
      "Epoch [9/10], Step [400/600], Loss: 0.3646095395088196, Test Accuracy: 92.55%\n",
      "Epoch [9/10], Step [500/600], Loss: 0.2833889126777649, Test Accuracy: 92.55%\n",
      "Epoch [9/10], Step [600/600], Loss: 0.16376160085201263, Test Accuracy: 92.6%\n",
      "Epoch [10/10], Step [100/600], Loss: 0.14428211748600006, Test Accuracy: 92.54%\n",
      "Epoch [10/10], Step [200/600], Loss: 0.12190684676170349, Test Accuracy: 92.55%\n",
      "Epoch [10/10], Step [300/600], Loss: 0.2766217291355133, Test Accuracy: 92.69%\n",
      "Epoch [10/10], Step [400/600], Loss: 0.31978359818458557, Test Accuracy: 92.58%\n",
      "Epoch [10/10], Step [500/600], Loss: 0.4104248285293579, Test Accuracy: 92.72%\n",
      "Epoch [10/10], Step [600/600], Loss: 0.25737717747688293, Test Accuracy: 92.55%\n"
     ]
    }
   ],
   "source": [
    "#Train the linear model for reference\n",
    "Linear_model = Lin_classifier(input_size=28*28,n_classes=10)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(Linear_model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 10\n",
    "test_acc_lin = train_pytorch_NN(Linear_model, n_epochs, train_loader_MNIST, test_loader_MNIST, loss, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Full NN",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59
         ],
         "y": [
          88.8,
          90.58,
          91.81,
          91.74,
          92.99,
          93.45,
          93.85,
          93.96,
          94.36,
          94.59,
          94.69,
          95.05,
          95.36,
          95.57,
          95.81,
          96.1,
          95.91,
          95.92,
          96.22,
          96.35,
          96.54,
          96.61,
          96.64,
          96.77,
          96.83,
          96.76,
          96.94,
          96.72,
          97.04,
          96.87,
          97.25,
          97.22,
          97.04,
          97.09,
          97.12,
          97.32,
          97.52,
          97.36,
          97.46,
          97.33,
          97.33,
          97.43,
          97.27,
          97.38,
          97.59,
          97.45,
          97.54,
          97.58,
          97.58,
          97.48,
          97.43,
          97.43,
          97.54,
          97.58,
          97.61,
          97.37,
          97.55,
          97.35,
          97.69,
          97.68
         ]
        },
        {
         "mode": "lines",
         "name": "ELM",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59
         ],
         "y": [
          76.16,
          79.18,
          80.97,
          82.45,
          83.31,
          84.08,
          84.07,
          84.73,
          84.9,
          85.06,
          85.36,
          85.47,
          85.71,
          85.77,
          85.89,
          86.05,
          86.07,
          86.1,
          86.25,
          86.16,
          86.4,
          86.46,
          86.45,
          86.34,
          86.44,
          86.67,
          86.6,
          86.73,
          86.48,
          86.73,
          86.6,
          86.56,
          86.95,
          86.77,
          86.77,
          86.76,
          86.99,
          86.85,
          86.75,
          86.97,
          86.81,
          86.92,
          86.94,
          86.84,
          87.02,
          86.89,
          86.95,
          86.96,
          86.87,
          86.82,
          87.02,
          87.06,
          86.77,
          86.89,
          87.01,
          87.04,
          86.9,
          86.84,
          86.89,
          86.99
         ]
        },
        {
         "mode": "lines",
         "name": "Linear",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59
         ],
         "y": [
          83.91,
          87.79,
          88.8,
          89.85,
          90.29,
          90.58,
          90.75,
          91.16,
          91.19,
          91.34,
          91.52,
          91.42,
          91.53,
          91.73,
          91.64,
          91.83,
          91.76,
          92.01,
          92,
          92.04,
          92.13,
          92.39,
          92.19,
          92.29,
          92.1,
          92.4,
          92.28,
          92.33,
          92.38,
          92.36,
          92.42,
          92.29,
          92.35,
          92.39,
          92.46,
          92.51,
          92.44,
          92.48,
          92.44,
          92.51,
          92.36,
          92.53,
          92.52,
          92.64,
          92.37,
          92.41,
          92.5,
          92.81,
          92.57,
          92.46,
          92.57,
          92.55,
          92.55,
          92.6,
          92.54,
          92.55,
          92.69,
          92.58,
          92.72,
          92.55
         ]
        }
       ],
       "layout": {
        "height": 400,
        "margin": {
         "b": 20,
         "l": 20,
         "r": 20,
         "t": 20
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 400,
        "xaxis": {
         "range": [
          0,
          60
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the accuracy of the ELM and FF models using plotly\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(test_acc)), y=test_acc, mode='lines', name='Full NN'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(test_acc_ELM)), y=test_acc_ELM, mode='lines', name='ELM'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(test_acc_lin)), y=test_acc_lin, mode='lines', name='Linear'))\n",
    "\n",
    "#change theme to white and set the sizer of the plot\n",
    "fig.update_layout(template='plotly_white', width=400, height=400,margin=dict(l=20, r=20, t=20, b=20))\n",
    "#set xlim\n",
    "fig.update_xaxes(range=[0, 60])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we scan the size of the hidden layer for both the FFNN and ELM to compare how performance scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FFNN with  10  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 1.275258183479309, Test Accuracy: 76.24%\n",
      "Epoch [1/15], Step [200/600], Loss: 0.6915454864501953, Test Accuracy: 84.11%\n",
      "Epoch [1/15], Step [300/600], Loss: 0.7792010307312012, Test Accuracy: 86.98%\n",
      "Epoch [1/15], Step [400/600], Loss: 0.45443809032440186, Test Accuracy: 88.45%\n",
      "Epoch [1/15], Step [500/600], Loss: 0.35001206398010254, Test Accuracy: 89.06%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.3474467992782593, Test Accuracy: 90.14%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.3502334952354431, Test Accuracy: 90.51%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.32560884952545166, Test Accuracy: 90.59%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.4012940227985382, Test Accuracy: 90.94%\n",
      "Epoch [2/15], Step [400/600], Loss: 0.1706448495388031, Test Accuracy: 90.88%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.29448455572128296, Test Accuracy: 91.18%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.30363333225250244, Test Accuracy: 91.47%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.2684727609157562, Test Accuracy: 91.55%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.4392496943473816, Test Accuracy: 91.63%\n",
      "Epoch [3/15], Step [300/600], Loss: 0.31698504090309143, Test Accuracy: 91.63%\n",
      "Epoch [3/15], Step [400/600], Loss: 0.12626701593399048, Test Accuracy: 91.71%\n",
      "Epoch [3/15], Step [500/600], Loss: 0.3064305782318115, Test Accuracy: 91.96%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.17928241193294525, Test Accuracy: 91.72%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.49590790271759033, Test Accuracy: 91.94%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.2855433225631714, Test Accuracy: 91.7%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.16700692474842072, Test Accuracy: 92.15%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.3177385926246643, Test Accuracy: 92.24%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.20746619999408722, Test Accuracy: 92.04%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.23948106169700623, Test Accuracy: 91.95%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.3166077733039856, Test Accuracy: 92.35%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.3410579562187195, Test Accuracy: 92.41%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.16225221753120422, Test Accuracy: 92.02%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.32504284381866455, Test Accuracy: 92.23%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.1948593556880951, Test Accuracy: 92.37%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.23569278419017792, Test Accuracy: 92.5%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.21023455262184143, Test Accuracy: 92.4%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.1810457855463028, Test Accuracy: 92.54%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.2627808153629303, Test Accuracy: 92.58%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.3049619197845459, Test Accuracy: 92.4%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.4644853472709656, Test Accuracy: 92.6%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.2588241696357727, Test Accuracy: 92.63%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.284146249294281, Test Accuracy: 92.46%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.06925253570079803, Test Accuracy: 92.55%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.19289658963680267, Test Accuracy: 92.86%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.301491916179657, Test Accuracy: 92.59%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.10304958373308182, Test Accuracy: 92.65%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.4245848059654236, Test Accuracy: 92.65%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.26954352855682373, Test Accuracy: 92.69%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.27546626329421997, Test Accuracy: 92.67%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.2724866271018982, Test Accuracy: 92.81%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.2173326313495636, Test Accuracy: 92.66%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.32340922951698303, Test Accuracy: 92.74%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.19447162747383118, Test Accuracy: 92.6%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.1934739053249359, Test Accuracy: 92.83%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.18665724992752075, Test Accuracy: 93.0%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.3374101519584656, Test Accuracy: 92.97%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.4751448333263397, Test Accuracy: 92.79%\n",
      "Epoch [9/15], Step [500/600], Loss: 0.3887249231338501, Test Accuracy: 92.81%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.4144275188446045, Test Accuracy: 92.88%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.2559882700443268, Test Accuracy: 92.81%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.15440955758094788, Test Accuracy: 92.76%\n",
      "Epoch [10/15], Step [300/600], Loss: 0.18338394165039062, Test Accuracy: 92.89%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.1303819864988327, Test Accuracy: 92.69%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.12394485622644424, Test Accuracy: 92.81%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.28259754180908203, Test Accuracy: 93.02%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.2978505790233612, Test Accuracy: 92.76%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.2256540060043335, Test Accuracy: 92.93%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.32564985752105713, Test Accuracy: 92.79%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.26815900206565857, Test Accuracy: 93.09%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.24994367361068726, Test Accuracy: 93.1%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.1671462059020996, Test Accuracy: 92.96%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.3716575503349304, Test Accuracy: 92.96%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.21972231566905975, Test Accuracy: 92.91%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.29753053188323975, Test Accuracy: 93.05%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.17287510633468628, Test Accuracy: 93.12%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.3575626015663147, Test Accuracy: 93.0%\n",
      "Epoch [12/15], Step [600/600], Loss: 0.20762407779693604, Test Accuracy: 92.99%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.308808296918869, Test Accuracy: 92.87%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.31057578325271606, Test Accuracy: 93.16%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.10836175829172134, Test Accuracy: 93.05%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.3235645592212677, Test Accuracy: 93.05%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.12827806174755096, Test Accuracy: 93.22%\n",
      "Epoch [13/15], Step [600/600], Loss: 0.2985524833202362, Test Accuracy: 92.9%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.2121371328830719, Test Accuracy: 92.85%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.30450114607810974, Test Accuracy: 92.86%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.20095010101795197, Test Accuracy: 93.02%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.27981701493263245, Test Accuracy: 93.04%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.3342127501964569, Test Accuracy: 93.02%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.26357176899909973, Test Accuracy: 92.97%\n",
      "Epoch [15/15], Step [100/600], Loss: 0.2354530692100525, Test Accuracy: 93.07%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.27792733907699585, Test Accuracy: 93.05%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.4366573095321655, Test Accuracy: 93.1%\n",
      "Epoch [15/15], Step [400/600], Loss: 0.3092755377292633, Test Accuracy: 93.15%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.17758524417877197, Test Accuracy: 93.06%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.2567734718322754, Test Accuracy: 93.07%\n",
      "Training ELM with  10  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 2.1719231605529785, Test Accuracy: 35.56%\n",
      "Epoch [1/15], Step [200/600], Loss: 2.013557195663452, Test Accuracy: 38.97%\n",
      "Epoch [1/15], Step [300/600], Loss: 1.9946417808532715, Test Accuracy: 39.45%\n",
      "Epoch [1/15], Step [400/600], Loss: 1.8633275032043457, Test Accuracy: 40.06%\n",
      "Epoch [1/15], Step [500/600], Loss: 1.8136491775512695, Test Accuracy: 40.6%\n",
      "Epoch [1/15], Step [600/600], Loss: 1.7870784997940063, Test Accuracy: 40.79%\n",
      "Epoch [2/15], Step [100/600], Loss: 1.6441740989685059, Test Accuracy: 41.16%\n",
      "Epoch [2/15], Step [200/600], Loss: 1.932462453842163, Test Accuracy: 41.58%\n",
      "Epoch [2/15], Step [300/600], Loss: 1.7484831809997559, Test Accuracy: 41.76%\n",
      "Epoch [2/15], Step [400/600], Loss: 1.689731478691101, Test Accuracy: 41.84%\n",
      "Epoch [2/15], Step [500/600], Loss: 1.6817272901535034, Test Accuracy: 41.79%\n",
      "Epoch [2/15], Step [600/600], Loss: 1.8507587909698486, Test Accuracy: 42.02%\n",
      "Epoch [3/15], Step [100/600], Loss: 1.6025729179382324, Test Accuracy: 42.11%\n",
      "Epoch [3/15], Step [200/600], Loss: 1.8586416244506836, Test Accuracy: 42.22%\n",
      "Epoch [3/15], Step [300/600], Loss: 1.75374436378479, Test Accuracy: 42.23%\n",
      "Epoch [3/15], Step [400/600], Loss: 1.7558870315551758, Test Accuracy: 42.59%\n",
      "Epoch [3/15], Step [500/600], Loss: 1.6522332429885864, Test Accuracy: 42.24%\n",
      "Epoch [3/15], Step [600/600], Loss: 1.7259505987167358, Test Accuracy: 42.4%\n",
      "Epoch [4/15], Step [100/600], Loss: 1.728763222694397, Test Accuracy: 42.62%\n",
      "Epoch [4/15], Step [200/600], Loss: 1.8772131204605103, Test Accuracy: 42.47%\n",
      "Epoch [4/15], Step [300/600], Loss: 1.677802562713623, Test Accuracy: 42.51%\n",
      "Epoch [4/15], Step [400/600], Loss: 1.6453697681427002, Test Accuracy: 42.63%\n",
      "Epoch [4/15], Step [500/600], Loss: 1.6357084512710571, Test Accuracy: 42.55%\n",
      "Epoch [4/15], Step [600/600], Loss: 1.7910100221633911, Test Accuracy: 42.63%\n",
      "Epoch [5/15], Step [100/600], Loss: 1.6440668106079102, Test Accuracy: 42.6%\n",
      "Epoch [5/15], Step [200/600], Loss: 1.6748276948928833, Test Accuracy: 42.64%\n",
      "Epoch [5/15], Step [300/600], Loss: 1.6828442811965942, Test Accuracy: 42.69%\n",
      "Epoch [5/15], Step [400/600], Loss: 1.7851768732070923, Test Accuracy: 42.78%\n",
      "Epoch [5/15], Step [500/600], Loss: 1.7188963890075684, Test Accuracy: 42.43%\n",
      "Epoch [5/15], Step [600/600], Loss: 1.5122554302215576, Test Accuracy: 42.6%\n",
      "Epoch [6/15], Step [100/600], Loss: 1.660751223564148, Test Accuracy: 42.65%\n",
      "Epoch [6/15], Step [200/600], Loss: 1.7886128425598145, Test Accuracy: 42.65%\n",
      "Epoch [6/15], Step [300/600], Loss: 1.6491626501083374, Test Accuracy: 42.84%\n",
      "Epoch [6/15], Step [400/600], Loss: 1.7250120639801025, Test Accuracy: 42.62%\n",
      "Epoch [6/15], Step [500/600], Loss: 1.776530146598816, Test Accuracy: 42.68%\n",
      "Epoch [6/15], Step [600/600], Loss: 1.64927339553833, Test Accuracy: 42.66%\n",
      "Epoch [7/15], Step [100/600], Loss: 1.4608019590377808, Test Accuracy: 42.68%\n",
      "Epoch [7/15], Step [200/600], Loss: 1.7712225914001465, Test Accuracy: 43.05%\n",
      "Epoch [7/15], Step [300/600], Loss: 1.5849440097808838, Test Accuracy: 42.78%\n",
      "Epoch [7/15], Step [400/600], Loss: 1.5806360244750977, Test Accuracy: 42.66%\n",
      "Epoch [7/15], Step [500/600], Loss: 1.7587227821350098, Test Accuracy: 42.83%\n",
      "Epoch [7/15], Step [600/600], Loss: 1.8757498264312744, Test Accuracy: 42.89%\n",
      "Epoch [8/15], Step [100/600], Loss: 1.6888254880905151, Test Accuracy: 42.92%\n",
      "Epoch [8/15], Step [200/600], Loss: 1.7742923498153687, Test Accuracy: 42.8%\n",
      "Epoch [8/15], Step [300/600], Loss: 1.6068497896194458, Test Accuracy: 42.91%\n",
      "Epoch [8/15], Step [400/600], Loss: 1.564939260482788, Test Accuracy: 42.93%\n",
      "Epoch [8/15], Step [500/600], Loss: 1.6469624042510986, Test Accuracy: 42.88%\n",
      "Epoch [8/15], Step [600/600], Loss: 1.661080002784729, Test Accuracy: 43.05%\n",
      "Epoch [9/15], Step [100/600], Loss: 1.6627020835876465, Test Accuracy: 42.84%\n",
      "Epoch [9/15], Step [200/600], Loss: 1.6011056900024414, Test Accuracy: 42.85%\n",
      "Epoch [9/15], Step [300/600], Loss: 1.6557961702346802, Test Accuracy: 42.99%\n",
      "Epoch [9/15], Step [400/600], Loss: 1.6056654453277588, Test Accuracy: 43.05%\n",
      "Epoch [9/15], Step [500/600], Loss: 1.5687483549118042, Test Accuracy: 42.9%\n",
      "Epoch [9/15], Step [600/600], Loss: 1.726340651512146, Test Accuracy: 42.82%\n",
      "Epoch [10/15], Step [100/600], Loss: 1.5719925165176392, Test Accuracy: 42.83%\n",
      "Epoch [10/15], Step [200/600], Loss: 1.6922944784164429, Test Accuracy: 42.81%\n",
      "Epoch [10/15], Step [300/600], Loss: 1.6218162775039673, Test Accuracy: 43.0%\n",
      "Epoch [10/15], Step [400/600], Loss: 1.745803713798523, Test Accuracy: 42.76%\n",
      "Epoch [10/15], Step [500/600], Loss: 1.660904884338379, Test Accuracy: 42.81%\n",
      "Epoch [10/15], Step [600/600], Loss: 1.7379766702651978, Test Accuracy: 42.81%\n",
      "Epoch [11/15], Step [100/600], Loss: 1.6477727890014648, Test Accuracy: 42.87%\n",
      "Epoch [11/15], Step [200/600], Loss: 1.634772539138794, Test Accuracy: 42.86%\n",
      "Epoch [11/15], Step [300/600], Loss: 1.588442087173462, Test Accuracy: 42.75%\n",
      "Epoch [11/15], Step [400/600], Loss: 1.6477643251419067, Test Accuracy: 42.75%\n",
      "Epoch [11/15], Step [500/600], Loss: 1.655930519104004, Test Accuracy: 42.78%\n",
      "Epoch [11/15], Step [600/600], Loss: 1.5878421068191528, Test Accuracy: 42.75%\n",
      "Epoch [12/15], Step [100/600], Loss: 1.702824592590332, Test Accuracy: 43.13%\n",
      "Epoch [12/15], Step [200/600], Loss: 1.7260605096817017, Test Accuracy: 43.0%\n",
      "Epoch [12/15], Step [300/600], Loss: 1.6702216863632202, Test Accuracy: 42.8%\n",
      "Epoch [12/15], Step [400/600], Loss: 1.6691850423812866, Test Accuracy: 42.86%\n",
      "Epoch [12/15], Step [500/600], Loss: 1.7022836208343506, Test Accuracy: 42.66%\n",
      "Epoch [12/15], Step [600/600], Loss: 1.7085975408554077, Test Accuracy: 42.77%\n",
      "Epoch [13/15], Step [100/600], Loss: 1.6932049989700317, Test Accuracy: 42.85%\n",
      "Epoch [13/15], Step [200/600], Loss: 1.77598237991333, Test Accuracy: 42.71%\n",
      "Epoch [13/15], Step [300/600], Loss: 1.7426555156707764, Test Accuracy: 42.67%\n",
      "Epoch [13/15], Step [400/600], Loss: 1.5275144577026367, Test Accuracy: 43.02%\n",
      "Epoch [13/15], Step [500/600], Loss: 1.7527140378952026, Test Accuracy: 42.67%\n",
      "Epoch [13/15], Step [600/600], Loss: 1.909287452697754, Test Accuracy: 42.89%\n",
      "Epoch [14/15], Step [100/600], Loss: 1.6512986421585083, Test Accuracy: 42.88%\n",
      "Epoch [14/15], Step [200/600], Loss: 1.690588355064392, Test Accuracy: 42.77%\n",
      "Epoch [14/15], Step [300/600], Loss: 1.563281536102295, Test Accuracy: 42.87%\n",
      "Epoch [14/15], Step [400/600], Loss: 1.6722484827041626, Test Accuracy: 42.73%\n",
      "Epoch [14/15], Step [500/600], Loss: 1.4570945501327515, Test Accuracy: 43.07%\n",
      "Epoch [14/15], Step [600/600], Loss: 1.6758006811141968, Test Accuracy: 42.8%\n",
      "Epoch [15/15], Step [100/600], Loss: 1.756618857383728, Test Accuracy: 42.87%\n",
      "Epoch [15/15], Step [200/600], Loss: 1.6652957201004028, Test Accuracy: 42.65%\n",
      "Epoch [15/15], Step [300/600], Loss: 1.9137881994247437, Test Accuracy: 42.78%\n",
      "Epoch [15/15], Step [400/600], Loss: 1.6489826440811157, Test Accuracy: 42.77%\n",
      "Epoch [15/15], Step [500/600], Loss: 1.850210428237915, Test Accuracy: 42.89%\n",
      "Epoch [15/15], Step [600/600], Loss: 1.7544273138046265, Test Accuracy: 42.97%\n",
      "Training FFNN with  20  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=20, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=20, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 0.695810854434967, Test Accuracy: 84.65%\n",
      "Epoch [1/15], Step [200/600], Loss: 0.41982993483543396, Test Accuracy: 88.98%\n",
      "Epoch [1/15], Step [300/600], Loss: 0.5967223644256592, Test Accuracy: 90.39%\n",
      "Epoch [1/15], Step [400/600], Loss: 0.28458449244499207, Test Accuracy: 91.0%\n",
      "Epoch [1/15], Step [500/600], Loss: 0.282836377620697, Test Accuracy: 91.26%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.328689843416214, Test Accuracy: 91.62%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.15507572889328003, Test Accuracy: 91.85%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.40935784578323364, Test Accuracy: 92.36%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.37268388271331787, Test Accuracy: 92.3%\n",
      "Epoch [2/15], Step [400/600], Loss: 0.23951981961727142, Test Accuracy: 92.48%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.26763856410980225, Test Accuracy: 92.48%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.18808986246585846, Test Accuracy: 92.26%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.18910476565361023, Test Accuracy: 92.83%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.24160069227218628, Test Accuracy: 92.89%\n",
      "Epoch [3/15], Step [300/600], Loss: 0.2563731074333191, Test Accuracy: 92.94%\n",
      "Epoch [3/15], Step [400/600], Loss: 0.21941906213760376, Test Accuracy: 93.19%\n",
      "Epoch [3/15], Step [500/600], Loss: 0.16770526766777039, Test Accuracy: 93.37%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.24597394466400146, Test Accuracy: 93.47%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.2784114480018616, Test Accuracy: 93.09%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.19008126854896545, Test Accuracy: 93.43%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.2778739631175995, Test Accuracy: 93.75%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.30731502175331116, Test Accuracy: 93.74%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.23629383742809296, Test Accuracy: 93.94%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.18862663209438324, Test Accuracy: 93.77%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.321712851524353, Test Accuracy: 93.88%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.18850435316562653, Test Accuracy: 94.08%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.33076760172843933, Test Accuracy: 94.09%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.23924189805984497, Test Accuracy: 94.24%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.1431555598974228, Test Accuracy: 94.02%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.3167356550693512, Test Accuracy: 94.43%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.08260250836610794, Test Accuracy: 94.11%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.14043165743350983, Test Accuracy: 94.3%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.17580945789813995, Test Accuracy: 94.46%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.2317066788673401, Test Accuracy: 94.58%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.17638766765594482, Test Accuracy: 94.57%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.15123562514781952, Test Accuracy: 94.69%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.22031165659427643, Test Accuracy: 94.73%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.19219262897968292, Test Accuracy: 94.79%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.254233181476593, Test Accuracy: 94.78%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.09803883731365204, Test Accuracy: 94.9%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.17342102527618408, Test Accuracy: 94.8%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.16333425045013428, Test Accuracy: 94.7%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.12832027673721313, Test Accuracy: 94.67%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.1303066462278366, Test Accuracy: 94.57%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.32026225328445435, Test Accuracy: 94.87%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.15058723092079163, Test Accuracy: 94.89%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.14083664119243622, Test Accuracy: 94.94%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.15397264063358307, Test Accuracy: 94.99%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.14345382153987885, Test Accuracy: 94.99%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.18851135671138763, Test Accuracy: 94.88%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.07286491245031357, Test Accuracy: 94.92%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.24494755268096924, Test Accuracy: 95.04%\n",
      "Epoch [9/15], Step [500/600], Loss: 0.16661621630191803, Test Accuracy: 94.94%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.10513705015182495, Test Accuracy: 95.01%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.16317355632781982, Test Accuracy: 94.99%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.07872352004051208, Test Accuracy: 95.14%\n",
      "Epoch [10/15], Step [300/600], Loss: 0.11940664052963257, Test Accuracy: 95.18%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.3306663930416107, Test Accuracy: 95.08%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.2293521761894226, Test Accuracy: 95.13%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.29360297322273254, Test Accuracy: 95.04%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.25821730494499207, Test Accuracy: 95.18%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.18245410919189453, Test Accuracy: 94.94%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.24024765193462372, Test Accuracy: 95.2%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.17805376648902893, Test Accuracy: 95.22%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.07506229728460312, Test Accuracy: 95.19%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.13854481279850006, Test Accuracy: 95.19%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.08431492000818253, Test Accuracy: 95.16%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.12164957821369171, Test Accuracy: 95.17%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.22658948600292206, Test Accuracy: 95.19%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.10969752073287964, Test Accuracy: 95.19%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.07357533276081085, Test Accuracy: 95.21%\n",
      "Epoch [12/15], Step [600/600], Loss: 0.09773292392492294, Test Accuracy: 95.28%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.191354900598526, Test Accuracy: 95.33%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.058026738464832306, Test Accuracy: 95.27%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.1425992250442505, Test Accuracy: 95.31%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.08564158529043198, Test Accuracy: 95.25%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.1432754546403885, Test Accuracy: 95.35%\n",
      "Epoch [13/15], Step [600/600], Loss: 0.10318519920110703, Test Accuracy: 95.31%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.08407119661569595, Test Accuracy: 95.33%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.1855856329202652, Test Accuracy: 95.32%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.07669644057750702, Test Accuracy: 95.34%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.15197616815567017, Test Accuracy: 95.3%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.04236512631177902, Test Accuracy: 95.46%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.21281714737415314, Test Accuracy: 95.42%\n",
      "Epoch [15/15], Step [100/600], Loss: 0.13648101687431335, Test Accuracy: 95.17%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.09815504401922226, Test Accuracy: 95.36%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.07543004304170609, Test Accuracy: 95.25%\n",
      "Epoch [15/15], Step [400/600], Loss: 0.16051934659481049, Test Accuracy: 95.41%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.1244797334074974, Test Accuracy: 95.46%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.10592526197433472, Test Accuracy: 95.43%\n",
      "Training ELM with  20  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=20, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=20, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 1.9912971258163452, Test Accuracy: 49.18%\n",
      "Epoch [1/15], Step [200/600], Loss: 1.8406528234481812, Test Accuracy: 51.31%\n",
      "Epoch [1/15], Step [300/600], Loss: 1.6512600183486938, Test Accuracy: 53.93%\n",
      "Epoch [1/15], Step [400/600], Loss: 1.463026762008667, Test Accuracy: 54.4%\n",
      "Epoch [1/15], Step [500/600], Loss: 1.5755990743637085, Test Accuracy: 54.91%\n",
      "Epoch [1/15], Step [600/600], Loss: 1.4893248081207275, Test Accuracy: 56.58%\n",
      "Epoch [2/15], Step [100/600], Loss: 1.386457085609436, Test Accuracy: 56.74%\n",
      "Epoch [2/15], Step [200/600], Loss: 1.2951579093933105, Test Accuracy: 57.21%\n",
      "Epoch [2/15], Step [300/600], Loss: 1.3478065729141235, Test Accuracy: 57.33%\n",
      "Epoch [2/15], Step [400/600], Loss: 1.4737375974655151, Test Accuracy: 57.75%\n",
      "Epoch [2/15], Step [500/600], Loss: 1.4428818225860596, Test Accuracy: 58.02%\n",
      "Epoch [2/15], Step [600/600], Loss: 1.436049222946167, Test Accuracy: 58.44%\n",
      "Epoch [3/15], Step [100/600], Loss: 1.2924742698669434, Test Accuracy: 58.39%\n",
      "Epoch [3/15], Step [200/600], Loss: 1.3382562398910522, Test Accuracy: 58.8%\n",
      "Epoch [3/15], Step [300/600], Loss: 1.2829103469848633, Test Accuracy: 59.02%\n",
      "Epoch [3/15], Step [400/600], Loss: 1.263149619102478, Test Accuracy: 59.25%\n",
      "Epoch [3/15], Step [500/600], Loss: 1.2258939743041992, Test Accuracy: 58.88%\n",
      "Epoch [3/15], Step [600/600], Loss: 1.3564727306365967, Test Accuracy: 59.11%\n",
      "Epoch [4/15], Step [100/600], Loss: 1.2162113189697266, Test Accuracy: 59.39%\n",
      "Epoch [4/15], Step [200/600], Loss: 1.186192512512207, Test Accuracy: 59.25%\n",
      "Epoch [4/15], Step [300/600], Loss: 1.0747649669647217, Test Accuracy: 59.33%\n",
      "Epoch [4/15], Step [400/600], Loss: 1.0832436084747314, Test Accuracy: 59.66%\n",
      "Epoch [4/15], Step [500/600], Loss: 1.190317153930664, Test Accuracy: 59.57%\n",
      "Epoch [4/15], Step [600/600], Loss: 1.3962327241897583, Test Accuracy: 59.88%\n",
      "Epoch [5/15], Step [100/600], Loss: 1.2938936948776245, Test Accuracy: 59.91%\n",
      "Epoch [5/15], Step [200/600], Loss: 1.3009545803070068, Test Accuracy: 59.44%\n",
      "Epoch [5/15], Step [300/600], Loss: 1.1827285289764404, Test Accuracy: 60.09%\n",
      "Epoch [5/15], Step [400/600], Loss: 1.3330003023147583, Test Accuracy: 59.93%\n",
      "Epoch [5/15], Step [500/600], Loss: 1.3113528490066528, Test Accuracy: 60.09%\n",
      "Epoch [5/15], Step [600/600], Loss: 1.271952509880066, Test Accuracy: 60.01%\n",
      "Epoch [6/15], Step [100/600], Loss: 1.1099525690078735, Test Accuracy: 60.2%\n",
      "Epoch [6/15], Step [200/600], Loss: 1.3843685388565063, Test Accuracy: 59.85%\n",
      "Epoch [6/15], Step [300/600], Loss: 1.1742626428604126, Test Accuracy: 60.4%\n",
      "Epoch [6/15], Step [400/600], Loss: 1.3216930627822876, Test Accuracy: 60.06%\n",
      "Epoch [6/15], Step [500/600], Loss: 1.0209405422210693, Test Accuracy: 60.26%\n",
      "Epoch [6/15], Step [600/600], Loss: 1.1206172704696655, Test Accuracy: 60.15%\n",
      "Epoch [7/15], Step [100/600], Loss: 1.2564061880111694, Test Accuracy: 59.95%\n",
      "Epoch [7/15], Step [200/600], Loss: 1.142961025238037, Test Accuracy: 60.46%\n",
      "Epoch [7/15], Step [300/600], Loss: 1.1960618495941162, Test Accuracy: 60.2%\n",
      "Epoch [7/15], Step [400/600], Loss: 1.1849764585494995, Test Accuracy: 60.2%\n",
      "Epoch [7/15], Step [500/600], Loss: 1.2648515701293945, Test Accuracy: 60.25%\n",
      "Epoch [7/15], Step [600/600], Loss: 1.2395342588424683, Test Accuracy: 60.29%\n",
      "Epoch [8/15], Step [100/600], Loss: 1.078864574432373, Test Accuracy: 60.21%\n",
      "Epoch [8/15], Step [200/600], Loss: 1.3532371520996094, Test Accuracy: 60.41%\n",
      "Epoch [8/15], Step [300/600], Loss: 1.1852233409881592, Test Accuracy: 60.26%\n",
      "Epoch [8/15], Step [400/600], Loss: 1.253960132598877, Test Accuracy: 60.33%\n",
      "Epoch [8/15], Step [500/600], Loss: 1.3263570070266724, Test Accuracy: 60.42%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.9793064594268799, Test Accuracy: 60.4%\n",
      "Epoch [9/15], Step [100/600], Loss: 1.4170106649398804, Test Accuracy: 60.39%\n",
      "Epoch [9/15], Step [200/600], Loss: 1.2014869451522827, Test Accuracy: 60.48%\n",
      "Epoch [9/15], Step [300/600], Loss: 1.3493287563323975, Test Accuracy: 60.61%\n",
      "Epoch [9/15], Step [400/600], Loss: 1.2005341053009033, Test Accuracy: 60.34%\n",
      "Epoch [9/15], Step [500/600], Loss: 1.1722385883331299, Test Accuracy: 60.44%\n",
      "Epoch [9/15], Step [600/600], Loss: 1.1715903282165527, Test Accuracy: 60.56%\n",
      "Epoch [10/15], Step [100/600], Loss: 1.0168883800506592, Test Accuracy: 60.26%\n",
      "Epoch [10/15], Step [200/600], Loss: 1.273928165435791, Test Accuracy: 60.16%\n",
      "Epoch [10/15], Step [300/600], Loss: 1.1720991134643555, Test Accuracy: 60.46%\n",
      "Epoch [10/15], Step [400/600], Loss: 1.2925738096237183, Test Accuracy: 60.55%\n",
      "Epoch [10/15], Step [500/600], Loss: 1.3719562292099, Test Accuracy: 60.39%\n",
      "Epoch [10/15], Step [600/600], Loss: 1.0682384967803955, Test Accuracy: 60.61%\n",
      "Epoch [11/15], Step [100/600], Loss: 1.2820838689804077, Test Accuracy: 60.79%\n",
      "Epoch [11/15], Step [200/600], Loss: 1.2045725584030151, Test Accuracy: 60.28%\n",
      "Epoch [11/15], Step [300/600], Loss: 1.0460519790649414, Test Accuracy: 60.7%\n",
      "Epoch [11/15], Step [400/600], Loss: 1.2959927320480347, Test Accuracy: 60.25%\n",
      "Epoch [11/15], Step [500/600], Loss: 1.1601958274841309, Test Accuracy: 60.39%\n",
      "Epoch [11/15], Step [600/600], Loss: 1.2365871667861938, Test Accuracy: 60.45%\n",
      "Epoch [12/15], Step [100/600], Loss: 1.0155935287475586, Test Accuracy: 60.83%\n",
      "Epoch [12/15], Step [200/600], Loss: 1.201647400856018, Test Accuracy: 60.6%\n",
      "Epoch [12/15], Step [300/600], Loss: 1.2201014757156372, Test Accuracy: 60.5%\n",
      "Epoch [12/15], Step [400/600], Loss: 1.179145336151123, Test Accuracy: 60.57%\n",
      "Epoch [12/15], Step [500/600], Loss: 1.308371901512146, Test Accuracy: 60.46%\n",
      "Epoch [12/15], Step [600/600], Loss: 1.147343397140503, Test Accuracy: 60.37%\n",
      "Epoch [13/15], Step [100/600], Loss: 1.3244619369506836, Test Accuracy: 60.44%\n",
      "Epoch [13/15], Step [200/600], Loss: 1.0377392768859863, Test Accuracy: 60.39%\n",
      "Epoch [13/15], Step [300/600], Loss: 1.1856507062911987, Test Accuracy: 60.56%\n",
      "Epoch [13/15], Step [400/600], Loss: 1.1931381225585938, Test Accuracy: 60.65%\n",
      "Epoch [13/15], Step [500/600], Loss: 1.2594109773635864, Test Accuracy: 60.53%\n",
      "Epoch [13/15], Step [600/600], Loss: 1.1953861713409424, Test Accuracy: 60.25%\n",
      "Epoch [14/15], Step [100/600], Loss: 1.3428219556808472, Test Accuracy: 60.5%\n",
      "Epoch [14/15], Step [200/600], Loss: 1.194104552268982, Test Accuracy: 60.64%\n",
      "Epoch [14/15], Step [300/600], Loss: 1.1476638317108154, Test Accuracy: 60.37%\n",
      "Epoch [14/15], Step [400/600], Loss: 1.3747769594192505, Test Accuracy: 60.67%\n",
      "Epoch [14/15], Step [500/600], Loss: 1.2405445575714111, Test Accuracy: 60.62%\n",
      "Epoch [14/15], Step [600/600], Loss: 1.1585359573364258, Test Accuracy: 60.48%\n",
      "Epoch [15/15], Step [100/600], Loss: 1.3030369281768799, Test Accuracy: 60.66%\n",
      "Epoch [15/15], Step [200/600], Loss: 1.392938256263733, Test Accuracy: 60.35%\n",
      "Epoch [15/15], Step [300/600], Loss: 1.217068076133728, Test Accuracy: 60.42%\n",
      "Epoch [15/15], Step [400/600], Loss: 1.3134983777999878, Test Accuracy: 60.33%\n",
      "Epoch [15/15], Step [500/600], Loss: 1.3215640783309937, Test Accuracy: 60.66%\n",
      "Epoch [15/15], Step [600/600], Loss: 1.1859761476516724, Test Accuracy: 60.37%\n",
      "Training FFNN with  50  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=50, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 0.5983303189277649, Test Accuracy: 88.05%\n",
      "Epoch [1/15], Step [200/600], Loss: 0.40398234128952026, Test Accuracy: 90.01%\n",
      "Epoch [1/15], Step [300/600], Loss: 0.4435511827468872, Test Accuracy: 91.09%\n",
      "Epoch [1/15], Step [400/600], Loss: 0.3250969350337982, Test Accuracy: 91.7%\n",
      "Epoch [1/15], Step [500/600], Loss: 0.26397669315338135, Test Accuracy: 92.12%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.23297767341136932, Test Accuracy: 92.24%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.3258552849292755, Test Accuracy: 92.99%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.27716362476348877, Test Accuracy: 93.2%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.20923396944999695, Test Accuracy: 93.4%\n",
      "Epoch [2/15], Step [400/600], Loss: 0.12865003943443298, Test Accuracy: 93.8%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.2258106768131256, Test Accuracy: 94.06%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.17589998245239258, Test Accuracy: 94.07%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.16522425413131714, Test Accuracy: 94.19%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.17689865827560425, Test Accuracy: 94.49%\n",
      "Epoch [3/15], Step [300/600], Loss: 0.10016961395740509, Test Accuracy: 94.82%\n",
      "Epoch [3/15], Step [400/600], Loss: 0.10195344686508179, Test Accuracy: 94.69%\n",
      "Epoch [3/15], Step [500/600], Loss: 0.1233547031879425, Test Accuracy: 94.7%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.23376043140888214, Test Accuracy: 94.9%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.139545738697052, Test Accuracy: 95.19%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.07936087995767593, Test Accuracy: 95.14%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.12316246330738068, Test Accuracy: 95.41%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.43133383989334106, Test Accuracy: 95.48%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.19205261766910553, Test Accuracy: 95.66%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.10755942016839981, Test Accuracy: 95.66%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.18584276735782623, Test Accuracy: 95.74%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.08244878798723221, Test Accuracy: 95.88%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.11708591133356094, Test Accuracy: 95.87%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.08075809478759766, Test Accuracy: 95.97%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.22562797367572784, Test Accuracy: 96.02%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.21710920333862305, Test Accuracy: 96.05%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.1508491039276123, Test Accuracy: 96.04%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.12852999567985535, Test Accuracy: 96.19%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.0739181637763977, Test Accuracy: 96.33%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.0742478147149086, Test Accuracy: 96.35%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.11411599814891815, Test Accuracy: 96.24%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.10340581089258194, Test Accuracy: 96.39%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.08958529680967331, Test Accuracy: 96.52%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.2169259488582611, Test Accuracy: 96.44%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.135827898979187, Test Accuracy: 96.49%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.09622947871685028, Test Accuracy: 96.65%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.05900369584560394, Test Accuracy: 96.56%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.13830214738845825, Test Accuracy: 96.56%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.08854953944683075, Test Accuracy: 96.52%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.03134452924132347, Test Accuracy: 96.77%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.10522232949733734, Test Accuracy: 96.65%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.08626919984817505, Test Accuracy: 96.83%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.09187426418066025, Test Accuracy: 96.8%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.06053531542420387, Test Accuracy: 96.75%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.028293967247009277, Test Accuracy: 96.77%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.04274970665574074, Test Accuracy: 96.85%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.11478059738874435, Test Accuracy: 96.76%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.07831893861293793, Test Accuracy: 96.85%\n",
      "Epoch [9/15], Step [500/600], Loss: 0.03794516250491142, Test Accuracy: 96.99%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.12797784805297852, Test Accuracy: 96.78%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.10536157339811325, Test Accuracy: 96.79%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.03785769268870354, Test Accuracy: 97.0%\n",
      "Epoch [10/15], Step [300/600], Loss: 0.14213880896568298, Test Accuracy: 96.97%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.09347715228796005, Test Accuracy: 96.86%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.05478094518184662, Test Accuracy: 96.84%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.057199377566576004, Test Accuracy: 97.02%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.08936662971973419, Test Accuracy: 97.17%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.12123420834541321, Test Accuracy: 97.0%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.03633536398410797, Test Accuracy: 96.91%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.03532955050468445, Test Accuracy: 97.06%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.10658155381679535, Test Accuracy: 97.08%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.13008254766464233, Test Accuracy: 97.16%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.016832351684570312, Test Accuracy: 97.24%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.0860276147723198, Test Accuracy: 97.02%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.07363591343164444, Test Accuracy: 97.18%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.04408686235547066, Test Accuracy: 97.03%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.05953805521130562, Test Accuracy: 96.95%\n",
      "Epoch [12/15], Step [600/600], Loss: 0.11058051884174347, Test Accuracy: 97.32%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.07621186971664429, Test Accuracy: 97.12%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.08433802425861359, Test Accuracy: 97.26%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.03402220830321312, Test Accuracy: 97.1%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.05283348634839058, Test Accuracy: 97.09%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.05462498590350151, Test Accuracy: 97.33%\n",
      "Epoch [13/15], Step [600/600], Loss: 0.033097557723522186, Test Accuracy: 97.1%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.061837490648031235, Test Accuracy: 97.25%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.030340077355504036, Test Accuracy: 97.28%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.05162985622882843, Test Accuracy: 97.39%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.015011932700872421, Test Accuracy: 97.37%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.029358308762311935, Test Accuracy: 97.38%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.053564731031656265, Test Accuracy: 97.31%\n",
      "Epoch [15/15], Step [100/600], Loss: 0.08142828941345215, Test Accuracy: 97.38%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.023761607706546783, Test Accuracy: 97.24%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.05155768245458603, Test Accuracy: 97.34%\n",
      "Epoch [15/15], Step [400/600], Loss: 0.0659833550453186, Test Accuracy: 97.33%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.031240861862897873, Test Accuracy: 97.3%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.03990241885185242, Test Accuracy: 97.26%\n",
      "Training ELM with  50  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=50, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 1.6068042516708374, Test Accuracy: 66.22%\n",
      "Epoch [1/15], Step [200/600], Loss: 1.2499960660934448, Test Accuracy: 68.3%\n",
      "Epoch [1/15], Step [300/600], Loss: 1.149044394493103, Test Accuracy: 70.45%\n",
      "Epoch [1/15], Step [400/600], Loss: 1.0249428749084473, Test Accuracy: 71.67%\n",
      "Epoch [1/15], Step [500/600], Loss: 1.0036396980285645, Test Accuracy: 72.73%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.9177159070968628, Test Accuracy: 73.23%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.9606487154960632, Test Accuracy: 73.87%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.8528633713722229, Test Accuracy: 73.96%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.987272322177887, Test Accuracy: 74.64%\n",
      "Epoch [2/15], Step [400/600], Loss: 0.6932446956634521, Test Accuracy: 74.86%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.7736887335777283, Test Accuracy: 75.14%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.809489369392395, Test Accuracy: 75.44%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.7769728302955627, Test Accuracy: 75.88%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.7620225548744202, Test Accuracy: 75.85%\n",
      "Epoch [3/15], Step [300/600], Loss: 0.6905168890953064, Test Accuracy: 76.0%\n",
      "Epoch [3/15], Step [400/600], Loss: 0.8067947626113892, Test Accuracy: 76.34%\n",
      "Epoch [3/15], Step [500/600], Loss: 0.7385464310646057, Test Accuracy: 76.33%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.8369350433349609, Test Accuracy: 76.38%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.644133985042572, Test Accuracy: 76.46%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.7821522355079651, Test Accuracy: 76.71%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.8214260339736938, Test Accuracy: 76.7%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.9167870283126831, Test Accuracy: 76.68%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.6419402360916138, Test Accuracy: 76.73%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.6883100867271423, Test Accuracy: 76.86%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.7516070604324341, Test Accuracy: 77.06%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.6855787038803101, Test Accuracy: 77.04%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.6976686120033264, Test Accuracy: 76.96%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.7050479650497437, Test Accuracy: 76.96%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.7324978709220886, Test Accuracy: 77.19%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.6664422750473022, Test Accuracy: 77.12%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.878334641456604, Test Accuracy: 77.12%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.7651437520980835, Test Accuracy: 77.16%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.7305527329444885, Test Accuracy: 77.21%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.8807563781738281, Test Accuracy: 77.24%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.4826480746269226, Test Accuracy: 77.36%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.7201029062271118, Test Accuracy: 77.44%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.7584025859832764, Test Accuracy: 77.42%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.7091975212097168, Test Accuracy: 77.33%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.6104580163955688, Test Accuracy: 77.42%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.7723175883293152, Test Accuracy: 77.38%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.7397287487983704, Test Accuracy: 77.36%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.7154732346534729, Test Accuracy: 77.47%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.7517971992492676, Test Accuracy: 77.37%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.7060871720314026, Test Accuracy: 77.34%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.9857790470123291, Test Accuracy: 77.29%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.6733169555664062, Test Accuracy: 77.27%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.6857122182846069, Test Accuracy: 77.42%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.8626807332038879, Test Accuracy: 77.61%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.7345921993255615, Test Accuracy: 77.29%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.6691300272941589, Test Accuracy: 77.77%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.6469960808753967, Test Accuracy: 77.61%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.7191883325576782, Test Accuracy: 77.48%\n",
      "Epoch [9/15], Step [500/600], Loss: 0.6155494451522827, Test Accuracy: 77.57%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.7175385355949402, Test Accuracy: 77.4%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.7142934203147888, Test Accuracy: 77.28%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.5790027379989624, Test Accuracy: 77.45%\n",
      "Epoch [10/15], Step [300/600], Loss: 1.0422497987747192, Test Accuracy: 77.61%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.639042317867279, Test Accuracy: 77.55%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.7332456707954407, Test Accuracy: 77.51%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.6261507868766785, Test Accuracy: 77.46%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.7897975444793701, Test Accuracy: 77.4%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.6372387409210205, Test Accuracy: 77.7%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.6429683566093445, Test Accuracy: 77.49%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.7704665660858154, Test Accuracy: 77.53%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.6294135451316833, Test Accuracy: 77.52%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.8572178483009338, Test Accuracy: 77.51%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.5910187363624573, Test Accuracy: 77.64%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.7000325918197632, Test Accuracy: 77.5%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.8891926407814026, Test Accuracy: 77.52%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.7397893667221069, Test Accuracy: 77.59%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.7769303321838379, Test Accuracy: 77.66%\n",
      "Epoch [12/15], Step [600/600], Loss: 0.5280906558036804, Test Accuracy: 77.6%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.8554114699363708, Test Accuracy: 77.41%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.6992872357368469, Test Accuracy: 77.35%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.6899275779724121, Test Accuracy: 77.45%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.634738028049469, Test Accuracy: 77.73%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.694182813167572, Test Accuracy: 77.67%\n",
      "Epoch [13/15], Step [600/600], Loss: 0.5445362329483032, Test Accuracy: 77.63%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.7655002474784851, Test Accuracy: 77.38%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.792945921421051, Test Accuracy: 77.36%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.6917656064033508, Test Accuracy: 77.53%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.8314350843429565, Test Accuracy: 77.68%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.626786470413208, Test Accuracy: 77.52%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.6637831926345825, Test Accuracy: 77.53%\n",
      "Epoch [15/15], Step [100/600], Loss: 0.8939328193664551, Test Accuracy: 77.55%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.7139794230461121, Test Accuracy: 77.78%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.7580833435058594, Test Accuracy: 77.59%\n",
      "Epoch [15/15], Step [400/600], Loss: 0.6619071364402771, Test Accuracy: 77.46%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.7211395502090454, Test Accuracy: 77.63%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.6351661086082458, Test Accuracy: 77.61%\n",
      "Training FFNN with  100  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 0.507278561592102, Test Accuracy: 88.92%\n",
      "Epoch [1/15], Step [200/600], Loss: 0.41851845383644104, Test Accuracy: 90.96%\n",
      "Epoch [1/15], Step [300/600], Loss: 0.530486524105072, Test Accuracy: 91.94%\n",
      "Epoch [1/15], Step [400/600], Loss: 0.2555086016654968, Test Accuracy: 92.37%\n",
      "Epoch [1/15], Step [500/600], Loss: 0.3702915608882904, Test Accuracy: 93.09%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.24828851222991943, Test Accuracy: 93.56%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.11800926178693771, Test Accuracy: 93.5%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.16247287392616272, Test Accuracy: 94.23%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.2559707760810852, Test Accuracy: 94.36%\n",
      "Epoch [2/15], Step [400/600], Loss: 0.1820361167192459, Test Accuracy: 94.65%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.2870329022407532, Test Accuracy: 94.86%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.05983758345246315, Test Accuracy: 95.16%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.18728329241275787, Test Accuracy: 95.27%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.19561094045639038, Test Accuracy: 95.54%\n",
      "Epoch [3/15], Step [300/600], Loss: 0.09081806987524033, Test Accuracy: 95.47%\n",
      "Epoch [3/15], Step [400/600], Loss: 0.18108907341957092, Test Accuracy: 95.78%\n",
      "Epoch [3/15], Step [500/600], Loss: 0.15034636855125427, Test Accuracy: 96.04%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.20460450649261475, Test Accuracy: 96.15%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.07794488221406937, Test Accuracy: 96.36%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.06184079498052597, Test Accuracy: 96.23%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.08510234951972961, Test Accuracy: 96.55%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.09305962920188904, Test Accuracy: 96.48%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.10520657896995544, Test Accuracy: 96.65%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.11163678020238876, Test Accuracy: 96.79%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.06091790646314621, Test Accuracy: 96.77%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.08832918107509613, Test Accuracy: 96.66%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.08939611166715622, Test Accuracy: 96.84%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.12699520587921143, Test Accuracy: 96.92%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.038191620260477066, Test Accuracy: 96.98%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.0522257536649704, Test Accuracy: 96.99%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.07153787463903427, Test Accuracy: 97.09%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.07833132892847061, Test Accuracy: 97.16%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.053827449679374695, Test Accuracy: 97.12%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.07298503816127777, Test Accuracy: 97.13%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.10564138740301132, Test Accuracy: 97.0%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.1587304174900055, Test Accuracy: 97.23%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.03540237620472908, Test Accuracy: 97.18%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.08774948120117188, Test Accuracy: 97.12%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.04657265543937683, Test Accuracy: 97.34%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.05774174630641937, Test Accuracy: 97.44%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.03131473809480667, Test Accuracy: 97.1%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.08435292541980743, Test Accuracy: 97.31%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.10434488207101822, Test Accuracy: 97.44%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.1415269821882248, Test Accuracy: 97.45%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.10909058898687363, Test Accuracy: 97.29%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.03175892308354378, Test Accuracy: 97.41%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.05249767377972603, Test Accuracy: 97.57%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.06398192048072815, Test Accuracy: 97.57%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.04416431114077568, Test Accuracy: 97.52%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.025872305035591125, Test Accuracy: 97.56%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.09968174248933792, Test Accuracy: 97.57%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.0402553454041481, Test Accuracy: 97.49%\n",
      "Epoch [9/15], Step [500/600], Loss: 0.036151908338069916, Test Accuracy: 97.51%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.04141925275325775, Test Accuracy: 97.5%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.02449391409754753, Test Accuracy: 97.34%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.06778065860271454, Test Accuracy: 97.59%\n",
      "Epoch [10/15], Step [300/600], Loss: 0.023560073226690292, Test Accuracy: 97.56%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.030774567276239395, Test Accuracy: 97.61%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.06793295592069626, Test Accuracy: 97.55%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.08448515087366104, Test Accuracy: 97.64%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.022622594609856606, Test Accuracy: 97.67%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.07446981221437454, Test Accuracy: 97.74%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.039684686809778214, Test Accuracy: 97.65%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.048297297209501266, Test Accuracy: 97.61%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.0344260148704052, Test Accuracy: 97.53%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.023594167083501816, Test Accuracy: 97.6%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.039567653089761734, Test Accuracy: 97.68%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.015209842473268509, Test Accuracy: 97.73%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.017292024567723274, Test Accuracy: 97.75%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.08865348994731903, Test Accuracy: 97.7%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.0704229474067688, Test Accuracy: 97.7%\n",
      "Epoch [12/15], Step [600/600], Loss: 0.008623999543488026, Test Accuracy: 97.58%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.05198173224925995, Test Accuracy: 97.63%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.023779205977916718, Test Accuracy: 97.81%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.019247764721512794, Test Accuracy: 97.58%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.04618227481842041, Test Accuracy: 97.66%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.0160917267203331, Test Accuracy: 97.71%\n",
      "Epoch [13/15], Step [600/600], Loss: 0.014453048817813396, Test Accuracy: 97.52%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.020778687670826912, Test Accuracy: 97.72%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.012356121093034744, Test Accuracy: 97.71%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.019246891140937805, Test Accuracy: 97.77%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.01001613587141037, Test Accuracy: 97.65%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.01689559407532215, Test Accuracy: 97.72%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.041322413831949234, Test Accuracy: 97.54%\n",
      "Epoch [15/15], Step [100/600], Loss: 0.011306937783956528, Test Accuracy: 97.72%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.014907910488545895, Test Accuracy: 97.63%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.010097896680235863, Test Accuracy: 97.7%\n",
      "Epoch [15/15], Step [400/600], Loss: 0.014743770472705364, Test Accuracy: 97.64%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.013725467957556248, Test Accuracy: 97.72%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.018813779577612877, Test Accuracy: 97.41%\n",
      "Training ELM with  100  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 1.2902345657348633, Test Accuracy: 75.26%\n",
      "Epoch [1/15], Step [200/600], Loss: 0.9575674533843994, Test Accuracy: 78.3%\n",
      "Epoch [1/15], Step [300/600], Loss: 0.7726157307624817, Test Accuracy: 80.01%\n",
      "Epoch [1/15], Step [400/600], Loss: 0.6298041343688965, Test Accuracy: 81.27%\n",
      "Epoch [1/15], Step [500/600], Loss: 0.7715910077095032, Test Accuracy: 82.28%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.5812695622444153, Test Accuracy: 82.74%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.8075334429740906, Test Accuracy: 83.2%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.6275141835212708, Test Accuracy: 83.63%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.5697280168533325, Test Accuracy: 84.08%\n",
      "Epoch [2/15], Step [400/600], Loss: 0.5453302264213562, Test Accuracy: 84.32%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.580538272857666, Test Accuracy: 84.36%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.5322304964065552, Test Accuracy: 84.81%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.5931903719902039, Test Accuracy: 85.0%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.5077404379844666, Test Accuracy: 85.08%\n",
      "Epoch [3/15], Step [300/600], Loss: 0.7298047542572021, Test Accuracy: 85.21%\n",
      "Epoch [3/15], Step [400/600], Loss: 0.8140193223953247, Test Accuracy: 85.16%\n",
      "Epoch [3/15], Step [500/600], Loss: 0.6071556210517883, Test Accuracy: 85.04%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.5418802499771118, Test Accuracy: 85.46%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.4893619418144226, Test Accuracy: 85.43%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.4837760031223297, Test Accuracy: 85.69%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.4965747594833374, Test Accuracy: 85.63%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.4559701979160309, Test Accuracy: 85.79%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.49400195479393005, Test Accuracy: 85.81%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.4230847954750061, Test Accuracy: 85.86%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.5325601696968079, Test Accuracy: 85.95%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.4762490391731262, Test Accuracy: 85.94%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.3868383765220642, Test Accuracy: 85.88%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.4980684518814087, Test Accuracy: 86.11%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.5571063160896301, Test Accuracy: 86.04%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.5309804677963257, Test Accuracy: 86.28%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.3687470257282257, Test Accuracy: 86.07%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.5182352662086487, Test Accuracy: 86.05%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.3972720801830292, Test Accuracy: 86.11%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.3966384530067444, Test Accuracy: 86.4%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.6859221458435059, Test Accuracy: 86.39%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.5359893441200256, Test Accuracy: 86.4%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.3543298840522766, Test Accuracy: 86.39%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.47606560587882996, Test Accuracy: 86.32%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.5269361734390259, Test Accuracy: 86.33%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.46521854400634766, Test Accuracy: 86.34%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.520703911781311, Test Accuracy: 86.41%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.5451090335845947, Test Accuracy: 86.53%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.48789483308792114, Test Accuracy: 86.29%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.4861468970775604, Test Accuracy: 86.19%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.4163477420806885, Test Accuracy: 86.51%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.40534308552742004, Test Accuracy: 86.33%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.45178642868995667, Test Accuracy: 86.41%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.39409103989601135, Test Accuracy: 86.53%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.39593714475631714, Test Accuracy: 86.49%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.49201419949531555, Test Accuracy: 86.33%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.4154723286628723, Test Accuracy: 86.39%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.3477981984615326, Test Accuracy: 86.3%\n",
      "Epoch [9/15], Step [500/600], Loss: 0.4349745512008667, Test Accuracy: 86.43%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.47634100914001465, Test Accuracy: 86.5%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.41647788882255554, Test Accuracy: 86.42%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.6678603887557983, Test Accuracy: 86.32%\n",
      "Epoch [10/15], Step [300/600], Loss: 0.4176633059978485, Test Accuracy: 86.5%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.4746805429458618, Test Accuracy: 86.56%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.466583788394928, Test Accuracy: 86.54%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.3844018876552582, Test Accuracy: 86.31%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.40341946482658386, Test Accuracy: 86.33%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.6095488667488098, Test Accuracy: 86.4%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.7823196649551392, Test Accuracy: 86.38%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.3886255621910095, Test Accuracy: 86.4%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.38589590787887573, Test Accuracy: 86.52%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.5290912985801697, Test Accuracy: 86.59%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.3338300585746765, Test Accuracy: 86.5%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.3225344717502594, Test Accuracy: 86.5%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.5983086228370667, Test Accuracy: 86.39%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.4944247007369995, Test Accuracy: 86.29%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.3700483441352844, Test Accuracy: 86.48%\n",
      "Epoch [12/15], Step [600/600], Loss: 0.45459601283073425, Test Accuracy: 86.67%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.5922806262969971, Test Accuracy: 86.36%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.45708033442497253, Test Accuracy: 86.52%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.4987862706184387, Test Accuracy: 86.28%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.4668603241443634, Test Accuracy: 86.36%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.42696651816368103, Test Accuracy: 86.42%\n",
      "Epoch [13/15], Step [600/600], Loss: 0.6434314250946045, Test Accuracy: 86.6%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.4092002213001251, Test Accuracy: 86.52%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.6441636681556702, Test Accuracy: 86.53%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.4823791980743408, Test Accuracy: 86.42%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.36871132254600525, Test Accuracy: 86.48%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.4390832185745239, Test Accuracy: 86.68%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.5057815313339233, Test Accuracy: 86.43%\n",
      "Epoch [15/15], Step [100/600], Loss: 0.39186087250709534, Test Accuracy: 86.44%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.32508185505867004, Test Accuracy: 86.52%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.3037134110927582, Test Accuracy: 86.57%\n",
      "Epoch [15/15], Step [400/600], Loss: 0.5323625802993774, Test Accuracy: 86.48%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.43795064091682434, Test Accuracy: 86.35%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.3222099542617798, Test Accuracy: 86.62%\n",
      "Training FFNN with  200  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=200, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 0.23288312554359436, Test Accuracy: 89.76%\n",
      "Epoch [1/15], Step [200/600], Loss: 0.37515705823898315, Test Accuracy: 91.6%\n",
      "Epoch [1/15], Step [300/600], Loss: 0.33261558413505554, Test Accuracy: 92.35%\n",
      "Epoch [1/15], Step [400/600], Loss: 0.1559562087059021, Test Accuracy: 92.92%\n",
      "Epoch [1/15], Step [500/600], Loss: 0.29935160279273987, Test Accuracy: 93.96%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.2544005513191223, Test Accuracy: 94.53%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.1602400839328766, Test Accuracy: 94.85%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.1504867672920227, Test Accuracy: 95.16%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.0572776272892952, Test Accuracy: 95.55%\n",
      "Epoch [2/15], Step [400/600], Loss: 0.0853259488940239, Test Accuracy: 95.73%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.11241470277309418, Test Accuracy: 95.85%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.1742168813943863, Test Accuracy: 96.13%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.08032147586345673, Test Accuracy: 96.47%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.06706969439983368, Test Accuracy: 96.44%\n",
      "Epoch [3/15], Step [300/600], Loss: 0.20539338886737823, Test Accuracy: 96.51%\n",
      "Epoch [3/15], Step [400/600], Loss: 0.08458573371171951, Test Accuracy: 96.84%\n",
      "Epoch [3/15], Step [500/600], Loss: 0.056516047567129135, Test Accuracy: 96.64%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.1847955584526062, Test Accuracy: 96.81%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.09499907493591309, Test Accuracy: 97.18%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.04491928219795227, Test Accuracy: 96.83%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.14593566954135895, Test Accuracy: 97.09%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.15726466476917267, Test Accuracy: 97.22%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.07932132482528687, Test Accuracy: 97.24%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.06239235773682594, Test Accuracy: 97.3%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.10359317809343338, Test Accuracy: 97.27%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.07272534817457199, Test Accuracy: 97.25%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.09000896662473679, Test Accuracy: 97.28%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.05905512347817421, Test Accuracy: 97.49%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.0284726545214653, Test Accuracy: 97.57%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.019086938351392746, Test Accuracy: 97.52%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.06767481565475464, Test Accuracy: 97.47%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.054944463074207306, Test Accuracy: 97.57%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.09489370137453079, Test Accuracy: 97.52%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.09649811685085297, Test Accuracy: 97.64%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.1237422525882721, Test Accuracy: 97.73%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.023093795403838158, Test Accuracy: 97.6%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.05424225702881813, Test Accuracy: 97.81%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.056103456765413284, Test Accuracy: 97.82%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.049605365842580795, Test Accuracy: 97.82%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.015464168041944504, Test Accuracy: 97.71%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.014711516909301281, Test Accuracy: 97.76%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.011725285090506077, Test Accuracy: 97.87%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.03445494547486305, Test Accuracy: 97.85%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.008510034531354904, Test Accuracy: 97.86%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.021291231736540794, Test Accuracy: 97.55%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.02939559519290924, Test Accuracy: 97.71%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.013423305936157703, Test Accuracy: 97.92%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.05703718215227127, Test Accuracy: 97.81%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.03738894686102867, Test Accuracy: 97.8%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.027960319072008133, Test Accuracy: 97.95%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.015506413765251637, Test Accuracy: 97.86%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.02502373419702053, Test Accuracy: 97.62%\n",
      "Epoch [9/15], Step [500/600], Loss: 0.014760009944438934, Test Accuracy: 97.78%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.013051492162048817, Test Accuracy: 98.01%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.02242743782699108, Test Accuracy: 97.75%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.005405841860920191, Test Accuracy: 98.12%\n",
      "Epoch [10/15], Step [300/600], Loss: 0.029231196269392967, Test Accuracy: 97.91%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.01854989305138588, Test Accuracy: 97.82%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.039264976978302, Test Accuracy: 97.91%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.01820940524339676, Test Accuracy: 97.91%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.021353140473365784, Test Accuracy: 98.07%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.0019125491380691528, Test Accuracy: 97.79%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.019396880641579628, Test Accuracy: 97.94%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.017771810293197632, Test Accuracy: 97.67%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.005994778126478195, Test Accuracy: 97.92%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.004033864941447973, Test Accuracy: 98.04%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.015334004536271095, Test Accuracy: 98.12%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.02301599085330963, Test Accuracy: 98.07%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.006014938931912184, Test Accuracy: 98.05%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.007769851479679346, Test Accuracy: 97.88%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.005339221563190222, Test Accuracy: 97.92%\n",
      "Epoch [12/15], Step [600/600], Loss: 0.03046155907213688, Test Accuracy: 97.74%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.006862827111035585, Test Accuracy: 98.04%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.03797288239002228, Test Accuracy: 97.94%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.008164368569850922, Test Accuracy: 97.89%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.00572919799014926, Test Accuracy: 98.05%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.005563430022448301, Test Accuracy: 97.83%\n",
      "Epoch [13/15], Step [600/600], Loss: 0.012050577439367771, Test Accuracy: 97.76%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.008117562159895897, Test Accuracy: 98.02%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.0051974947564303875, Test Accuracy: 97.95%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.00996401533484459, Test Accuracy: 98.04%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.008892547339200974, Test Accuracy: 98.07%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.0049166264943778515, Test Accuracy: 97.98%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.006961008533835411, Test Accuracy: 97.99%\n",
      "Epoch [15/15], Step [100/600], Loss: 0.010919791646301746, Test Accuracy: 97.98%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.0028250061441212893, Test Accuracy: 98.12%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.004731007385998964, Test Accuracy: 98.05%\n",
      "Epoch [15/15], Step [400/600], Loss: 0.002406023908406496, Test Accuracy: 98.01%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.009177464991807938, Test Accuracy: 97.98%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.006028815638273954, Test Accuracy: 98.0%\n",
      "Training ELM with  200  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=200, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 0.8143833875656128, Test Accuracy: 81.37%\n",
      "Epoch [1/15], Step [200/600], Loss: 0.6801668405532837, Test Accuracy: 85.66%\n",
      "Epoch [1/15], Step [300/600], Loss: 0.45655375719070435, Test Accuracy: 86.95%\n",
      "Epoch [1/15], Step [400/600], Loss: 0.46194979548454285, Test Accuracy: 87.7%\n",
      "Epoch [1/15], Step [500/600], Loss: 0.4631226360797882, Test Accuracy: 88.24%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.4540657699108124, Test Accuracy: 88.4%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.40249526500701904, Test Accuracy: 89.02%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.307079553604126, Test Accuracy: 89.4%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.3297666311264038, Test Accuracy: 89.55%\n",
      "Epoch [2/15], Step [400/600], Loss: 0.5444476008415222, Test Accuracy: 89.62%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.3952421545982361, Test Accuracy: 89.96%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.3128957748413086, Test Accuracy: 90.15%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.37475520372390747, Test Accuracy: 90.11%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.3278447389602661, Test Accuracy: 90.23%\n",
      "Epoch [3/15], Step [300/600], Loss: 0.37483787536621094, Test Accuracy: 90.29%\n",
      "Epoch [3/15], Step [400/600], Loss: 0.3316953182220459, Test Accuracy: 90.61%\n",
      "Epoch [3/15], Step [500/600], Loss: 0.4871993660926819, Test Accuracy: 90.38%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.5531367659568787, Test Accuracy: 90.59%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.4312810003757477, Test Accuracy: 90.75%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.49851444363594055, Test Accuracy: 90.61%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.44612330198287964, Test Accuracy: 90.83%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.5501993298530579, Test Accuracy: 91.01%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.16833725571632385, Test Accuracy: 90.91%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.2772926986217499, Test Accuracy: 90.98%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.2663138806819916, Test Accuracy: 91.04%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.3211803138256073, Test Accuracy: 91.08%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.18648761510849, Test Accuracy: 91.07%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.3591826260089874, Test Accuracy: 91.13%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.3735668659210205, Test Accuracy: 90.92%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.3110124468803406, Test Accuracy: 91.05%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.4883483052253723, Test Accuracy: 91.03%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.39285945892333984, Test Accuracy: 91.29%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.36505451798439026, Test Accuracy: 91.17%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.32112812995910645, Test Accuracy: 91.29%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.30342766642570496, Test Accuracy: 91.22%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.3502123951911926, Test Accuracy: 91.1%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.2501315176486969, Test Accuracy: 91.45%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.17989122867584229, Test Accuracy: 91.16%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.33083659410476685, Test Accuracy: 91.35%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.4119092524051666, Test Accuracy: 91.25%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.18214185535907745, Test Accuracy: 91.26%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.3400488793849945, Test Accuracy: 91.36%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.18600846827030182, Test Accuracy: 91.28%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.22913287580013275, Test Accuracy: 91.24%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.21935676038265228, Test Accuracy: 91.26%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.31295454502105713, Test Accuracy: 91.13%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.30295902490615845, Test Accuracy: 91.17%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.2217414826154709, Test Accuracy: 91.36%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.40491044521331787, Test Accuracy: 91.24%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.3598455488681793, Test Accuracy: 91.41%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.29733696579933167, Test Accuracy: 91.32%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.1651296764612198, Test Accuracy: 91.28%\n",
      "Epoch [9/15], Step [500/600], Loss: 0.39449286460876465, Test Accuracy: 91.3%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.33934175968170166, Test Accuracy: 91.02%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.3428939878940582, Test Accuracy: 91.28%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.42591914534568787, Test Accuracy: 91.57%\n",
      "Epoch [10/15], Step [300/600], Loss: 0.4268832504749298, Test Accuracy: 91.41%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.23063525557518005, Test Accuracy: 91.15%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.24835935235023499, Test Accuracy: 91.37%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.3636549413204193, Test Accuracy: 91.52%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.3361380398273468, Test Accuracy: 91.39%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.23068569600582123, Test Accuracy: 91.21%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.17881101369857788, Test Accuracy: 91.41%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.2155694216489792, Test Accuracy: 91.56%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.3089911937713623, Test Accuracy: 91.29%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.43806400895118713, Test Accuracy: 91.46%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.2299865186214447, Test Accuracy: 91.36%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.21717126667499542, Test Accuracy: 91.34%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.3078058362007141, Test Accuracy: 91.43%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.2496301531791687, Test Accuracy: 91.33%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.23913726210594177, Test Accuracy: 91.61%\n",
      "Epoch [12/15], Step [600/600], Loss: 0.2403986006975174, Test Accuracy: 91.61%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.3210650384426117, Test Accuracy: 91.4%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.35057008266448975, Test Accuracy: 91.4%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.24566254019737244, Test Accuracy: 91.25%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.1908103972673416, Test Accuracy: 91.25%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.2149924486875534, Test Accuracy: 91.53%\n",
      "Epoch [13/15], Step [600/600], Loss: 0.28967389464378357, Test Accuracy: 91.46%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.3403959572315216, Test Accuracy: 91.52%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.21131311357021332, Test Accuracy: 91.42%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.2846266031265259, Test Accuracy: 91.3%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.24782133102416992, Test Accuracy: 91.35%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.3247857689857483, Test Accuracy: 91.27%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.34272879362106323, Test Accuracy: 91.57%\n",
      "Epoch [15/15], Step [100/600], Loss: 0.47655797004699707, Test Accuracy: 91.35%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.335460364818573, Test Accuracy: 91.5%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.25008952617645264, Test Accuracy: 91.42%\n",
      "Epoch [15/15], Step [400/600], Loss: 0.17963427305221558, Test Accuracy: 91.46%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.3540114462375641, Test Accuracy: 91.34%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.4346437156200409, Test Accuracy: 91.51%\n",
      "Training FFNN with  500  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=500, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 0.31605565547943115, Test Accuracy: 90.12%\n",
      "Epoch [1/15], Step [200/600], Loss: 0.287204384803772, Test Accuracy: 92.69%\n",
      "Epoch [1/15], Step [300/600], Loss: 0.23412801325321198, Test Accuracy: 93.52%\n",
      "Epoch [1/15], Step [400/600], Loss: 0.2266312539577484, Test Accuracy: 94.12%\n",
      "Epoch [1/15], Step [500/600], Loss: 0.19752557575702667, Test Accuracy: 95.48%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.1483519822359085, Test Accuracy: 96.18%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.17198632657527924, Test Accuracy: 96.07%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.14662618935108185, Test Accuracy: 96.11%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.10213614255189896, Test Accuracy: 96.64%\n",
      "Epoch [2/15], Step [400/600], Loss: 0.22056551277637482, Test Accuracy: 96.89%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.11660311371088028, Test Accuracy: 96.98%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.11202852427959442, Test Accuracy: 97.33%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.10752184689044952, Test Accuracy: 97.09%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.12128254771232605, Test Accuracy: 97.28%\n",
      "Epoch [3/15], Step [300/600], Loss: 0.05751359462738037, Test Accuracy: 97.24%\n",
      "Epoch [3/15], Step [400/600], Loss: 0.05764075368642807, Test Accuracy: 97.41%\n",
      "Epoch [3/15], Step [500/600], Loss: 0.08367794007062912, Test Accuracy: 97.66%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.05720030888915062, Test Accuracy: 97.27%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.02264065109193325, Test Accuracy: 97.78%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.025420675054192543, Test Accuracy: 97.78%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.03113296814262867, Test Accuracy: 97.7%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.06328108161687851, Test Accuracy: 97.79%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.02486230619251728, Test Accuracy: 97.88%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.04973640292882919, Test Accuracy: 98.03%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.08428884297609329, Test Accuracy: 97.81%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.04576072096824646, Test Accuracy: 97.98%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.020445846021175385, Test Accuracy: 98.01%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.03495265170931816, Test Accuracy: 98.0%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.030076730996370316, Test Accuracy: 97.88%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.058891307562589645, Test Accuracy: 97.97%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.013895622454583645, Test Accuracy: 98.27%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.014276377856731415, Test Accuracy: 98.04%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.11248642951250076, Test Accuracy: 97.89%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.05415665730834007, Test Accuracy: 98.08%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.038189008831977844, Test Accuracy: 98.0%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.021486137062311172, Test Accuracy: 97.96%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.02940012700855732, Test Accuracy: 97.87%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.0065224384889006615, Test Accuracy: 98.17%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.013815568760037422, Test Accuracy: 98.07%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.03582029789686203, Test Accuracy: 98.25%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.01656224951148033, Test Accuracy: 97.97%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.03246567025780678, Test Accuracy: 97.91%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.009456171654164791, Test Accuracy: 98.21%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.009715680964291096, Test Accuracy: 98.09%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.01317957416176796, Test Accuracy: 97.94%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.012332421727478504, Test Accuracy: 98.17%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.03289749473333359, Test Accuracy: 98.2%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.016255026683211327, Test Accuracy: 98.09%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.002449762774631381, Test Accuracy: 98.16%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.014000028371810913, Test Accuracy: 98.24%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.004781642463058233, Test Accuracy: 98.28%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.012884647585451603, Test Accuracy: 98.17%\n",
      "Epoch [9/15], Step [500/600], Loss: 0.025885099545121193, Test Accuracy: 97.99%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.011444061063230038, Test Accuracy: 98.18%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.0031303802970796824, Test Accuracy: 98.25%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.0025076144374907017, Test Accuracy: 98.28%\n",
      "Epoch [10/15], Step [300/600], Loss: 0.0021546687930822372, Test Accuracy: 97.98%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.005788618698716164, Test Accuracy: 98.07%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.009822564199566841, Test Accuracy: 98.05%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.01717567630112171, Test Accuracy: 98.36%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.004574441816657782, Test Accuracy: 98.24%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.0034234162885695696, Test Accuracy: 98.37%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.021026041358709335, Test Accuracy: 98.32%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.0035736963618546724, Test Accuracy: 98.02%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.005078449845314026, Test Accuracy: 98.27%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.005352212116122246, Test Accuracy: 97.96%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.003270612331107259, Test Accuracy: 98.13%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.0019905762746930122, Test Accuracy: 98.31%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.0062141199596226215, Test Accuracy: 98.18%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.0022558770142495632, Test Accuracy: 98.21%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.00312990415841341, Test Accuracy: 98.19%\n",
      "Epoch [12/15], Step [600/600], Loss: 0.002237193053588271, Test Accuracy: 98.29%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.002412195550277829, Test Accuracy: 98.17%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.0014423112152144313, Test Accuracy: 98.15%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.004121911246329546, Test Accuracy: 98.36%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.005142245441675186, Test Accuracy: 98.02%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.01252234261482954, Test Accuracy: 97.98%\n",
      "Epoch [13/15], Step [600/600], Loss: 0.0028862953186035156, Test Accuracy: 98.04%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.0038384583313018084, Test Accuracy: 98.34%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.002707767765969038, Test Accuracy: 98.29%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.011728232726454735, Test Accuracy: 98.19%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.0030770432204008102, Test Accuracy: 98.39%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.0037631478626281023, Test Accuracy: 98.33%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.0029958593659102917, Test Accuracy: 98.3%\n",
      "Epoch [15/15], Step [100/600], Loss: 0.0015452690422534943, Test Accuracy: 98.29%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.0020568212494254112, Test Accuracy: 98.33%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.0005094896769151092, Test Accuracy: 98.39%\n",
      "Epoch [15/15], Step [400/600], Loss: 0.00043855540570802987, Test Accuracy: 98.25%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.0007568784058094025, Test Accuracy: 98.29%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.000496777705848217, Test Accuracy: 98.24%\n",
      "Training ELM with  500  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=500, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 0.5052016973495483, Test Accuracy: 88.69%\n",
      "Epoch [1/15], Step [200/600], Loss: 0.33494749665260315, Test Accuracy: 90.34%\n",
      "Epoch [1/15], Step [300/600], Loss: 0.25981900095939636, Test Accuracy: 91.22%\n",
      "Epoch [1/15], Step [400/600], Loss: 0.26019495725631714, Test Accuracy: 91.74%\n",
      "Epoch [1/15], Step [500/600], Loss: 0.22523237764835358, Test Accuracy: 92.24%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.2624504268169403, Test Accuracy: 92.53%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.2938087284564972, Test Accuracy: 92.77%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.23975013196468353, Test Accuracy: 92.68%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.243938148021698, Test Accuracy: 92.87%\n",
      "Epoch [2/15], Step [400/600], Loss: 0.3059978783130646, Test Accuracy: 93.15%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.24978697299957275, Test Accuracy: 93.18%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.3524061441421509, Test Accuracy: 93.57%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.23666734993457794, Test Accuracy: 93.38%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.17336693406105042, Test Accuracy: 93.57%\n",
      "Epoch [3/15], Step [300/600], Loss: 0.22085458040237427, Test Accuracy: 93.57%\n",
      "Epoch [3/15], Step [400/600], Loss: 0.1634717881679535, Test Accuracy: 93.8%\n",
      "Epoch [3/15], Step [500/600], Loss: 0.1970733106136322, Test Accuracy: 93.65%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.13669875264167786, Test Accuracy: 93.67%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.09915313124656677, Test Accuracy: 94.01%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.17616571485996246, Test Accuracy: 93.9%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.139142706990242, Test Accuracy: 94.1%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.09255149215459824, Test Accuracy: 93.96%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.1238202452659607, Test Accuracy: 94.09%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.1715967059135437, Test Accuracy: 93.82%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.10124809294939041, Test Accuracy: 93.97%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.13267992436885834, Test Accuracy: 94.15%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.11280946433544159, Test Accuracy: 94.16%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.16717010736465454, Test Accuracy: 94.22%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.14937648177146912, Test Accuracy: 94.2%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.18189477920532227, Test Accuracy: 94.0%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.166368305683136, Test Accuracy: 94.28%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.27261343598365784, Test Accuracy: 94.2%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.09424172341823578, Test Accuracy: 94.21%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.15810498595237732, Test Accuracy: 94.43%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.1127462312579155, Test Accuracy: 94.36%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.12910956144332886, Test Accuracy: 94.2%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.18144828081130981, Test Accuracy: 94.52%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.07440849393606186, Test Accuracy: 94.16%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.0951012670993805, Test Accuracy: 94.47%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.0977325513958931, Test Accuracy: 94.33%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.10314956307411194, Test Accuracy: 94.08%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.18662795424461365, Test Accuracy: 94.12%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.17630040645599365, Test Accuracy: 94.44%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.12052798271179199, Test Accuracy: 94.55%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.17890548706054688, Test Accuracy: 94.43%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.07292145490646362, Test Accuracy: 94.35%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.11245105415582657, Test Accuracy: 94.49%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.10503597557544708, Test Accuracy: 94.23%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.22696739435195923, Test Accuracy: 94.41%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.14049674570560455, Test Accuracy: 94.62%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.12465965002775192, Test Accuracy: 94.26%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.1071692481637001, Test Accuracy: 94.51%\n",
      "Epoch [9/15], Step [500/600], Loss: 0.12179090827703476, Test Accuracy: 94.56%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.19395200908184052, Test Accuracy: 93.82%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.13702329993247986, Test Accuracy: 94.51%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.1135144978761673, Test Accuracy: 94.5%\n",
      "Epoch [10/15], Step [300/600], Loss: 0.19936445355415344, Test Accuracy: 94.73%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.1663103550672531, Test Accuracy: 94.61%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.1037847250699997, Test Accuracy: 94.6%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.07149616628885269, Test Accuracy: 94.63%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.09810268133878708, Test Accuracy: 94.48%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.11404234170913696, Test Accuracy: 94.45%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.1378687024116516, Test Accuracy: 94.47%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.15734954178333282, Test Accuracy: 94.76%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.18796470761299133, Test Accuracy: 94.69%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.1201084554195404, Test Accuracy: 94.65%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.07478819787502289, Test Accuracy: 94.53%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.08196189254522324, Test Accuracy: 94.56%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.19915226101875305, Test Accuracy: 94.56%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.28195545077323914, Test Accuracy: 94.43%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.20950882136821747, Test Accuracy: 94.5%\n",
      "Epoch [12/15], Step [600/600], Loss: 0.18850216269493103, Test Accuracy: 94.63%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.08601918071508408, Test Accuracy: 94.54%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.11784248054027557, Test Accuracy: 94.26%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.12290653586387634, Test Accuracy: 94.58%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.17100118100643158, Test Accuracy: 94.66%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.06979267299175262, Test Accuracy: 94.3%\n",
      "Epoch [13/15], Step [600/600], Loss: 0.08789494633674622, Test Accuracy: 94.59%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.20470543205738068, Test Accuracy: 94.68%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.08575515449047089, Test Accuracy: 94.65%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.1422674059867859, Test Accuracy: 94.57%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.20194321870803833, Test Accuracy: 94.6%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.11690246313810349, Test Accuracy: 94.63%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.08570658415555954, Test Accuracy: 94.58%\n",
      "Epoch [15/15], Step [100/600], Loss: 0.04166322201490402, Test Accuracy: 94.48%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.10282507538795471, Test Accuracy: 94.58%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.16930347681045532, Test Accuracy: 94.72%\n",
      "Epoch [15/15], Step [400/600], Loss: 0.23322933912277222, Test Accuracy: 94.72%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.14538592100143433, Test Accuracy: 94.6%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.20790186524391174, Test Accuracy: 94.35%\n",
      "Training FFNN with  1000  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=1000, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1000, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 0.45730045437812805, Test Accuracy: 90.88%\n",
      "Epoch [1/15], Step [200/600], Loss: 0.16852258145809174, Test Accuracy: 93.36%\n",
      "Epoch [1/15], Step [300/600], Loss: 0.10807297378778458, Test Accuracy: 94.69%\n",
      "Epoch [1/15], Step [400/600], Loss: 0.287339448928833, Test Accuracy: 95.48%\n",
      "Epoch [1/15], Step [500/600], Loss: 0.10794337093830109, Test Accuracy: 95.57%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.20396511256694794, Test Accuracy: 96.38%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.0783945620059967, Test Accuracy: 96.53%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.07828790694475174, Test Accuracy: 96.47%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.03319934755563736, Test Accuracy: 96.71%\n",
      "Epoch [2/15], Step [400/600], Loss: 0.15306232869625092, Test Accuracy: 97.18%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.08387047797441483, Test Accuracy: 97.51%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.08723395317792892, Test Accuracy: 97.42%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.01929493248462677, Test Accuracy: 97.47%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.12209764122962952, Test Accuracy: 97.7%\n",
      "Epoch [3/15], Step [300/600], Loss: 0.07491099089384079, Test Accuracy: 96.98%\n",
      "Epoch [3/15], Step [400/600], Loss: 0.023764917626976967, Test Accuracy: 97.61%\n",
      "Epoch [3/15], Step [500/600], Loss: 0.037263959646224976, Test Accuracy: 97.61%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.018386907875537872, Test Accuracy: 97.3%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.1211838349699974, Test Accuracy: 97.65%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.010528020560741425, Test Accuracy: 97.91%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.04178444296121597, Test Accuracy: 97.75%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.01475964579731226, Test Accuracy: 98.0%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.07131899148225784, Test Accuracy: 97.26%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.03799813613295555, Test Accuracy: 97.93%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.024987176060676575, Test Accuracy: 98.06%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.008687231689691544, Test Accuracy: 97.97%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.01932775415480137, Test Accuracy: 98.02%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.028109021484851837, Test Accuracy: 98.04%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.04763905704021454, Test Accuracy: 97.95%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.007892435416579247, Test Accuracy: 97.95%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.019268717616796494, Test Accuracy: 98.19%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.010139882564544678, Test Accuracy: 98.26%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.012314621359109879, Test Accuracy: 98.06%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.13502559065818787, Test Accuracy: 97.83%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.011911951005458832, Test Accuracy: 97.93%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.006186575163155794, Test Accuracy: 98.1%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.008305137045681477, Test Accuracy: 98.05%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.002859131433069706, Test Accuracy: 98.12%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.005946440622210503, Test Accuracy: 97.89%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.009098755195736885, Test Accuracy: 98.07%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.010897241532802582, Test Accuracy: 98.3%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.01726597547531128, Test Accuracy: 97.8%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.009784472174942493, Test Accuracy: 98.18%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.013607509434223175, Test Accuracy: 98.16%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.005252804607152939, Test Accuracy: 97.98%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.02860044501721859, Test Accuracy: 97.96%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.0031279397662729025, Test Accuracy: 98.1%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.0027461170684546232, Test Accuracy: 98.05%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.00789583008736372, Test Accuracy: 98.26%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.004978796932846308, Test Accuracy: 98.32%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.0009855079697445035, Test Accuracy: 98.12%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.002210167935118079, Test Accuracy: 98.08%\n",
      "Epoch [9/15], Step [500/600], Loss: 0.012994540855288506, Test Accuracy: 98.08%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.00466293515637517, Test Accuracy: 97.92%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.0015380762051790953, Test Accuracy: 97.95%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.019946107640862465, Test Accuracy: 98.24%\n",
      "Epoch [10/15], Step [300/600], Loss: 0.009345066733658314, Test Accuracy: 97.96%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.014054946601390839, Test Accuracy: 98.18%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.044755369424819946, Test Accuracy: 97.91%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.007336977869272232, Test Accuracy: 97.85%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.002017328981310129, Test Accuracy: 98.28%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.008836569264531136, Test Accuracy: 98.18%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.01831795647740364, Test Accuracy: 98.29%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.01245836727321148, Test Accuracy: 98.19%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.004676667973399162, Test Accuracy: 98.02%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.0013985928380861878, Test Accuracy: 98.1%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.001625358359888196, Test Accuracy: 98.12%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.0007388466037809849, Test Accuracy: 98.23%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.0013580417726188898, Test Accuracy: 98.17%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.013215623795986176, Test Accuracy: 98.2%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.0010328281205147505, Test Accuracy: 98.25%\n",
      "Epoch [12/15], Step [600/600], Loss: 0.007008105982095003, Test Accuracy: 97.88%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.006348360329866409, Test Accuracy: 97.81%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.0008213978144340217, Test Accuracy: 98.21%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.002110231202095747, Test Accuracy: 98.26%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.0007463499787263572, Test Accuracy: 98.24%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.022439826279878616, Test Accuracy: 98.02%\n",
      "Epoch [13/15], Step [600/600], Loss: 0.007449872326105833, Test Accuracy: 98.12%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.013946844264864922, Test Accuracy: 98.14%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.0028288266621530056, Test Accuracy: 98.09%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.0021113399416208267, Test Accuracy: 98.16%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.0021134871058166027, Test Accuracy: 98.27%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.0030054033268243074, Test Accuracy: 98.27%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.0013134757755324244, Test Accuracy: 98.03%\n",
      "Epoch [15/15], Step [100/600], Loss: 0.018478458747267723, Test Accuracy: 98.06%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.00040946490480564535, Test Accuracy: 98.22%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.0014316358137875795, Test Accuracy: 97.96%\n",
      "Epoch [15/15], Step [400/600], Loss: 9.661468357080594e-05, Test Accuracy: 98.25%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.0005288716638460755, Test Accuracy: 98.1%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.019402237609028816, Test Accuracy: 97.3%\n",
      "Training ELM with  1000  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=1000, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1000, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 0.33629363775253296, Test Accuracy: 89.73%\n",
      "Epoch [1/15], Step [200/600], Loss: 0.3894318640232086, Test Accuracy: 91.77%\n",
      "Epoch [1/15], Step [300/600], Loss: 0.31890106201171875, Test Accuracy: 92.75%\n",
      "Epoch [1/15], Step [400/600], Loss: 0.3614186942577362, Test Accuracy: 92.8%\n",
      "Epoch [1/15], Step [500/600], Loss: 0.1953289955854416, Test Accuracy: 93.57%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.12308571487665176, Test Accuracy: 94.06%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.20538471639156342, Test Accuracy: 93.94%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.24664781987667084, Test Accuracy: 94.18%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.2203093320131302, Test Accuracy: 94.37%\n",
      "Epoch [2/15], Step [400/600], Loss: 0.22734060883522034, Test Accuracy: 94.66%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.12337832152843475, Test Accuracy: 94.86%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.08661209046840668, Test Accuracy: 94.61%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.09024054557085037, Test Accuracy: 95.01%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.1724594533443451, Test Accuracy: 94.78%\n",
      "Epoch [3/15], Step [300/600], Loss: 0.18948017060756683, Test Accuracy: 94.98%\n",
      "Epoch [3/15], Step [400/600], Loss: 0.17085646092891693, Test Accuracy: 95.28%\n",
      "Epoch [3/15], Step [500/600], Loss: 0.1631752848625183, Test Accuracy: 95.19%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.10708818584680557, Test Accuracy: 94.95%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.1408555656671524, Test Accuracy: 95.39%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.1970691680908203, Test Accuracy: 95.27%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.1074497252702713, Test Accuracy: 95.34%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.10972197353839874, Test Accuracy: 95.47%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.16371183097362518, Test Accuracy: 95.51%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.11007905751466751, Test Accuracy: 95.79%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.19871993362903595, Test Accuracy: 95.69%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.1881849318742752, Test Accuracy: 95.34%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.0869227945804596, Test Accuracy: 95.46%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.19871826469898224, Test Accuracy: 95.18%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.10028507560491562, Test Accuracy: 95.61%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.21962323784828186, Test Accuracy: 95.66%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.08944300562143326, Test Accuracy: 95.64%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.11999248713254929, Test Accuracy: 95.56%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.09811745584011078, Test Accuracy: 95.98%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.06330021470785141, Test Accuracy: 95.48%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.10827769339084625, Test Accuracy: 95.6%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.08784078806638718, Test Accuracy: 95.94%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.11413949728012085, Test Accuracy: 95.89%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.12739385664463043, Test Accuracy: 95.82%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.06281258910894394, Test Accuracy: 95.87%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.11025658249855042, Test Accuracy: 95.49%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.11373944580554962, Test Accuracy: 95.72%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.10166482627391815, Test Accuracy: 96.0%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.03712134435772896, Test Accuracy: 95.88%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.04041450098156929, Test Accuracy: 95.81%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.07616899162530899, Test Accuracy: 95.75%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.06496232748031616, Test Accuracy: 95.61%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.19017478823661804, Test Accuracy: 96.15%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.09284723550081253, Test Accuracy: 95.72%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.19785715639591217, Test Accuracy: 95.99%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.057035621255636215, Test Accuracy: 95.62%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.0474921353161335, Test Accuracy: 95.73%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.09113863855600357, Test Accuracy: 96.22%\n",
      "Epoch [9/15], Step [500/600], Loss: 0.04654159024357796, Test Accuracy: 95.74%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.09210088849067688, Test Accuracy: 95.82%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.07170652598142624, Test Accuracy: 95.76%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.13013240694999695, Test Accuracy: 96.0%\n",
      "Epoch [10/15], Step [300/600], Loss: 0.11541356891393661, Test Accuracy: 95.92%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.10108336806297302, Test Accuracy: 96.13%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.08062615245580673, Test Accuracy: 95.64%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.09229432046413422, Test Accuracy: 96.26%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.10938728600740433, Test Accuracy: 95.54%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.1367347091436386, Test Accuracy: 95.79%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.06079874932765961, Test Accuracy: 96.16%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.0767238438129425, Test Accuracy: 96.05%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.12902863323688507, Test Accuracy: 95.79%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.06560590863227844, Test Accuracy: 96.08%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.18513455986976624, Test Accuracy: 95.83%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.10031921416521072, Test Accuracy: 95.91%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.07869952917098999, Test Accuracy: 95.77%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.05171837657690048, Test Accuracy: 95.61%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.09360998868942261, Test Accuracy: 95.96%\n",
      "Epoch [12/15], Step [600/600], Loss: 0.07008391618728638, Test Accuracy: 96.18%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.06906335800886154, Test Accuracy: 95.93%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.10115668177604675, Test Accuracy: 95.94%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.04135304316878319, Test Accuracy: 96.13%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.11873266100883484, Test Accuracy: 95.83%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.08074669539928436, Test Accuracy: 95.73%\n",
      "Epoch [13/15], Step [600/600], Loss: 0.029986515641212463, Test Accuracy: 95.94%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.07104849815368652, Test Accuracy: 96.11%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.12375177443027496, Test Accuracy: 96.03%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.06988681852817535, Test Accuracy: 95.82%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.07202675193548203, Test Accuracy: 95.97%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.06866797804832458, Test Accuracy: 95.85%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.061516571789979935, Test Accuracy: 95.85%\n",
      "Epoch [15/15], Step [100/600], Loss: 0.08385664969682693, Test Accuracy: 96.36%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.0906115248799324, Test Accuracy: 95.75%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.039198532700538635, Test Accuracy: 96.2%\n",
      "Epoch [15/15], Step [400/600], Loss: 0.061051588505506516, Test Accuracy: 96.0%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.12634789943695068, Test Accuracy: 95.78%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.11196381598711014, Test Accuracy: 95.93%\n",
      "Training FFNN with  2000  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=2000, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2000, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 0.28758639097213745, Test Accuracy: 91.92%\n",
      "Epoch [1/15], Step [200/600], Loss: 0.2947885990142822, Test Accuracy: 93.88%\n",
      "Epoch [1/15], Step [300/600], Loss: 0.254965603351593, Test Accuracy: 94.75%\n",
      "Epoch [1/15], Step [400/600], Loss: 0.14171582460403442, Test Accuracy: 96.45%\n",
      "Epoch [1/15], Step [500/600], Loss: 0.23263674974441528, Test Accuracy: 95.98%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.09927240014076233, Test Accuracy: 96.69%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.03359565511345863, Test Accuracy: 97.19%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.023739228025078773, Test Accuracy: 97.16%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.05865945667028427, Test Accuracy: 97.37%\n",
      "Epoch [2/15], Step [400/600], Loss: 0.07934407889842987, Test Accuracy: 97.7%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.11031723022460938, Test Accuracy: 97.26%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.08993648737668991, Test Accuracy: 97.54%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.054837074130773544, Test Accuracy: 97.56%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.08692183345556259, Test Accuracy: 97.46%\n",
      "Epoch [3/15], Step [300/600], Loss: 0.06802177429199219, Test Accuracy: 98.0%\n",
      "Epoch [3/15], Step [400/600], Loss: 0.06745613366365433, Test Accuracy: 97.76%\n",
      "Epoch [3/15], Step [500/600], Loss: 0.05305294692516327, Test Accuracy: 97.54%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.07271357625722885, Test Accuracy: 97.81%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.01363014243543148, Test Accuracy: 98.01%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.044632378965616226, Test Accuracy: 98.05%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.0162192415446043, Test Accuracy: 97.99%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.014351905323565006, Test Accuracy: 97.78%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.04435610771179199, Test Accuracy: 98.15%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.03299180790781975, Test Accuracy: 98.32%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.00919408816844225, Test Accuracy: 98.1%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.007104441057890654, Test Accuracy: 98.2%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.0016852787230163813, Test Accuracy: 98.18%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.023836283013224602, Test Accuracy: 98.24%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.00710446247830987, Test Accuracy: 98.11%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.010972651652991772, Test Accuracy: 97.86%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.03984450921416283, Test Accuracy: 98.27%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.018073638901114464, Test Accuracy: 98.21%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.007838444784283638, Test Accuracy: 98.26%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.001134346122853458, Test Accuracy: 98.14%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.0020847199484705925, Test Accuracy: 98.12%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.006685948930680752, Test Accuracy: 98.02%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.0029297543223947287, Test Accuracy: 98.24%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.01763094775378704, Test Accuracy: 98.38%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.006916808430105448, Test Accuracy: 98.0%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.015376085415482521, Test Accuracy: 98.23%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.0014838938368484378, Test Accuracy: 98.29%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.01755061000585556, Test Accuracy: 98.09%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.014062651433050632, Test Accuracy: 98.27%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.013870376162230968, Test Accuracy: 97.81%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.006455203518271446, Test Accuracy: 98.27%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.02174517884850502, Test Accuracy: 98.08%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.002121300669386983, Test Accuracy: 98.05%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.010555812157690525, Test Accuracy: 98.09%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.0034523389767855406, Test Accuracy: 98.22%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.0030791927129030228, Test Accuracy: 98.22%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.00036815940984524786, Test Accuracy: 98.37%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.022687921300530434, Test Accuracy: 98.15%\n",
      "Epoch [9/15], Step [500/600], Loss: 0.01832384429872036, Test Accuracy: 98.32%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.005016041919589043, Test Accuracy: 97.9%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.007868082262575626, Test Accuracy: 97.96%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.019222965463995934, Test Accuracy: 98.28%\n",
      "Epoch [10/15], Step [300/600], Loss: 0.005900966934859753, Test Accuracy: 98.34%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.03150997683405876, Test Accuracy: 98.2%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.002410655375570059, Test Accuracy: 98.25%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.0015416304813697934, Test Accuracy: 98.16%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.008341892622411251, Test Accuracy: 98.15%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.0034023693297058344, Test Accuracy: 98.31%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.0011501191183924675, Test Accuracy: 98.17%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.010156628675758839, Test Accuracy: 98.16%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.0004990108427591622, Test Accuracy: 97.94%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.00922818761318922, Test Accuracy: 97.7%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.0020982706919312477, Test Accuracy: 98.32%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.0020826307591050863, Test Accuracy: 98.29%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.004106030333787203, Test Accuracy: 98.21%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.0004116710333619267, Test Accuracy: 98.07%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.0022507577668875456, Test Accuracy: 98.25%\n",
      "Epoch [12/15], Step [600/600], Loss: 7.431443373207003e-05, Test Accuracy: 97.82%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.0008880578097887337, Test Accuracy: 98.21%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.0001557901268824935, Test Accuracy: 98.16%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.00337792094796896, Test Accuracy: 98.37%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.007323762867599726, Test Accuracy: 98.31%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.023166535422205925, Test Accuracy: 98.11%\n",
      "Epoch [13/15], Step [600/600], Loss: 6.338346429402009e-05, Test Accuracy: 98.27%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.04238307103514671, Test Accuracy: 98.15%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.0006229201098904014, Test Accuracy: 98.31%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.01470007561147213, Test Accuracy: 98.28%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.0422128289937973, Test Accuracy: 98.13%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.001346345292404294, Test Accuracy: 98.22%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.0010695565724745393, Test Accuracy: 98.16%\n",
      "Epoch [15/15], Step [100/600], Loss: 0.010198083706200123, Test Accuracy: 98.33%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.0024425170850008726, Test Accuracy: 98.21%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.0005393704632297158, Test Accuracy: 98.4%\n",
      "Epoch [15/15], Step [400/600], Loss: 0.010167594067752361, Test Accuracy: 98.2%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.0010224917205050588, Test Accuracy: 98.05%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.02044760249555111, Test Accuracy: 98.4%\n",
      "Training ELM with  2000  neurons...\n",
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=2000, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=2000, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/15], Step [100/600], Loss: 0.4775667190551758, Test Accuracy: 90.94%\n",
      "Epoch [1/15], Step [200/600], Loss: 0.3111106753349304, Test Accuracy: 92.89%\n",
      "Epoch [1/15], Step [300/600], Loss: 0.3083103597164154, Test Accuracy: 92.62%\n",
      "Epoch [1/15], Step [400/600], Loss: 0.25776785612106323, Test Accuracy: 93.66%\n",
      "Epoch [1/15], Step [500/600], Loss: 0.18596234917640686, Test Accuracy: 94.73%\n",
      "Epoch [1/15], Step [600/600], Loss: 0.27150648832321167, Test Accuracy: 94.29%\n",
      "Epoch [2/15], Step [100/600], Loss: 0.08082981407642365, Test Accuracy: 95.15%\n",
      "Epoch [2/15], Step [200/600], Loss: 0.11197901517152786, Test Accuracy: 95.37%\n",
      "Epoch [2/15], Step [300/600], Loss: 0.12232401221990585, Test Accuracy: 95.57%\n",
      "Epoch [2/15], Step [400/600], Loss: 0.11490695923566818, Test Accuracy: 95.81%\n",
      "Epoch [2/15], Step [500/600], Loss: 0.17725032567977905, Test Accuracy: 95.89%\n",
      "Epoch [2/15], Step [600/600], Loss: 0.14893315732479095, Test Accuracy: 96.09%\n",
      "Epoch [3/15], Step [100/600], Loss: 0.06145527958869934, Test Accuracy: 95.56%\n",
      "Epoch [3/15], Step [200/600], Loss: 0.08045151829719543, Test Accuracy: 95.39%\n",
      "Epoch [3/15], Step [300/600], Loss: 0.19364288449287415, Test Accuracy: 95.88%\n",
      "Epoch [3/15], Step [400/600], Loss: 0.07639093697071075, Test Accuracy: 96.05%\n",
      "Epoch [3/15], Step [500/600], Loss: 0.07430455088615417, Test Accuracy: 95.74%\n",
      "Epoch [3/15], Step [600/600], Loss: 0.12292682379484177, Test Accuracy: 96.28%\n",
      "Epoch [4/15], Step [100/600], Loss: 0.0706198513507843, Test Accuracy: 96.51%\n",
      "Epoch [4/15], Step [200/600], Loss: 0.18483810126781464, Test Accuracy: 95.68%\n",
      "Epoch [4/15], Step [300/600], Loss: 0.05394083634018898, Test Accuracy: 96.18%\n",
      "Epoch [4/15], Step [400/600], Loss: 0.08130447566509247, Test Accuracy: 96.21%\n",
      "Epoch [4/15], Step [500/600], Loss: 0.054970547556877136, Test Accuracy: 96.23%\n",
      "Epoch [4/15], Step [600/600], Loss: 0.0731796994805336, Test Accuracy: 96.37%\n",
      "Epoch [5/15], Step [100/600], Loss: 0.04553346708416939, Test Accuracy: 96.59%\n",
      "Epoch [5/15], Step [200/600], Loss: 0.09209228307008743, Test Accuracy: 96.49%\n",
      "Epoch [5/15], Step [300/600], Loss: 0.1054532527923584, Test Accuracy: 96.66%\n",
      "Epoch [5/15], Step [400/600], Loss: 0.03055654838681221, Test Accuracy: 96.62%\n",
      "Epoch [5/15], Step [500/600], Loss: 0.10181281715631485, Test Accuracy: 96.54%\n",
      "Epoch [5/15], Step [600/600], Loss: 0.06900037825107574, Test Accuracy: 96.44%\n",
      "Epoch [6/15], Step [100/600], Loss: 0.054804727435112, Test Accuracy: 96.18%\n",
      "Epoch [6/15], Step [200/600], Loss: 0.16305652260780334, Test Accuracy: 96.35%\n",
      "Epoch [6/15], Step [300/600], Loss: 0.07054232805967331, Test Accuracy: 96.63%\n",
      "Epoch [6/15], Step [400/600], Loss: 0.12133696675300598, Test Accuracy: 96.71%\n",
      "Epoch [6/15], Step [500/600], Loss: 0.10877923667430878, Test Accuracy: 96.47%\n",
      "Epoch [6/15], Step [600/600], Loss: 0.11737984418869019, Test Accuracy: 96.67%\n",
      "Epoch [7/15], Step [100/600], Loss: 0.1160486489534378, Test Accuracy: 96.44%\n",
      "Epoch [7/15], Step [200/600], Loss: 0.06329096108675003, Test Accuracy: 96.6%\n",
      "Epoch [7/15], Step [300/600], Loss: 0.1263943910598755, Test Accuracy: 96.74%\n",
      "Epoch [7/15], Step [400/600], Loss: 0.10857047140598297, Test Accuracy: 96.59%\n",
      "Epoch [7/15], Step [500/600], Loss: 0.054912008345127106, Test Accuracy: 96.66%\n",
      "Epoch [7/15], Step [600/600], Loss: 0.11971132457256317, Test Accuracy: 96.63%\n",
      "Epoch [8/15], Step [100/600], Loss: 0.035472311079502106, Test Accuracy: 96.91%\n",
      "Epoch [8/15], Step [200/600], Loss: 0.037200894206762314, Test Accuracy: 96.23%\n",
      "Epoch [8/15], Step [300/600], Loss: 0.08052104711532593, Test Accuracy: 96.43%\n",
      "Epoch [8/15], Step [400/600], Loss: 0.03031044639647007, Test Accuracy: 96.16%\n",
      "Epoch [8/15], Step [500/600], Loss: 0.1100115180015564, Test Accuracy: 96.75%\n",
      "Epoch [8/15], Step [600/600], Loss: 0.06218511238694191, Test Accuracy: 96.78%\n",
      "Epoch [9/15], Step [100/600], Loss: 0.1590416580438614, Test Accuracy: 96.54%\n",
      "Epoch [9/15], Step [200/600], Loss: 0.06544741988182068, Test Accuracy: 96.03%\n",
      "Epoch [9/15], Step [300/600], Loss: 0.06475792080163956, Test Accuracy: 96.74%\n",
      "Epoch [9/15], Step [400/600], Loss: 0.01997889205813408, Test Accuracy: 96.47%\n",
      "Epoch [9/15], Step [500/600], Loss: 0.05153855308890343, Test Accuracy: 96.53%\n",
      "Epoch [9/15], Step [600/600], Loss: 0.11643385142087936, Test Accuracy: 96.66%\n",
      "Epoch [10/15], Step [100/600], Loss: 0.06837739050388336, Test Accuracy: 96.51%\n",
      "Epoch [10/15], Step [200/600], Loss: 0.026251718401908875, Test Accuracy: 96.75%\n",
      "Epoch [10/15], Step [300/600], Loss: 0.04771975427865982, Test Accuracy: 96.34%\n",
      "Epoch [10/15], Step [400/600], Loss: 0.05641043186187744, Test Accuracy: 96.22%\n",
      "Epoch [10/15], Step [500/600], Loss: 0.087319515645504, Test Accuracy: 96.32%\n",
      "Epoch [10/15], Step [600/600], Loss: 0.06406612694263458, Test Accuracy: 96.44%\n",
      "Epoch [11/15], Step [100/600], Loss: 0.03591383621096611, Test Accuracy: 96.67%\n",
      "Epoch [11/15], Step [200/600], Loss: 0.09756319224834442, Test Accuracy: 96.38%\n",
      "Epoch [11/15], Step [300/600], Loss: 0.09888334572315216, Test Accuracy: 96.0%\n",
      "Epoch [11/15], Step [400/600], Loss: 0.02398090809583664, Test Accuracy: 96.64%\n",
      "Epoch [11/15], Step [500/600], Loss: 0.11939439177513123, Test Accuracy: 96.25%\n",
      "Epoch [11/15], Step [600/600], Loss: 0.008305966854095459, Test Accuracy: 96.76%\n",
      "Epoch [12/15], Step [100/600], Loss: 0.011337504722177982, Test Accuracy: 96.6%\n",
      "Epoch [12/15], Step [200/600], Loss: 0.030325334519147873, Test Accuracy: 96.01%\n",
      "Epoch [12/15], Step [300/600], Loss: 0.058327458798885345, Test Accuracy: 96.43%\n",
      "Epoch [12/15], Step [400/600], Loss: 0.012608830817043781, Test Accuracy: 96.29%\n",
      "Epoch [12/15], Step [500/600], Loss: 0.027283094823360443, Test Accuracy: 96.68%\n",
      "Epoch [12/15], Step [600/600], Loss: 0.05757661908864975, Test Accuracy: 96.65%\n",
      "Epoch [13/15], Step [100/600], Loss: 0.02769429422914982, Test Accuracy: 96.85%\n",
      "Epoch [13/15], Step [200/600], Loss: 0.03310778737068176, Test Accuracy: 96.48%\n",
      "Epoch [13/15], Step [300/600], Loss: 0.007290720473974943, Test Accuracy: 96.7%\n",
      "Epoch [13/15], Step [400/600], Loss: 0.022029688581824303, Test Accuracy: 96.78%\n",
      "Epoch [13/15], Step [500/600], Loss: 0.02935337834060192, Test Accuracy: 96.79%\n",
      "Epoch [13/15], Step [600/600], Loss: 0.015617472119629383, Test Accuracy: 96.83%\n",
      "Epoch [14/15], Step [100/600], Loss: 0.012404710054397583, Test Accuracy: 96.3%\n",
      "Epoch [14/15], Step [200/600], Loss: 0.029334725812077522, Test Accuracy: 96.39%\n",
      "Epoch [14/15], Step [300/600], Loss: 0.024962136521935463, Test Accuracy: 96.57%\n",
      "Epoch [14/15], Step [400/600], Loss: 0.036598023027181625, Test Accuracy: 96.45%\n",
      "Epoch [14/15], Step [500/600], Loss: 0.04715454578399658, Test Accuracy: 96.67%\n",
      "Epoch [14/15], Step [600/600], Loss: 0.06625226885080338, Test Accuracy: 96.55%\n",
      "Epoch [15/15], Step [100/600], Loss: 0.031861476600170135, Test Accuracy: 96.17%\n",
      "Epoch [15/15], Step [200/600], Loss: 0.027215342968702316, Test Accuracy: 96.59%\n",
      "Epoch [15/15], Step [300/600], Loss: 0.04988176375627518, Test Accuracy: 96.6%\n",
      "Epoch [15/15], Step [400/600], Loss: 0.11449617147445679, Test Accuracy: 96.66%\n",
      "Epoch [15/15], Step [500/600], Loss: 0.06954178214073181, Test Accuracy: 96.34%\n",
      "Epoch [15/15], Step [600/600], Loss: 0.060571637004613876, Test Accuracy: 96.24%\n"
     ]
    }
   ],
   "source": [
    "#We scan the NN size and plot the accuracy of the ELM and FF models to compare with MNIST\n",
    "\n",
    "n_neurons_vec = [10,20,50,100,200,500,1000,2000]\n",
    "n_epochs = 15\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "test_acc_mat = np.zeros([len(n_neurons_vec),6*n_epochs])\n",
    "test_acc_ELM_mat = np.zeros([len(n_neurons_vec),6*n_epochs])\n",
    "\n",
    "for i in range(len(n_neurons_vec)):\n",
    "    print('Training FFNN with ', n_neurons_vec[i], ' neurons...')\n",
    "    n_neurons = n_neurons_vec[i]\n",
    "    \n",
    "    NN_MNIST = Neural_Net(input_size=28*28, hidden_size=n_neurons, n_classes=10)\n",
    "    optimizer = torch.optim.Adam(NN_MNIST.parameters(), lr=0.001)\n",
    "\n",
    "    NN_MNIST.NN_stack[1].weight.requires_grad = True\n",
    "    NN_MNIST.NN_stack[1].bias.requires_grad = True\n",
    "\n",
    "    #training the full NN\n",
    "    \n",
    "    test_acc_mat[i,:] = train_pytorch_NN(NN_MNIST, n_epochs, train_loader_MNIST, test_loader_MNIST, loss, optimizer)\n",
    "    \n",
    "    NN_MNIST.reset_weights()\n",
    "    NN_MNIST.NN_stack[1].weight.requires_grad = False\n",
    "    NN_MNIST.NN_stack[1].bias.requires_grad = False\n",
    "    optimizer = torch.optim.Adam(NN_MNIST.parameters(), lr=0.01)\n",
    "    \n",
    "    print('Training ELM with ', n_neurons_vec[i], ' neurons...')\n",
    "    #set the input layer to not require gradients\n",
    "\n",
    "    \n",
    "    test_acc_ELM_mat[i,:] = train_pytorch_NN(NN_MNIST, n_epochs, train_loader_MNIST, test_loader_MNIST, loss, optimizer)\n",
    "    \n",
    "    del NN_MNIST  # Assuming 'model' is your neural network instance\n",
    "    torch.cuda.empty_cache()  # Advisable after deleting the model\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot comparison results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "royalblue"
         },
         "mode": "markers+lines",
         "name": "Full NN",
         "type": "scatter",
         "x": [
          10,
          20,
          50,
          100,
          200,
          500,
          1000,
          2000
         ],
         "y": [
          93.22,
          95.46,
          97.39,
          97.81,
          98.12,
          98.39,
          98.32,
          98.4
         ]
        },
        {
         "line": {
          "color": "firebrick"
         },
         "mode": "markers+lines",
         "name": "ELM",
         "type": "scatter",
         "x": [
          10,
          20,
          50,
          100,
          200,
          500,
          1000,
          2000
         ],
         "y": [
          43.13,
          60.83,
          77.78,
          86.68,
          91.61,
          94.76,
          96.36,
          96.91
         ]
        },
        {
         "line": {
          "dash": "dot"
         },
         "mode": "lines",
         "name": "Linear",
         "type": "scatter",
         "x": [
          10,
          20,
          50,
          100,
          200,
          500,
          1000,
          2000
         ],
         "y": [
          92.81,
          92.81,
          92.81,
          92.81,
          92.81,
          92.81,
          92.81,
          92.81
         ]
        }
       ],
       "layout": {
        "height": 300,
        "margin": {
         "b": 20,
         "l": 20,
         "r": 20,
         "t": 20
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 400,
        "xaxis": {
         "exponentformat": "power",
         "title": {
          "text": "Neurons"
         },
         "type": "log"
        },
        "yaxis": {
         "title": {
          "text": "Accuracy [%]"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=n_neurons_vec, y=np.max(test_acc_mat,1), mode='markers+lines', name='Full NN', line = dict(color='royalblue')))\n",
    "fig.add_trace(go.Scatter(x=n_neurons_vec, y=np.max(test_acc_ELM_mat,1), mode='markers+lines', name='ELM',line = dict(color='firebrick')))\n",
    "#add linear model as dotted line \n",
    "fig.add_trace(go.Scatter(x=n_neurons_vec, y=np.max(test_acc_lin)*np.ones(len(n_neurons_vec)), mode='lines', name='Linear', line=dict(dash='dot')))\n",
    "#change theme to white and set the sizer of the plot\n",
    "fig.update_layout(template='plotly_white', width=400, height=300,margin=dict(l=20, r=20, t=20, b=20))\n",
    "#log scale on y axis\n",
    "fig.update_yaxes(title_text=\"Accuracy [%]\")\n",
    "fig.update_xaxes(title_text=\"Neurons\",type = 'log',exponentformat=\"power\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for the same number of neurons training the input weights is very beneficial we need 30x the amount of neurons when using the ELM for the same level of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "Performance ratio",
         "type": "scatter",
         "x": [
          76.24,
          76.44878787878787,
          76.65757575757576,
          76.86636363636363,
          77.0751515151515,
          77.28393939393939,
          77.49272727272727,
          77.70151515151515,
          77.91030303030303,
          78.1190909090909,
          78.32787878787879,
          78.53666666666666,
          78.74545454545454,
          78.95424242424242,
          79.1630303030303,
          79.37181818181817,
          79.58060606060606,
          79.78939393939393,
          79.99818181818182,
          80.2069696969697,
          80.41575757575757,
          80.62454545454545,
          80.83333333333333,
          81.0421212121212,
          81.25090909090909,
          81.45969696969696,
          81.66848484848484,
          81.87727272727273,
          82.0860606060606,
          82.29484848484849,
          82.50363636363636,
          82.71242424242423,
          82.92121212121212,
          83.13,
          83.33878787878787,
          83.54757575757576,
          83.75636363636363,
          83.9651515151515,
          84.17393939393939,
          84.38272727272727,
          84.59151515151515,
          84.80030303030303,
          85.0090909090909,
          85.21787878787879,
          85.42666666666666,
          85.63545454545454,
          85.84424242424242,
          86.0530303030303,
          86.26181818181817,
          86.47060606060606,
          86.67939393939393,
          86.8881818181818,
          87.0969696969697,
          87.30575757575757,
          87.51454545454546,
          87.72333333333333,
          87.9321212121212,
          88.14090909090909,
          88.34969696969696,
          88.55848484848484,
          88.76727272727273,
          88.9760606060606,
          89.18484848484849,
          89.39363636363636,
          89.60242424242423,
          89.81121212121212,
          90.02,
          90.22878787878787,
          90.43757575757576,
          90.64636363636363,
          90.8551515151515,
          91.06393939393939,
          91.27272727272727,
          91.48151515151514,
          91.69030303030303,
          91.8990909090909,
          92.10787878787879,
          92.31666666666666,
          92.52545454545454,
          92.73424242424242,
          92.9430303030303,
          93.15181818181819,
          93.36060606060606,
          93.56939393939393,
          93.77818181818182,
          93.9869696969697,
          94.19575757575757,
          94.40454545454546,
          94.61333333333333,
          94.8221212121212,
          95.03090909090909,
          95.23969696969696,
          95.44848484848484,
          95.65727272727273,
          95.8660606060606,
          96.07484848484847,
          96.28363636363636,
          96.49242424242424,
          96.70121212121211,
          96.91
         ],
         "y": [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          34.50644942294633,
          33.444275404720095,
          32.540610786224754,
          31.76243743491547,
          31.085312225153878,
          30.490753030705186,
          29.964525993883736,
          30.282356652732652,
          32.32944344703759,
          34.17585544568528,
          35.84972195849705,
          33.83263988155999,
          32.139314058956856,
          30.81784528552456,
          29.75786186099939,
          34.41993434937355,
          41.238057874355825,
          47.01583434835571
         ]
        }
       ],
       "layout": {
        "height": 400,
        "margin": {
         "b": 20,
         "l": 20,
         "r": 20,
         "t": 20
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 400,
        "xaxis": {
         "range": [
          92,
          97
         ],
         "title": {
          "text": "Accuracy [%]"
         }
        },
        "yaxis": {
         "title": {
          "text": "# Neurons ELM / # Neurons NN"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming test_acc_mat and test_acc_ELM_mat contain the max accuracy for each neuron count\n",
    "interp_neurons_NN = interp1d(np.max(test_acc_mat,1), n_neurons_vec, kind='linear', bounds_error=False)\n",
    "interp_neurons_ELM = interp1d(np.max(test_acc_ELM_mat,1), n_neurons_vec, kind='linear', bounds_error=False)\n",
    "\n",
    "# Define a common range of accuracies for comparison (ensure it's within the range both models can achieve)\n",
    "common_accuracy_range = np.linspace(max(test_acc_mat.min(), test_acc_ELM_mat.min()), min(test_acc_mat.max(), test_acc_ELM_mat.max()), 100)\n",
    "\n",
    "# Estimate the number of neurons required for each model to achieve these accuracies\n",
    "neurons_NN = interp_neurons_NN(common_accuracy_range)\n",
    "neurons_ELM = interp_neurons_ELM(common_accuracy_range)\n",
    "\n",
    "# Calculate the ratio of neuron counts (NN / ELM) for the same accuracies\n",
    "neuron_ratio = neurons_ELM / neurons_NN\n",
    "\n",
    "# Plotting\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=common_accuracy_range, y=neuron_ratio, mode='markers+lines', name='Performance ratio'))\n",
    "#change theme to white and set the sizer of the plot\n",
    "fig.update_layout(template='plotly_white', width=400, height=400,margin=dict(l=20, r=20, t=20, b=20))\n",
    "fig.update_xaxes(title_text=\"Accuracy [%]\",range=[92,97])\n",
    "fig.update_yaxes(title_text=\"# Neurons ELM / # Neurons NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the data to txt files for processing\n",
    "\n",
    "#from numpy import asarray\n",
    "#from numpy import savetxt\n",
    "\n",
    "# save to csv file\n",
    "savetxt('data\\\\Results\\\\NN_training\\\\test_acc_FFNN.csv', test_acc_mat, delimiter=',')\n",
    "savetxt('data\\\\Results\\\\NN_training\\\\test_acc_ELM.csv', test_acc_ELM_mat, delimiter=',')\n",
    "savetxt('data\\\\Results\\\\NN_training\\\\test_acc_compare.csv', [test_acc,test_acc_ELM,test_acc_lin], delimiter=',')\n",
    "\n",
    "savetxt('data\\\\Results\\\\NN_training\\\\common_acc_range.csv', common_accuracy_range, delimiter=',')\n",
    "savetxt('data\\\\Results\\\\NN_training\\\\neuron_ratio.csv', neuron_ratio, delimiter=',')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we study the impact of model quantization on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/10], Step [100/600], Loss: 0.3675820231437683, Test Accuracy: 89.06%\n",
      "Epoch [1/10], Step [200/600], Loss: 0.26932501792907715, Test Accuracy: 90.72%\n",
      "Epoch [1/10], Step [300/600], Loss: 0.15140490233898163, Test Accuracy: 91.92%\n",
      "Epoch [1/10], Step [400/600], Loss: 0.16536912322044373, Test Accuracy: 92.81%\n",
      "Epoch [1/10], Step [500/600], Loss: 0.26765143871307373, Test Accuracy: 93.13%\n",
      "Epoch [1/10], Step [600/600], Loss: 0.2550232410430908, Test Accuracy: 93.22%\n",
      "Epoch [2/10], Step [100/600], Loss: 0.2108728289604187, Test Accuracy: 93.84%\n",
      "Epoch [2/10], Step [200/600], Loss: 0.3862888216972351, Test Accuracy: 94.41%\n",
      "Epoch [2/10], Step [300/600], Loss: 0.20241504907608032, Test Accuracy: 94.81%\n",
      "Epoch [2/10], Step [400/600], Loss: 0.17850971221923828, Test Accuracy: 94.89%\n",
      "Epoch [2/10], Step [500/600], Loss: 0.1865399032831192, Test Accuracy: 95.17%\n",
      "Epoch [2/10], Step [600/600], Loss: 0.09733948111534119, Test Accuracy: 95.36%\n",
      "Epoch [3/10], Step [100/600], Loss: 0.11806324869394302, Test Accuracy: 95.42%\n",
      "Epoch [3/10], Step [200/600], Loss: 0.13068300485610962, Test Accuracy: 95.68%\n",
      "Epoch [3/10], Step [300/600], Loss: 0.25097566843032837, Test Accuracy: 95.82%\n",
      "Epoch [3/10], Step [400/600], Loss: 0.1283748745918274, Test Accuracy: 95.88%\n",
      "Epoch [3/10], Step [500/600], Loss: 0.08671637624502182, Test Accuracy: 96.02%\n",
      "Epoch [3/10], Step [600/600], Loss: 0.21614955365657806, Test Accuracy: 96.33%\n",
      "Epoch [4/10], Step [100/600], Loss: 0.09374359250068665, Test Accuracy: 96.26%\n",
      "Epoch [4/10], Step [200/600], Loss: 0.20833510160446167, Test Accuracy: 96.35%\n",
      "Epoch [4/10], Step [300/600], Loss: 0.02955872006714344, Test Accuracy: 96.41%\n",
      "Epoch [4/10], Step [400/600], Loss: 0.09349359571933746, Test Accuracy: 96.45%\n",
      "Epoch [4/10], Step [500/600], Loss: 0.17404115200042725, Test Accuracy: 96.7%\n",
      "Epoch [4/10], Step [600/600], Loss: 0.0752110406756401, Test Accuracy: 96.81%\n",
      "Epoch [5/10], Step [100/600], Loss: 0.04585301876068115, Test Accuracy: 96.89%\n",
      "Epoch [5/10], Step [200/600], Loss: 0.0482049360871315, Test Accuracy: 96.75%\n",
      "Epoch [5/10], Step [300/600], Loss: 0.150678813457489, Test Accuracy: 96.91%\n",
      "Epoch [5/10], Step [400/600], Loss: 0.1684056669473648, Test Accuracy: 96.99%\n",
      "Epoch [5/10], Step [500/600], Loss: 0.06145603209733963, Test Accuracy: 96.9%\n",
      "Epoch [5/10], Step [600/600], Loss: 0.07726342976093292, Test Accuracy: 97.13%\n",
      "Epoch [6/10], Step [100/600], Loss: 0.08357539772987366, Test Accuracy: 97.22%\n",
      "Epoch [6/10], Step [200/600], Loss: 0.0916057601571083, Test Accuracy: 97.3%\n",
      "Epoch [6/10], Step [300/600], Loss: 0.04165225476026535, Test Accuracy: 97.12%\n",
      "Epoch [6/10], Step [400/600], Loss: 0.05488382279872894, Test Accuracy: 97.29%\n",
      "Epoch [6/10], Step [500/600], Loss: 0.0511271134018898, Test Accuracy: 97.29%\n",
      "Epoch [6/10], Step [600/600], Loss: 0.05556431785225868, Test Accuracy: 97.37%\n",
      "Epoch [7/10], Step [100/600], Loss: 0.08034181594848633, Test Accuracy: 97.07%\n",
      "Epoch [7/10], Step [200/600], Loss: 0.07248804718255997, Test Accuracy: 97.43%\n",
      "Epoch [7/10], Step [300/600], Loss: 0.08289020508527756, Test Accuracy: 97.32%\n",
      "Epoch [7/10], Step [400/600], Loss: 0.04716264083981514, Test Accuracy: 97.34%\n",
      "Epoch [7/10], Step [500/600], Loss: 0.019296111539006233, Test Accuracy: 97.19%\n",
      "Epoch [7/10], Step [600/600], Loss: 0.09558184444904327, Test Accuracy: 97.4%\n",
      "Epoch [8/10], Step [100/600], Loss: 0.05667763575911522, Test Accuracy: 97.49%\n",
      "Epoch [8/10], Step [200/600], Loss: 0.03206181153655052, Test Accuracy: 97.42%\n",
      "Epoch [8/10], Step [300/600], Loss: 0.04954862594604492, Test Accuracy: 97.48%\n",
      "Epoch [8/10], Step [400/600], Loss: 0.13739940524101257, Test Accuracy: 97.69%\n",
      "Epoch [8/10], Step [500/600], Loss: 0.027330880984663963, Test Accuracy: 97.62%\n",
      "Epoch [8/10], Step [600/600], Loss: 0.04108938202261925, Test Accuracy: 97.61%\n",
      "Epoch [9/10], Step [100/600], Loss: 0.08372274041175842, Test Accuracy: 97.52%\n",
      "Epoch [9/10], Step [200/600], Loss: 0.12739212810993195, Test Accuracy: 97.59%\n",
      "Epoch [9/10], Step [300/600], Loss: 0.02456977777183056, Test Accuracy: 97.75%\n",
      "Epoch [9/10], Step [400/600], Loss: 0.07335755974054337, Test Accuracy: 97.74%\n",
      "Epoch [9/10], Step [500/600], Loss: 0.025471193715929985, Test Accuracy: 97.72%\n",
      "Epoch [9/10], Step [600/600], Loss: 0.07238714396953583, Test Accuracy: 97.57%\n",
      "Epoch [10/10], Step [100/600], Loss: 0.026726407930254936, Test Accuracy: 97.79%\n",
      "Epoch [10/10], Step [200/600], Loss: 0.04328443482518196, Test Accuracy: 97.55%\n",
      "Epoch [10/10], Step [300/600], Loss: 0.0373416431248188, Test Accuracy: 97.71%\n",
      "Epoch [10/10], Step [400/600], Loss: 0.0310222078114748, Test Accuracy: 97.54%\n",
      "Epoch [10/10], Step [500/600], Loss: 0.04350392892956734, Test Accuracy: 97.58%\n",
      "Epoch [10/10], Step [600/600], Loss: 0.02381504699587822, Test Accuracy: 97.71%\n"
     ]
    }
   ],
   "source": [
    "#impact of quantization on network performance \n",
    "\n",
    "n_bit_vector = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12]\n",
    "\n",
    "#We Now create an instance of the NN class and move if to the GPU if available\n",
    "n_neurons = 100\n",
    "NN_MNIST = Neural_Net(input_size=28*28, hidden_size=n_neurons, n_classes=10)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(NN_MNIST.parameters(), lr=0.001)\n",
    "\n",
    "#training the full NN\n",
    "n_epochs = 10\n",
    "test_acc = train_pytorch_NN(NN_MNIST, n_epochs, train_loader_MNIST, test_loader_MNIST, loss, optimizer)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "trained_params = NN_MNIST.get_params()\n",
    "if trained_params.requires_grad:\n",
    "    # Detach the tensor from the computation graph\n",
    "    trained_params = trained_params.detach()\n",
    "if trained_params.is_cuda:\n",
    "    # Move the tensor to the CPU\n",
    "    trained_params = trained_params.cpu()\n",
    "trained_params = trained_params.numpy()\n",
    "\n",
    "accuracy_mat_quant = np.zeros([100,len(n_bit_vector)])\n",
    "\n",
    "for i in range(len(n_bit_vector)):\n",
    "     accuracy_list = []\n",
    "     \n",
    "     n_levels = 2**n_bit_vector[i]\n",
    "     \n",
    "     quantize_model(NN_MNIST,n_levels)\n",
    "     \n",
    "     correct = 0 \n",
    "     total = 0\n",
    "     for images, labels in test_loader_MNIST:\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "          Y_pred = NN_MNIST.forward(images)\n",
    "          _, predicted = torch.max(Y_pred.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "          accuracy = ( 100*correct/total)\n",
    "          accuracy_list.append(accuracy)\n",
    "     accuracy_mat_quant[:,i] = accuracy_list\n",
    "\n",
    "     NN_MNIST.set_params(trained_params)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "Quantized performance",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          12
         ],
         "y": [
          10.424542538300047,
          65.36793149596674,
          95.43282334965585,
          97.08655682618311,
          97.29851336775221,
          97.40361029574844,
          97.45384810213584,
          97.45685847660542,
          97.43041844342547,
          97.46395888526845,
          97.46395888526845
         ]
        }
       ],
       "layout": {
        "height": 300,
        "margin": {
         "b": 20,
         "l": 20,
         "r": 20,
         "t": 20
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 400,
        "xaxis": {
         "tickvals": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          12
         ],
         "title": {
          "text": "Number of bits"
         }
        },
        "yaxis": {
         "title": {
          "text": "Accuracy [%]"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=n_bit_vector, y=np.mean(accuracy_mat_quant,0), mode='markers+lines', name='Quantized performance'))\n",
    "#change theme to white and set the sizer of the plot\n",
    "fig.update_layout(template='plotly_white', width=400, height=300,margin=dict(l=20, r=20, t=20, b=20))\n",
    "#increaser the number of ticks on the x axis\n",
    "fig.update_xaxes(tickvals=n_bit_vector)\n",
    "fig.update_xaxes(title_text=\"Number of bits\")\n",
    "fig.update_yaxes(title_text=\"Accuracy [%]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt('data\\\\Results\\\\NN_training\\\\quantization.csv', [n_bit_vector,np.mean(accuracy_mat_quant,0)], delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Neural_Net(\n",
      "  (NN_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "maximum supported dimension for an ndarray is 32, found 100",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 31\u001b[0m\n\u001b[0;32m     26\u001b[0m init_pos \u001b[38;5;241m=\u001b[39m init_pos\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     28\u001b[0m PEPG_optimizer \u001b[38;5;241m=\u001b[39m PEPG_opt(N_dim, pop_size, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, starting_mu\u001b[38;5;241m=\u001b[39minit_pos ,starting_sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mtrain_online_pop_NN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNN_MNIST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_MNIST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader_MNIST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPEPG_optimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 72\u001b[0m, in \u001b[0;36mtrain_online_pop_NN\u001b[1;34m(model, n_epochs, train_loader, test_loader, loss, optimizer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m loss(Y_pred,labels)\n\u001b[0;32m     70\u001b[0m     rewards\u001b[38;5;241m.\u001b[39mappend(loss_value)\n\u001b[1;32m---> 72\u001b[0m rewards \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m)\u001b[49m[:,np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m     73\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mtell(rewards)\n\u001b[0;32m     74\u001b[0m best_params \u001b[38;5;241m=\u001b[39m coordinates[:,np\u001b[38;5;241m.\u001b[39margmin(rewards)]\n",
      "\u001b[1;31mValueError\u001b[0m: maximum supported dimension for an ndarray is 32, found 100"
     ]
    }
   ],
   "source": [
    "# Training loop PEPG for MNIST: \n",
    "\n",
    "# TODO : need to rework PEPG and CMA and PSO to take a param dictionary as input parameters so I can create an optimizer loop for them \n",
    "\n",
    "#NN_MNIST.reset_weights()\n",
    "#NN_MNIST.NN_stack[0].requires_grad = True\n",
    "n_neurons = 100\n",
    "n_epochs =1\n",
    "NN_MNIST = Neural_Net(input_size=28*28, hidden_size=n_neurons, n_classes=10)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# learning parameters\n",
    "\n",
    "epochs = 10\n",
    "N_dim = NN_MNIST.num_params\n",
    "pop_size = 100\n",
    "\n",
    "init_pos = NN_MNIST.get_params()\n",
    "\n",
    "if init_pos.requires_grad:\n",
    "    # Detach the tensor from the computation graph\n",
    "    init_pos = init_pos.detach()\n",
    "if init_pos.is_cuda:\n",
    "    # Move the tensor to the CPU\n",
    "    init_pos = init_pos.cpu()\n",
    "init_pos = init_pos.numpy()\n",
    "\n",
    "PEPG_optimizer = PEPG_opt(N_dim, pop_size, learning_rate=0.05, starting_mu=init_pos ,starting_sigma=0.5)\n",
    "\n",
    "\n",
    "train_online_pop_NN(NN_MNIST, n_epochs, train_loader_MNIST, test_loader_MNIST, loss, PEPG_optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01789798, -0.01329115, -0.00524061, ...,  0.05293956,\n",
       "       -0.00237943, -0.03485161], dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
